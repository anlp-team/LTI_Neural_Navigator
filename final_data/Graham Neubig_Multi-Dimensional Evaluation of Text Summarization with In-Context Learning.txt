Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorTécnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan
Text: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)—acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples—toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:•Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.•Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.
8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487–8495 July 9-14, 2023 ©2023 Association for Computational Linguistics


Inthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:•Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.•Relevance:Thepropertyofcapturingsalientinformationfromthesource.•Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.•Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.
1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse–decodednumericstring–asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.
8488


2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin§4.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin§4.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire
CTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343
Table1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g."Isthisacoherentsummary?")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall’sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms
MetricCoherenceConsistencyFluencyRelevanceρτρτρτρτ
ICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396
8489


500
500
500
500
Consistency
Consistency
Coherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show
1000
1000
1000
1000
0.2
Coherence Uniform Sampling
Relevance Stratified Sampling
0
0
0
0
Coherence
Coherence
RelevanceAspect
3.5
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
RelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe
Consistency Stratified Sampling
Seed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.
1.5
1500
1500
1500
1500
3.0
Consistency Uniform Sampling
Coherence Human
Fluency Uniform Sampling
2.5
Fluency Stratified Sampling
4.0Number of In-context Examples
Relevance Human
Fluency
Fluency
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
Seed 2
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
Fluency Human
2.0
Seed 1
0.4
0.4
0.6Spearman Correlation
0.6Spearman Correlation
Consistency Human
Relevance Uniform Sampling
8490


1.25
1.25
1.25
1.25
1.25
0.981
26.63
0.849
4.85
0.929
0.761
4.47
Metric
0.96-0.96-0.96-0.96
4.78
BRIO
BRIO
BRIO
BRIO
3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.
Model
0.996
4.15
22.09
0.890
Overall
4.97
0.908
Table2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric’shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems–GPT-3,BRIO,andT0–theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.
4.80
28.20
Coh.Con.Flu.Rel.
Human
3.68
4.73
BARTSc.
0.985
0.96
4.27
0.71
0.71
0.71
0.71
0.71
4.65
4.65
T0
T0
T0
T0
0.904
ROUGE-L
ICE
0.994
GPT-3
GPT-3
GPT-3
GPT-3
0.937

0.8960.9930.9930.834
4.574.654.884.48
8491


Relatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580–7605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806–3812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry´sci´nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449–1462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230–9240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332–9346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74–81,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280–289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL’02,page311–318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881–7892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008–5020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263–27277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.
8492


WeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563–578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA∈[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines–ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall’sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman’srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.
8493


ACL2023ResponsibleNLPChecklist
TheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.
AForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper’smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescientiﬁcartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeciﬁed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidentiﬁesindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection–Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigniﬁcant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.
8494


C(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe"hyperparamters"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigniﬁcanceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants’demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou’reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual’spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality
8495