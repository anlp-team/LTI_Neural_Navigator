Technological University Dublin Technological University Dublin ARROW@TU Dublin ARROW@TU Dublin
Conference papers
School of Computer Science
2023
Queer In AI: A Case Study in Community-Led Participatory AI Queer In AI: A Case Study in Community-Led Participatory AI
Anaelia Ovalle University of California, USA
Arjun Subramonian University of California, USA
Ashwiin Singh Queer in AI, India
See next page for additional authors
Follow this and additional works at: https://arrow.tudublin.ie/scschcomcon
Part of the Computer Engineering Commons, and the Social and Behavioral Sciences Commons
Recommended Citation Recommended Citation Ovalle, Anaelia; Subramonian, Arjun; Singh, Ashwiin; Voelcker, Claas; Sutherland, Danica; Locatelli, Davide; Breznik, Eva; Klubicka, Felip; Yuan, Hang; J, Hetvi; Zhang, Huan; Shriram, Jaidev; Lehman, Kruno; Soldaini, Luca; Sap, Maarten; Deisenroth, Marc Peter; Pacheco, Maria Leonor; Ryskina, Maria; Mundt, Martin; Agarwal, Melind; McLean, Nyx; Xu, Pan; Pranav, A.; Korpan, Raj; Ray, Ruchira; Mathew, Sarah; Arora, Sarthak; John, S.T.; Anand, Tanvi; Agrawal, Vishakha; Agnew, William; Long, Yanan; Wang, Zijie J.; Talat, Zeerak; Ghosh, Avijit; Dennler, Nathaniel; Noseworthy, Michael; Jha, Sharvani; Baylor, Emi; Joshi, Aditya; Bilenko, Natalia Y.; McNamara, Andrew; Gontijo-Lopes, Raphael; Markham, Alex; Dong, Evyn; Kay, Jackie; Saraswat, Manu; Vytla, Nikhil; and Stark, Luke, "Queer In AI: A Case Study in Community-Led Participatory AI" (2023). Conference papers. 407. https://arrow.tudublin.ie/scschcomcon/407
This Conference Paper is brought to you for free and open access by the School of Computer Science at ARROW@TU Dublin. It has been accepted for inclusion in Conference papers by an authorized administrator of ARROW@TU Dublin. For more information, please contact arrow.admin@tudublin.ie, aisling.coyne@tudublin.ie, gerard.connolly@tudublin.ie, vera.kilshaw@tudublin.ie.
This work is licensed under a Creative Commons Attribution-Share Alike 4.0 International License.


Authors Authors Anaelia Ovalle, Arjun Subramonian, Ashwiin Singh, Claas Voelcker, Danica Sutherland, Davide Locatelli, Eva Breznik, Felip Klubicka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, Melind Agarwal, Nyx McLean, Pan Xu, A. Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, S.T. John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael Gontijo-Lopes, Alex Markham, Evyn Dong, Jackie Kay, Manu Saraswat, Nikhil Vytla, and Luke Stark
This conference paper is available at ARROW@TU Dublin: https://arrow.tudublin.ie/scschcomcon/407


1882
Queer In AI: A Case Study in Community-Led Participatory AI
Organizers of QueerInAI Queer in AI Many Countries
Anaelia Ovalle Queer in AI & University of California, Los Angeles USA
Arjun Subramonian Queer in AI & University of California, Los Angeles USA
Danica J. Sutherland Queer in AI & University of British Columbia & Amii Canada
Claas Voelcker Queer in AI & University of Toronto, Vector Institute Canada
Ashwin Singh Queer in AI India
Filip Klubička Queer in AI & ADAPT Centre, Technological University Dublin Ireland
Eva Breznik Queer in AI & Uppsala University Sweden
Davide Locatelli Queer in AI Spain
Huan Zhang Queer in AI USA
Hetvi J Queer in AI United Kingdom
Hang Yuan Queer in AI United Kingdom
Jaidev Shriram Queer in AI & University of California, San Diego USA
Luca Soldaini Queer in AI & Allen Institute for AI USA
Kruno Lehman Queer in AI Switzerland
Maria Leonor Pacheco Queer in AI & University of Colorado Boulder USA
Marc Peter Deisenroth Queer in AI & University College London United Kingdom
Maarten Sap Queer in AI & Language Technologies Institute, Carnegie Mellon University & Allen Institute for AI USA
Maria Ryskina Queer in AI & MIT USA
Milind Agarwal Queer in AI & George Mason University USA
Martin Mundt Queer in AI & TU Darmstadt & hessian.AI Germany
Nyx McLean Queer in AI & Rhodes University South Africa
Pan Xu Queer in AI & Duke University USA
A Pranav Queer in AI Hong Kong
Sarah Mathew Queer in AI & Georgia Institute of Technology USA
Raj Korpan Queer in AI & Iona University USA
Ruchira Ray Queer in AI USA
Sarthak Arora Queer in AI India
ST John Queer in AI & Aalto University Finland
Tanvi Anand Queer in AI USA


1883
Vishakha Agrawal Queer in AI India
William Agnew Queer in AI & University of Washington USA
Yanan Long Queer in AI & University of Chicago USA
Zeerak Talat Queer in AI Canada
Zijie J. Wang Queer in AI & Georgia Tech USA
Avijit Ghosh Queer in AI & Northeastern University USA
Michael Noseworthy Queer In AI & MIT USA
Nathaniel Dennler Queer In AI USA
Sharvani Jha Queer In AI USA
Aditya Joshi Queer In AI & SEEK, Australia Australia
Emi Baylor Queer In AI Canada
Natalia Y. Bilenko Queer in AI USA
Raphael Gontijo-Lopes Queer in AI USA
Andrew McNamara Queer in AI & Microsoft Canada
Alex Markham Queer in AI Sweden
Evyn Dˇong Queer in AI USA
Manu Saraswat Queer in AI Canada
Jackie Kay Queer in AI United Kingdom
Nikhil Vytla Queer in AI USA
Luke Stark Queer in AI & Western University Canada
ABSTRACT Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer peo- ple. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, de- centralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community’s programs over the years. We discuss different challenges that emerged in the process, look at ways this
organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization’s impact. Queer in AI provides important lessons and insights for practi- tioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer com- munity. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fos- tering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participa- tory practices, and bringing participation to institutions outside of individual research projects. Queer in AI’s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory meth- ods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. FAccT ’23, June 12–15, 2023, Chicago, IL, USA © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0192-4/23/06. . . $15.00 https://doi.org/10.1145/3593013.3594134
ACM Reference Format: Organizers of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubička, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan Xu, A Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy,


1884
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
in scope and time. Contrary to participation being controlled by the corporations and states the design and own AI, we argue in the favor of shifting power towards marginalized groups and centering their experiences. We call for a culture of participation in AI to address this, one that enables deep and long-term participation in AI research, institutions, and practices.
Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNa- mara, Raphael Gontijo-Lopes, Alex Markham, Evyn Dˇong, Jackie Kay, Manu Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI: A Case Study in Community-Led Participatory AI. In 2023 ACM Conference on Fairness, Ac- countability, and Transparency (FAccT ’23), June 12–15, 2023, Chicago, IL, USA. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3593013.3594134
Over the years, the AI community has witnessed several community-led efforts from marginalized communities, each tackling issues of inequality that arise along various axes of marginalization; these include Black in AI [12], LatinX in AI [77], Women in Machine Learning [133], Masakhane [84], Widening NLP [130], Diversity in AI [36], Indigenous in AI [64], Queer in HCI [34], the Indigenous Protocol and AI Working Group [79], the Deep Learning Indaba [31], Khipu [73], North Africans in ML [91], {Dis}Ability in AI [63], Te Hiku Media [47], and Muslims in ML [88]. These organizations have worked in AI ethics, advocated against AI harms, provided longstanding venues and visibility for AI ethics research within major ML and NLP conferences, resolved inclusion issues with those venues, and developed community-led datasets, models, and other technology. Most importantly, they have advanced participation by marginalized communities in AI research and development at large, nurturing countless researchers and practitioners with community, mentorship, financial aid, and innumerable other forms of help with the many barriers marginalized people face in AI. These groups have made AI much more diverse, and strengthened the voices of marginalized people within AI.
1 INTRODUCTION Artificial intelligence (AI) has seen enormous developments in re- cent years, such as substantial advances in protein modeling, drug discovery, weather prediction, and personalized medicine [67, 102, 128]. The ubiquity of unregulated AI within socio-technical sys- tems, however, often produces discriminatory outcomes and harms marginalized communities globally [8, 10, 66]. For queer people in particular, machine learning models learn brittle, toxic represen- tations that cause representational and allocational harms, from misgendering to healthcare discrimination [32, 37, 70, 124]. Identi- fying and mitigating harmful outcomes has led to the development of computational and socio-technical methods for achieving fair- ness [13, 29, 86], including automatic evaluation and unfairness mitigation techniques [16, 41, 86]. While such approaches have the potential to mitigate harms for queer people in domains like fighting online abuse, health, and employment [124], computa- tional techniques generally encode narrow conceptualizations of fairness where queer identities are assumed to be known, observ- able, measurable, discrete, and static [81]. By locating the source of unfairness in individuals or in specific design decisions [129], com- putational approaches to fairness can reinforce existing power rela- tions [35, 68], including marginalized communities only in preda- tory ways [53] or as “ethics washing” [112] (cf. Appendix §A for an extended critique of computational approaches to fairness).
In this work, we argue that AI ethicists who value participatory methods as a means for making ethical AI should engage with par- ticipatory and community-lead AI ethics organizations, and study their organizational, strategic, and administrative work through which they are advancing participation and building cultures of participation. This often difficult process involves navigating the complexities of combining inquiry with praxis, and sheds light on differences between participatory approaches.
Participatory methods address some of these limitations. Involv- ing users as co-designers holds great potential for dismantling power relations and empowering marginalized communities that are disproportionately impacted by AI [9, 74, 119]. Reflexivity in participatory methods encourages transparency during the design process itself, as opposed to a detrimental “innovate first, fix later” approach to building trustworthy AI [48]. By establishing the value- laden nature of technologies, it can prevent personal biases, beliefs and values from seeping into AI systems unexamined.
To this end, we offer a case study analyzing Queer in AI, a grass- roots organization that aims to raise awareness of queer issues in AI/ML, foster a community of queer researchers and celebrate the work of queer scientists. Operating primarily as an online com- munity over Slack, the organization runs various programs and initiatives towards fulfilling its mission. We analyze and critique its principles, methodology, initiatives, and impact over the years as a case study of community-led participatory methods in AI.
Unfortunately, there are many challenges to incorporating par- ticipatory approaches across top-down structures, such as corpora- tions that operate within capitalism. Popular modes of participation within AI suffer from extractive and exploitative forms of commu- nity involvement or “participation washing” [112]. For example, a recent report [95] sheds light on how OpenAI used exploitative labor practices to make ChatGPT less toxic, subjecting Kenyan workers to psychologically distressing content1 without sufficient provision for mental health support. Gray and Suri [56] also uncov- ers many exploitative labor practices performed by minorities to power AI systems.
Our key contributions are:
We document salient forms of marginalization and oppres- sion that particularly affect queer people (§2).
We present the organizing principles and programs of Queer in AI (§3), including how they started, major changes, and qualitative and quantitative analyses of impacts (§4).
We analyze challenges and shortcomings of Queer in AI (§5). • We present an argument for conducting more and valuing AI ethics research that combines inquiry and praxis (§6).
More fundamentally, we question whether marginalized com- munities should engage in designing with the creators of harmful AI systems that prioritize profit over their safety. Even in projects where communities are involved, engagement is too often limited
Positionality Statement Most authors of this paper are formally trained as computer scientists, with some also having training in gender theory or related fields. All authors have informal training in queer studies through activism and advocacy. Our backgrounds
1This content included examples of sexual abuse, hate speech, violence, murder, child abuse, rape, animal abuse, torture and self-harm.


1885
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
Community Response
Core Principles
Hierarchy
Tensions and Challenges
Community-LedInitiatives
Outcomes
Equity
DecentralizedOrganizing
Trans-Inclusive PublishingAdvocacy
Accessibility
Workshops& Socials
Funding
Intersectionality
Inclusive ConferenceGuide
Inclusivity
Graduate School ApplicationFinancial Aid Program
Community
Role Models
Figure 1: Overview of Queer in AI’s core principles, community responses, programming outcomes, and tensions and challenges.
influence this work’s design, decisions, and development. We do our best to position our work in a global context, with authors from Asia, Europe, South Africa, South America, and North America.
The medical profession’s response to the HIV/AIDS crisis was fa- tally slow until pressured by heroic activism [110]; a medical field that had included and empowered queer people may have saved many queer lives. Similarly, the American Psychiatric Association classified homosexuality as a mental illness until 1973, greatly con- tributing to the stigmatization of queer people around the world, until queer activists pressured the group for change [38]. Recent ini- tiatives have inverted this dynamics, centering queer communities in descisions about mental healthcare [74].
2 MARGINALIZATION OF QUEER PEOPLE IN
STEM AND AI
Hegemonic forms of AI focus on classifying complex people and situations into narrow categories at the cost of context, and are often built to support surveillance, prediction, and control – de- signs which are fundamentally incompatible with queer identi- ties rooted in the freedom of being [71]. The framing and use of common AI systems that interact with gender are thus often prob- lematic, and inherently cisnormative and heteronormative, so that even well-meaning, purportedly inclusive AI projects are prone to “designing out” certain queer lives [59]. Documented harms across various AI applications are numerous, and sometimes life- threatening. These include physiognomic and phrenologic appli- cations such as computer vision to (falsely) infer gender and sexu- ality [4, 70, 72, 80, 107, 108, 118]. AI-enabled surveillance systems, in conjunction with surveillance of online spaces such as dating apps by states, corporations, and even individuals have outed queer people, compromising their privacy and safety [22, 61, 92, 94]. On- line spaces, especially social media platforms, have insufficient and poorly explained privacy and security tools, requiring com- munity education and adaptation to meet the needs of queer peo- ple [33, 54, 96]. Their moderation enables widespread censorship of queer words and identities [30, 43, 111, 113], while also sub- jecting queer communities to disproportionate online harassment and hate speech [97, 125]. Some of these harms can be traced to large language models (LLMs) trained on datasets containing hate speech and censored queer words, leading search systems to avoid queer content and content moderation systems to more often tag it as suspect [37, 55]. LLMs also overwhelmingly fail to account for non-binary genders and pronouns, contributing to erasure of these identities [17, 32].
One hurdle in understanding the marginalization of LGBTQIA+ people in STEM is a lack of demographic data on sexual orientation and gender identity [51]. The US’s National Science Foundation has delayed the collection of such data for years, despite the urging of queer scientists [76]. Taking matters into its own hands, Queer in AI administers an annual survey of its global community to uncover the demographics and challenges faced by queer researchers in AI (discussed in detail in Appendix §B). In Queer in AI’s 2021-22 community survey (𝑁 = 252), 74% of members reported a lack of role models and 77% reported a lack of community as obstacles in their journey of becoming an AI practitioner.
There is a dire lack of studies and data on queer scientists’ ex- periences in the Global South, where colonial histories have led to the criminalization of queerness [1–3]. Queer in AI organizers from Turkey, Colombia, and India have shared that much queer activism in these countries focuses on survival and gaining basic human rights, recognition and respect in society, amid high levels of discrimination, violence, and psychological distress [23]. They perceive being out and working towards queer visibility in STEM fields to be beyond luxuries, especially given the dominant (cisnor- mative, heteronormative) view that identity and profession should be “kept separate.” Barriers to acceptance are only amplified for queer individuals also marginalized on intersecting axes like class or caste.
3 CORE PRINCIPLES OF QUEER IN AI Three governing principles drive Queer in AI’s mission to raise awareness of queer issues in AI and foster a community of queer researchers: (i) decentralized organizing, (ii) intersectionality, and (iii) community-led initiatives. Overall, Queer in AI’s decentralized operations allow for swift community-led initiatives towards its mission (§3.1), which center on intersectionality as critical inquiry and praxis (§3.2). In doing so, it acknowledges and continuously works to account for “the complexities of multiple, competing, fluid, and intersecting identities” [58]. Queer in AI’s primary approach
In the US, queer people are (at least) 20% less represented in STEM than in the national population, and experience higher lev- els of “career limitations, harassment, and professional devalua- tion” [19]. Consequently, queer scientists often face “systematically more negative workplace experiences than their non-LGBT col- leagues” [20], and “leave STEM at an alarming rate” [51]. The exclusion of queer people from science comes with significant consequences, both for queer scientists and queer people further marginalized by fields that do not understand or care about them.


1886
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
consists of including people with diverse lived experiences in par- ticipatory schemes (§3.3).
oppression, Queer in AI attempts to empower its most marginalized members to shape and control its programming, addressing key challenges of participatory design such as the exclusion of marginal- ized people from participation [69], community power-sharing [27] and the co-formation of knowledge [45]. In doing so, Queer in AI works towards a system of resistant knowledge firmly grounded in intersectionality’s critical praxis [25, Chs. 3 & 4].
3.1 Participation and Decentralization For its first two years, Queer in AI had a hierarchical structure, with a president and officers. However, organizing and governance of grassroots communities, and especially queer communities, presents unique challenges. Queer people are incredibly diverse, and choosing one or even a group of queer people to represent the community as a whole is reductive and impossible. This is also difficult for the organizers, with high-profile queer activists and organizers frequently facing targeted harassment campaigns, and Queer in AI organizers frequently reporting lack of time, external support, or recognition for volunteering (cf. Figure A16). Queer in AI thus adopted a decentralized organizing structure, to encourage broad participation. Queer in AI minimizes distinctions between organizers and members to encourage the entire community to participate in organizing. Most volunteer coordination occurs in the same Slack channel as is used for community discussion, calls for help or feedback on programs mixed with memes, introductions, personal news, and discussions of travel or pets. Of the 49 active Slack channels only 4, where personally identifiable information is discussed, are not public. Openness and embedding in the community increase transparency and accountability: any community member can view organizing discussions and join in, with no more barrier to entry than joining a Slack channel. It also helps provide the connection and joy for which 75% of its organizers joined Queer in AI (cf. Figure A15). Fluidity between member and organizer also makes it easier for community members’ areas and levels of engagement to ebb and flow over time without losing their connection to the community.
3.3 Participation and Community Leadership 3.3.1 Research. Various forms of community-engaged research guide the dissemination of knowledge both within and outside of Queer in AI and exist across a continuum, from community- informed to community-involved to community-led. Community- informed research consists of researchers inviting the community to incorporate lived experience to guide research questions, data collection, or data interpretation [60]. Towards more community- involved research, community members may be more involved in decision-making processes and research planning [60, 105]. At the highest level of engagement, community-driven approaches such as community-based participatory action research (PAR) cen- ters shared collaborative decision-making between researchers and community members across research design, knowledge creation, intervention development, and policy-making [28, 82, 126]. In prac- tice, entities outside of the organization may partner with Queer in AI community members to form relationships designed to help objectives oriented towards investigating and supporting “the pur- suit of answers to the questions of their daily struggle and survival” [121]. Individuals are often members of both other entities as well as of Queer in AI so that members may operate from the role of an external entity (e.g. researcher from a company) and at vari- ous depths of community engagement. The resulting knowledge production is such that is “by the people, for the people” in which research is not only seen as a process to create knowledge but to also educate and mobilize for action [28, 57]. By “putting com- munity first”, the distinction between participant and researcher is removed. Community-based participatory action research thus also serves as a decolonizing epistemological framework which inherently interrogates power and privilege [46].
3.2 Participation and Intersectionality Over five years, Queer in AI’s community has grown to about 870 members, geographically distributed across more than 47 coun- tries (cf. Figure 2). The community members have diverse identities across axes such as ethnicity, gender, class, disability, and caste. About 20.3% of respondents identified as transgender, and 34.4% identified as non-cisgender; 34.9% identified as Black, Latinx, in- digenous or a person of color; less than 2% identified as intersex. Membership spans academia and industry, with about 16% of mem- bers pursuing an undergraduate degree, 21% in an industry role, and 64% in academia, all with varying degrees of seniority (cf. Ap- pendix §B.6 for additional details of community demographics). As a result, Queer in AI helps naturally bridge otherwise insular aisles of power and social contexts.
3.3.2 Response & resilience. Within Queer in AI, community re- silience operates across dimensions including but not limited to the social, political, and economic. Advocacy efforts operate across do- mains, tasks, resources, and activities within the organization [75]. Resources and activities are structural means towards tasks and domains that reflect the Queer in AI mission. Specifically, resources and activities are dedicated to raising awareness of queer issues in AI/ML. Financial, educational, and social avenues are created within the organization as a form of creating resilience and advocacy in the face of oppressive sociotechnical barriers. Operating across 47 countries, Queer in AI primarily organizes through Slack, Zoom, a dedicated mailing list, and social media platforms. Doing so makes room for rapid and adaptive situational awareness within the online community [117]. Besides the “internal” milieu of an organization, Queer in AI is responsive to events in both reactive and proactive forms. Digital volunteer efforts emerge as self-organizing responses to external factors [24, 42]. This work further details examples of
As the queer community consistently experiences discrimina- tion, stigmatization, and inequity [18, 87], Queer in AI uses the lens of intersectionality as a means of critical inquiry to identify how interlocking forms of oppression, such as racism and sexism, co-construct and exacerbate social and structural disparities [26]. To proactively dismantle injustices, Queer in AI centers the experi- ences of its members so that active participation in the Queer in AI community results in the co-creation of initiatives, which reflect of tackling such barriers, including economic (§5.3), educational (§4.1), and social (§4.2) ones. By prioritizing fighting intersectional


1887
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
Figure 2: Country of origin of the respondents to the Queer in AI’s 2021–2022 demographic survey.
Table 1: Self-reported ethnicity, gender, and sexual orientation of the respondents to the Queer in AI’s 2021–2022 demographic survey. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories (cf. Figure A4). “Unaggregated” refers to responses that could not be adequately described with any subset of other categories; however, responses in this group may overlap with the remaining categories. For options with fewer than 4 responses, exact values are omitted for privacy.
Ethnicity
Sexual Orientation
Gender
Queer Gay Bisexual Pansexual Lesbian Asexual Unaggregated
108 95 61 29 22 19 17 16 16
Man Woman Non-binary Genderqueer Gender non-conforming Genderfluid Agender Questioning Unaggregated
127 34 17 13 13 12 8 8 6 ≤ 3 ≤ 3 ≤ 3 6
90 89 87 42 30 26 29
Caucasian South Asian East Asian Black/African/African-American Latinx Mixed Jewish Middle Eastern Southeast Asian West Asian Central Asian Hispanic Unaggregated
Many of Queer in AI’s initiatives have emerged from conversa- tions and threads on public channels about discriminatory experi- ences with different institutions. For example, discussion around exclusionary gender collection practices on conference registration forms led to the creation of an inclusive conference guide (covered in more detail in §4.3) and substantial improvements to relevant conferences’ practices. Similarly, significant advocacy against dead- naming in citations and conference proceedings (§4.4) began from discourse on public channels. Thus, as a space, Queer in AI’s Slack is effective at mobilizing community-led initiatives through decentral- ized organizing. Moreover, the emergence of these initiatives from diverse yet intersecting shared queer experiences grounds them in global contexts of social inequality and injustice. For instance, Queer in AI’s graduate school application financial aid program (§4.1) and workshops and socials (§4.2) target several particular challenges rooted in non-Western contexts, centering otherwise- marginalized experiences. The organizational and volunteer work that constitutes the administration of all these initiatives is thus deeply intersectional.
how responses to acute external factors and larger efforts against oppression manifest as Queer in AI initiatives.
4 QUEER IN AI INITIATIVES The structure of Queer in AI is decentralized and includes volun- teers, core organizers (extensive organizing experience with Queer in AI) and a diversity, equity and inclusion admin (DEIA, a core organizer who has a more active role in administrative duties). Most of Queer in AI’s communication is mediated by its Slack workspace. A key aspect of Queer in AI’s organizing lies in the transparency of its operations and associated information exchanges, which pre- dominantly take place over public Slack channels. There are only four private channels on the workspace, which exist to preserve privacy while facilitating discussions around personally identifi- able information. The workspace has included the exchange of over 133,000 messages (including individuals’ one-to-one private messages), of which over 25,000 have been sent in public channels, accounting for the majority (57%) of total views. This transparency, in conjunction with regular updates and outreach on Slack, keeps community members involved in ongoing events and initiatives.


1888
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
of experiences with graduate school admissions [114]. This initia- tive keeps minimum barriers to receiving the aid by not seeking to decide who is “deserving” of aid, avoiding imposing excessive requirements for documenting eligibility and providing timely men- torship and help to the applicants for their submissions. Although, the payment pipeline often disadvantages applicants from coun- tries and territories where PayPal is not available or restrictions are imposed on receiving transfers from the US.
We now examine four major initiatives in detail; Appendix §C
further describes efforts in policy advocacy.
4.1 Graduate School Application Financial Aid
Program
Queer folks report a lack of community and queer role models due to the underrepresentation of senior queer folks in academia. Thus, supporting queer and low-income scholars financially helps bring more marginalized voices into STEM academia, creating more op- portunities for participatory research and technology design. To address this, Queer in AI launched the Graduate School Applica- tion Fee Aid Program to improve queer representation and make graduate programs accessible.
4.1.3 Participatory learnings. Each aid applicant is treated as a member of the community with a valuable perspective of their own – the initiative actively seeks feedback from aid recipients and encourages them to volunteer in the future, which would both help improve the program and keep it sustainable. This feedback indicated that aid recipients’ demographics were more diverse than Queer in AI’s organizing team (Table 3), which helps Queer in AI recruit more diverse volunteers and community members by first directly, meaningfully helping them. Also, the feedback survey il- lustrates widespread deficiencies in existing admissions fee waivers: such as lack of fee waivers (67%), unable to produce adequate docu- mentation (14%) and the fear of outing themselves (10%). This aid program allowed recipients to take admissions tests (56%), avoid skipping essential expenses (54%) and avoid skipping groceries or bills (40%). The vast majority of recipients reported the scholar- ship enabled them to apply to additional programs (around 6 on average).
Financial challenges. The costs for graduate school applica- 4.1.1 tions prevent many low-income and international scientists from accessing graduate programs, well before they can benefit from many of the fellowships and need-based scholarships intended to address exclusion. This process is costly: between the application fees (∼$50–$150 USD per program in North America and parts of Europe), costs of required tests (e.g. GRE), test results and tran- script delivery fees, and test preparation expenses, one round of applications can easily amount to over $1,000 USD. International applicants may be further required to pay for language proficiency tests (e.g. TOEFL), translation services, and third-party credential vetting. Although some schools offer fee waivers, they vary widely from school to school, are often very limited in applicability, and can require onerous documentation.
4.1.4 Critical Reflections. The program operates with a tension between opening opportunities to marginalized people from all over the world and reinforcing the exclusionary practices of these powerful institutions. In addition to funding influential and rich academic institutions, the program also indirectly supports the standardized testing industry. The limited amount of funds and barriers to sending the money internationally often pose challenges between the organizers and the aid recipients. In spite of that, Queer in AI believes that it is crucial to provide timely aid regardless of these barriers, even if doing so reinforces undesirable structures.
The majority of applicants apply to North American schools. This is likely caused by the cultural dominance of Anglo-American schools in the AI/ML space and the common practice of requiring extensive standardized tests and application fees at these schools.2 Standardized tests like the GRE claim to level the playing field for applicants, they institute barriers to individuals from the Global South and reify colonialism under a veneer of fairness. Addition- ally, fees make these exams wholly inaccessible to many in the Global South: the GRE costs three times the average monthly salary in Ethiopia [11]. Data collected from Queer in AI’s surveys have been used to argue that departments should eliminate the GRE and application fees.
4.2 Workshops and Socials In STEM disciplines, conferences can be a hostile setting for minori- tized groups [85, 104, 134]. Queer in AI members in 2022 rated how welcome they felt attending AI conferences at 3.38 on average (𝜇1/2 = 3) on a five-point Likert scale (cf. Appendix § B). Recognizing this need, Queer in AI has organized workshops and networking events since its very first informal meetup at NeurIPS 2017: as of submission, 13 workshops and 35 social events in total (Table 4), with a cumulative attendance of hundreds of participants.3 These events provide an opportunity to connect and network with other queer scientists, spotlight work by members of Queer in AI, host talks on topics relevant to its members, and arrange panels where experts discuss topics at the intersection of AI, fairness, ethics, and the queer community. The following subsections cover how Queer in AI’s principles influence event planning and enable them to overcome challenges in the process.
These financial challenges are particularly likely to be insur- mountable for queer scientists, who may be cut off from familial financial support, might pay out of pocket for gender-affirming healthcare, and often incur additional expenses managing oppres- sion and trauma. Queer people thus suffer from increased student loan debt [83] and high rates of housing insecurity [131]. A com- plete critique of the graduate application process and its socio- economical context is out of the scope of this paper. Queer in AI believes it is nonetheless important to provide concrete aid right now to applicants faced with the current system.
4.1.2 Mutual aid design. The design of the aid program is decentral- ized, community-led constituting volunteers with a diverse range
2While fees and standardized tests are the norms at many prominent institutions, there are examples of alternative paths, such as the ELLIS PhD Program, a European initiative for AI/ML PhD programs, which requires neither [44].
3An exact count could not be obtained: to maintain attendees’ privacy, Queer in AI does not require signups for most events, and deletes names immediately after events when they are required.


1889
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
Table 2: The Queer in AI Graduate School Application Fee Aid Program budget and impact per academic year, in USD.
Aid per applicant
Budget
No. aid recipients
Academic year
Total aid
$16,689 $70,607 $40,476
31 81 48
$20,000 $73,768 $41,711
up to $750 up to $1,250 up to $1,250
2020/2021 2021/2022 2022/2023 (at time of writing)
Table 3: Gender, sexual orientation, romantic orientation and continent of scholarship recipients who filled the optional feedback survey (𝑛 = 46 out of 𝑁 = 160 total recipients). For options with fewer than 4 responses, exact values are omitted for privacy.
Sexual Orientation
Continent
Gender
Romantic Orientation
20 18 7 6 6 ≤3 ≤3 ≤3
Homoromantic Biromantic Demiromantic Grayromatic Alloromantic Aromantic Heteroromantic
21 13 5 5 ≤3 ≤3 ≤3
Asia North America Africa Europe South America
19 14 5 ≤3 ≤3
Woman Man Genderqueer Non-binary Gender non-conforming Agender Genderfluid Questioning
18 16 12 9 4 4 ≤3 ≤3
Gay Queer Bisexual Lesbian Asexual Pansexual Demisexual Questioning
Table 4: Workshop and events organized by Queer in AI in 2017–2022 across conferences in AI. Events marked with p were held in person, v indicates virtual-only events, and h refers to events that occurred in a “hybrid” format.
2019
2018
Year
2017
2021
2022
2020
5 FAccTh ‡ ICLRv ICMLh NAACLh NeurIPSh
1 NeurIPSp
3 EMNLPv † ICMLv NeurIPSv
2 ICMLp NeurIPSp
2 NeurIPSv ICMLv
Workshops

10 AAAIv ACLv CoRLv EACLv EMNLPv ICLRv ICMLv NAACLv NeurIPSv SIGIRv
11 AAAIp AACLv ACLv CogSciv COLINGv CORLv EMNLPv FAccTp ICLRv ICMLv NeurIPSv
7 AAAIv AAMASv ACLh ICLRv ICMLh NAACLh NeurIPSh
5 ACLp CVPRp ICMLp NAACLp NeurIPSp
1 NeurIPSp
1 NeurIPSp
Social Events
† at EMNLP 2021, Queer in AI co-hosted a workshop with WiNLP. ‡ at FAccT, Queer in AI hosted two CRAFT sessions.
and speaker ideas from community workspace. This approach has allowed Queer in AI to host panels and talks on intersectional topics that often do not have a presence at major AI/ML venues (for just one example, a discussion on the intersection of queerness, caste and AI at NeurIPS 2021 [99]). Queer in AI organizers spend tremen- dous effort by making the workshops as inclusive as possible by providing fair honoraria to the speakers and organizing the events in online, hybrid, and in-person settings.
4.2.1 Workshop Organizing. Queer in AI workshops and socials are typically organized by members of the community planning to attend the conference; no prior academic or organizing expe- rience is required. Junior or new members of the community are often encouraged to lead these initiatives while being mentored by more experienced organizers throughout the process. Organizers, DEIAs, and Queer in AI’s financial stewards coordinate to secure logistical, monetary and other miscellaneous needs of the event. These include renting equipment to support accessibility, honoraria for speakers, scholarships for attendees, refreshments for socials, online outreach and promotion of the event, and so on. All of this communication takes place asynchronously over Slack, or in Zoom meetings scheduled across organizers’ time zones. This decentral- ized approach also helps enable Queer in AI members spanning different sub-fields in AI to tailor events to represent and serve the needs of their sub-community. When prompted to rate how welcome they felt at these workshops, the response was overwhelm- ingly positive, with about 47% of queer attendees rating it five out of five on a Likert scale (𝜇=4.16, 𝜇1/2=4) (cf. Appendix § B6).
4.2.3 Barriers and Challenges in Participation. AI conferences are often not accessible for a sizable portion of queer researchers, espe- cially those belonging to other marginalized backgrounds or from countries with lower purchasing power or higher rates of discrimi- nation towards queer people [127]. Primary reasons includes high registration and travel costs. Out of all Queer in AI members who reported being unable to attend conferences owing to lack of fund- ing, 88% identified as one of black, indigenous, person of color, transgender, neurodivergent, or disabled (cf. Appendix § B6). While Queer in AI tries to work with conference organizers to use DEI funds for increasing the attendance of queer scientists, in many cases conference organizers refuse to engage with Queer in AI’s requests. Queer in AI thus often provides a combination of travel grants, registration waivers, and reimbursement for conference- related expenses to queer AI researchers. In other cases, unofficial
4.2.2 Panels and Talks at Workshops. Panels and talks at Queer in AI are crucial as they help in amplifying queer voices and concerns in our field. Many topics presented in the panels and keynotes have later served a bigger impact in the AI field, such as talks on confer- ence inclusivity and name change policies. Queer in AI encourages a participatory approach to workshop design: by soliciting topics


1890
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
social events4 near the conference venue and online virtual so- cials on gather.town are organized to accommodate excluded time zones and overcome both financial and geographical access barriers. Other barriers specific to the conference location, such as unsafe legal and social climates 5 for queer people or exclusionary visa processes, continue to significantly limit queer participation within AI spaces. Finally, for conferences which are poorly equipped in their support for disabled people, Queer in AI provides live captions for all in-person and virtual events, and secures equipment to create accessible spaces.
and sexuality of attendees only for statistical purposes and in anonymized form); and (iii) ensure that mechanisms to report disruptive or harmful behaviours are swift and effective. Queer in AI recommends adopting a code of conduct (e.g., [100, 132]) to not only establish communication norms, but also describe how policy violations are handled [39].
Increasing Queer Representation and Participation: Queer re- 4.3.2 searchers’ needs are regularly ignored in many aspects of the re- search community: challenges include lack of academic support, hostility from colleagues and advisors, inflexible name change poli- cies, lack of representation in the research itself, and more [21]. Stronger inclusion efforts, both for representation and participa- tion, can work towards addressing a lack of queer community and role models [109]. To increase representation, Queer in AI strongly encourages conference organizers to invite queer keynote speakers and panelists, prioritizing those from marginalized backgrounds (e.g., BIPOC or non-cisgender) [40]. Queer in AI recommends fair and equal compensation based on effort rather than seniority for all speakers [52, 103]. As noted in previous sections, financial acces- sibility and a lack of community were the main barriers for queer folks to feel included at conferences. Queer in AI strongly advocates setting up spaces for queer folks to network and socialize with pri- vacy measures and also providing subsidies for queer researchers to attend virtual or in-person events.
4.3 Advocacy for Improving Queer Inclusivity
in Conferences
As conferences moved online in response to the COVID-19 pan- demic, Queer in AI organizers noted a series of operational failures that could cause queer attendees to feel unsafe or unwelcome. Regis- tration platforms demanded attendees to provide their legal names, thus potentially deadnaming them; the use of pronoun badges for speakers and attendees was rarely encouraged, or platforms did not support displaying pronouns; virtual chat software blocked common queer terms such as “queer” or “lesbian”, thus preventing queer attendees from communicating freely. Queer in AI organizers worked closely with many conferences to resolve these issues, as they had in prior settings (§4.2), and ultimately decided to collect recommendations aimed at highlighting best practices to ensure safety, privacy, and accessibility for queer attendees at academic conferences in AI in a collected guidance document.6
4.3.3 Critical Reflection. This guide and advocacy are not without their limitations. Most recommendations are still focused on vir- tual spaces and currently written guide lacks in-depth accessibility recommendations. Queer in AI needs to collaborate with disabled folks with a wider range of disabilities to document best practices regarding accessibility accommodations. Most significantly, despite organizers’ efforts the guide has seen relatively modest adoption.
These recommendations began based on existing best practices and experience with conference organizers, but were refined through extensive iterative feedback from members of Queer in AI and other affinity groups, incorporating many opinions and ultimately achieving consensus among a broad group of contribu- tors. The guide has recently been expanded to also cover in-person events as conferences move to hybrid or in-person formats. This queer advocacy to improve inclusivity covers two aspects: improving queer safety and increasing queer representation.
4.4 Trans-inclusive Publishing Advocacy For many transgender, non-binary, and gender-diverse scholars (as well as others), the continued circulation of a previous name in publishing is a significant source of trauma [122]. Referring to an author by a previous name without consent (deadnaming) may effectively out their identity against their will. Queer in AI has worked along with the Name Change Policy Working Group [89] to advocate name change policies in AI venues, helping to establish the name-change policies and procedures now adopted by most AI-related venues [5, 6, 14, 15, 62, 78, 90, 123] (cf. Appendix § C for more about Queer in AI’s advocacy and impact).
Improving Queer Safety: As in any public space, queer 4.3.1 conference-goers might face discrimination based on their gender and sexual orientation. Therefore, it is paramount for attendees to be able to control what information they wish to disclose to the organizers and attendees of a conference. Queer in AI advocates mechanisms to (i) respect attendees’ identities by collecting gender and pronoun information in a manner that does not misrepresent or erase queer identities, by creating forms with inclusive gender categories and disclosing the data usage [106] (ii) minimize the amount of personal information queer individuals have to disclose [7] (for example, only collecting legal names when absolutely necessary, and using responses about the gender
Even publishers with functional name change policies are often woefully slow to implement them, and search engines can index outdated information long after its correction [115, 116]; moreover, authors often use outdated bibliographic entries long after relevant publications and search tools have been updated [120]. It is thus vital to check the correctness of citations in submitted papers to avoid propagating incorrect information. QueerInAI has thus devel- oped a tool to check paper PDFs for mistaken citations. It searches the ACL Anthology, DBLP, and arXiv for a close paper title match, and prompts a correction if the paper’s author list disagrees with that source, detecting both deadnaming and incomplete or outdated
4These events are not officially included within the conference program but promoted over Queer in AI’s Slack and mailing list as well as social media. A recent example is AAAI 2023 where the conference fees was exorbitantly high and negligible effort was put into provision for registration waivers. 5EMNLP 2022 (in Abu Dhabi) predatorily included Queer in AI to obtain their approval for conference safety measures; Queer in AI rejected this, due to the conference operating at a different domain of power for trans people and the power inherent in speaking for the entire queer community. 6The guide, originally published as [101], queerinai.com/how-to-make-virtual-conferences-queer-friendly.
is a living document available at


1891
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
author lists. DBLP in particular provides better name change sup- port than many other platforms, via ORCID [93]. This toolkit has been integrated into ACL publication camera-ready systems [98], and Queer in AI hopes to expand it to other conferences. A demo is available at qinai-name-check.streamlit.app.
resources required to even connect with Queer in AI. Second, while Queer in AI strives to be intersectional, it severely lacks access to queer networks in countries from the Global South. It originated and primarily operated within a Western context during its initial years, which led to the inadvertent creation of barriers that limit its outreach. For example, because Queer in AI organizers are best connected with US and European institutions, its events are often co-located at conferences attended mainly by scientists residing in the Global North. Further, its meetings often occur at times best aligned with European and American time zones, at the expense of much of Asia. Finally, all Queer in AI activities require English proficiency.
Additionally, Queer in AI advocates publishers to promptly grant name correction requests in any format, without unnecessary bar- riers or documentation requirements. Such changes should remove all instances of authors’ previous names from all records, or (at the author’s discretion) add disclaimers for media that cannot be updated (e.g., audio or video recordings). As the result of this ad- vocacy, Queer in AI has helped institute effective name-change processes at NAACL and EMNLP; and has worked with the Asso- ciation for Computational Linguistics [49] to implement a name change process, proactive measures to prevent the deadnaming of trans authors, and protocols to handle authors’ requests to keep their videos private.
While recent community and focused outreach efforts have re- duced some of these barriers, significant work lies ahead in estab- lishing truly global ways of participation, especially for countries where queerness is criminalized. Third, participation in Queer in AI exerts a toll on mental health and exhaustion of its organizers (cf. Figure A16). This is partly due to Queer in AI’s lack of formal structure, instead relying on individuals self-coordinating on initia- tives of their choice. While efficient, this approach can make joining and keeping track of ongoing efforts challenging for newcomers and neurodivergent members of the community. Past organizers have also shared anecdotes of experiencing exhaustion, fatigue, and anxiety due to a lack of accommodation of different working styles and falling behind on personal schedules while undertaking opera- tional work for Queer in AI (cf. Figure A16). This disproportionately impacts disabled and neurodivergent members and is compounded for intersecting marginalized identities.
5 TENSIONS AND CHALLENGES As reflexivity is a core tenet of intersectionality [25], this section critically examines the tensions and challenges that emerge in the operationalization of Queer in AI’s principles within its initiatives. From the issues with Queer in AI initiaitves discussed in the pre- vious section, we find three common, root themes of hierarchy, accessibility, and funding. We argue that these are not only criti- cal challenges for Queer in AI, but deep challengesany participatory or community-lead AI organization must address to be successful.
Even after years of critical reflection and significant investment of volunteer time, money, and other resources, Queer in AI is still inaccessible to many. While accessibility to everyone should always be the goal, in practice, no single community or participatory initia- tive will be able to include everyone in that community. Therefore, participatory researchers aspiring to broad inclusion should con- sider the pluralities of communities and participatory initiatives with radically different structures.
5.1 Hierarchy Decentralized organizing plays a vital role in minimizing power distance and distinctions between members of Queer in AI. Even so, there are notable distinctions between members who participate in organizing, core organizers, and the DEIAs as paid contractors. Queer in AI’s core organizers and DEIAs help sustain the growth of the organization through mentorship of new volunteers and institu- tional memory. In addition, they form a relatively large and diverse group for deliberating on rare decisons that cannot be discussed openly, such as those involving PII. Their existence does, however, pose challenges in accessibility for people unfamiliar with navi- gating unstructured social networks, and can be non-transparent to newer or less involved members. The core organizers also as- sume a more active role, sharing considerable power in steering the direction of its initiatives. Queer in AI helps address these ten- sions by setting a fixed one-year tenure for DEIAs, and inducting organizers who have been active throughout the preceding year as core organizers. Resolving tensions between decentralization and hierarchies created by knowledge and experience, or forced by privacy concerns, nonetheless remains an open problem within Queer in AI.
5.3 Funding Funding and payments are where Queer in AI struggles most to meet its commitments to decentralization, intersectionality, and community leadership. Queer in AI relies on sponsorships, dona- tions, and contributions from its parent organization oSTEM to fund its activities. In 2022, Queer in AI expenses (rounded to the closest integer) totaled US$100,658: the graduate application fee scholar- ship program (§4.1) spent $40,435; two DEIA contractors were paid a total of $33,220; speaker honoraria totaled $14,500; $6,941 went to travel grants, room and board, and conference registration fees; emergency microgrants for queer people totaled $5,000. Income comprised $78,000 in corporate sponsorship, $13,711 in donations, and $5,000 in grant revenue (cf. Appendix §B.9 provides income and expenses for previous years.).
5.2 Accessibility Despite global participation, Queer in AI’s structure and opera- tional design can discourage participation for many queer scien- tists. First, participation in a volunteer-run community not only requires organizers to have income that allows them to perform free labor but also have access to computers, internet, and other
Queer in AI’s reliance on corporate sponsorship may call into question its independence and community-lead ideal. Corporate sponsors receive access to opt-in resume books, short speaking opportunities, and event recruiting booths. A large part of Queer


1892
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
in AI’s funding still comes from big tech corporations that are com- plicit in oppression and genocide globally, such as the policing of Palestinians. Queer in AI has nonetheless dropped and turned down many sponsors for ethics concerns, including a mutual decision with Black in AI in 2021 to drop Google [65], costing $20,000 in lost sponsorship per year. While Queer in AI has been growing donations, many in the Queer in AI community are students or early in their careers with very limited capacity to give. Oppor- tunities for grants are limited, as many scientific funding bodies such as the US’s NSF exclude queer people from many of their D&I initiatives [50].
onto finance & sponsorships and workshops. Queer in AI addition- ally plans to supplement its 2023 community survey with commu- nity interviews about accessibility, towards gleaning actionable insights about mitigating barriers to participation. Furthermore, Queer in AI’s organizers will work with its community to refine its sponsorship policies and identify less precarious mechanisms for transferring funds. All of these activities are motivated and will be guided by our core principles of decentralization, intersectionality, and centering community. Queer in AI will further communicate its activities and their implications for equity and inclusivity via accessible media, e.g., blog posts, zines.
Queer in AI sends honoraria, scholarships, and travel grants to people in many different countries, primarily through PayPal and wires. Payment disbursal in Queer in AI is highly centralized; for reasons of security oSTEM only allows one Queer in AI organizer to send PayPal payments. All wires and credit card payments must be sent by the oSTEM CEO. Additionally, payments strain Queer in AI’s intersectional values. PayPal does not work well in China, In- dia, many countries in Africa, and some countries in South America, forcing reliance on slower and more administratively difficult wire transfers. Moreover, U.S. law requires people receiving honoraria and other types of payments to pay US taxes above a certain thresh- old, which requires a lengthy registration process or significant fees and overhead from Queer in AI. Payments also frequently trigger spurious fraud alerts and investigations, which require even more time from and stress on organizers.
ACKNOWLEDGMENTS This work would not have been possible without the activism and organizing efforts of the Queer in AI community. We would also like to thank Katta Spiel and Os Keyes for their insightful feedback on the earlier versions of the paper.
REFERENCES
[1] 2015.
Some African Countries Are Trying to Use Science to Make Homophobic Laws, Now African Scientists are Pushing Back. https://www.smithsonianmag.com/smart-news/africans-scientists-speak-out- against-homophobic-laws-180955579/
https://
[2] 2020. A constant uneasy state: Trans people in STEM in India. thelifeofscience.com/2020/11/09/transgender-people-in-science/
[3] 2022. Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro re- election. https://www.washingtonblade.com/2022/05/19/brazil-lgbtq-activists- hiv-aids-service-providers-fear-bolsonaro-reelection/
In summary, marginalization prefigures Queer in AI’s funding options, legal and security concerns exert a strong centralizing pres- sure on financial administration, and the financial system regards many payments, especially to non-Western countries and those making them, with suspicion by default.
[4] Blaise Agüera y Arcas, Margaret Mitchell, and Alexander Todorov. 2017. Phys- iognomy’s New Clothes. https://medium.com/@blaisea/physiognomys-new- clothes-f2d4b59fdd6a
[5] ACL Anthology. (n.d.). Requesting Corrections. https://aclanthology.org/info/
corrections/ [Accessed Feb 2023].
[6] arXiv. 2021. arXiv Proceedings: Name Change Policy. https://blog.arxiv.org/
2021/03/11/update-name-change-policy, Name Change Policy blog.
[7] Alison Barclay and Melissa Russell. 2017. A guide to LGBTIQ-inclusive data collection. https://meridianact.org.au. https://meridianact.org.au/wp-content/ uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf
6 CONCLUSION Participatory methods have the potential to address issues of power and inclusion in AI, but their benefits and challenges in practice are still unclear because few organizations have deeply engaged with them. In this paper we studied Queer in AI as a case study of a grassroots participatory AI organization. We explored how they designed their organization to enable participation, and how initiatives addressing intersectional marginalization arose from and were continuously refined by this participation. We theorized how Queer in AI’s numerous socials, workshops, and other events have contributed to a culture of participation in AI by bringing queer people into AI conferences and research and industry settings and resisting predatory inclusion. We hope this case study will inform theoretical study and practical design of participatory initiatives. In particular, we encourage consideration of Queer in AI’s reinforcing principles of decentralization, community leadership, and focus on intersectionality, and urge care for mitigating the ways hierarchy, inaccessability, and funding can subvert participatory methods.
[8] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. 610–623.
[9] Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to the People? Opportunities and Challenges for Participatory AI. In Equity and Access in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO ’22). Association for Computing Machinery, New York, NY, USA, Article 6, 8 pages. https://doi.org/10.1145/3551624.3555290
[10] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. 2021. Mul- timodal datasets: misogyny, pornography, and malignant stereotypes. arXiv (2021). https://arxiv.org/abs/2110.01963
[11] Black in AI. 2020. Academic Program. https://blackinai.github.io/#/programs/
academic-program
[12] Black in AI (n.d.). https://blackinai.github.io [13] Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020. Lan- guage (Technology) is Power: A Critical Survey of “Bias” in NLP. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguis- tics. Association for Computational Linguistics, Online, 5454–5476. https: //doi.org/10.18653/v1/2020.acl-main.485
[14] ACM Publications Board. 2019. ACM Publications Policy on Author Name
Changes. https://www.acm.org/publications/policies/author-name-changes
[15] Melisa Bok. 2022. Comment on issue: Transphobic name and email policy. https:
6.1 Future Directions Queer in AI will continue to grapple with the tensions and alleviate the challenges addressed in §5. To dismantle hierarchies among organizers created by knowledge, experienced Queer in AI orga- nizers will host structured trainings to onboard new organizers
//github.com/openreview/openreview/issues/28#issuecomment-1124245541
[16] Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam Tauman Kalai. 2016. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings. Advances in Neural Information Processing Systems 29 (2016).
[17] Yang Trista Cao and Hal Daumé III. 2020. Toward Gender-Inclusive Coreference Resolution. In Proceedings of the 58th Annual Meeting of the Association for


1893
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
Computational Linguistics. Association for Computational Linguistics, Online, 4568–4595. https://doi.org/10.18653/v1/2020.acl-main.418
2021#h.lx7wo16mt2ax
[44] ELLIS. 2022. ELLIS PhD Program: Call for applications 2022. https://ellis.eu/
[18] Logan S Casey, Sari L Reisner, Mary G Findling, Robert J Blendon, John M Benson, Justin M Sayde, and Carolyn Miller. 2019. Discrimination in the United States: Experiences of lesbian, gay, bisexual, transgender, and queer Americans. Health services research 54 (2019), 1454–1466.
news/ellis-phd-program-call-for-applications-2022
[45] Myra Marx Ferree. 2016. The discursive politics of feminist intersectionality. In
Framing Intersectionality. Routledge, 55–65.
[46] Michelle Fine and María Elena Torre. 2006. Intimate details: Participatory action
research in prison. Action Research 4, 3 (2006), 253–269.
[19] EA Cech and TJ Waidzunas. 2021. Systemic inequalities for LGBTQ professionals
[47] Aoife Finn, Peter-Lucas Jones, Keoni Mahelona, Suzanne Duncan, and Gianna Leoni. 2022. Developing a Part-Of-Speech tagger for te reo M¯aori. In Proceedings of the Fifth Workshop on the Use of Computational Methods in the Study of Endangered Languages. 93–98.
in STEM. Science advances 7, 3 (2021), eabe0933.
[20] Erin A. Cech and Michelle Pham. 2017. Queer in STEM Organizations: Work- place Disadvantages for LGBT Employees in STEM Related Federal Agencies. The Social Sciences 6 (2017), 12.
[48] Luciano Floridi. 2019. Establishing the rules for building trustworthy AI. Nature
[21] Erin A. Cech and Michelle V. Pham. 2017. Queer in STEM Organizations: Work- place Disadvantages for LGBT Employees in STEM Related Federal Agencies. Social Sciences 6, 1 (2017). https://doi.org/10.3390/socsci6010012
Machine Intelligence 1, 6 (2019), 261–262.
[49] Association for Computational Linguistics. (n.d.). https://www.aclweb.org/ [50] Jon Freeman. 2023. Letter to the NSF Director. https://static1.squarespace.
[22] Pia Ceres. 2022. Kids are back in classrooms and laptops are still spying on them. Wired (Aug 2022). https://www.wired.com/story/student-monitoring- software-privacy-in-schools/
com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/ 1674078140137/Letter+to+NSF+Director+-+LGBTQ%2B+Data_redacted.pdf
[51] Jonathan B. Freeman. 2020. Measuring and Resolving LGBTQ Disparities in STEM. Policy Insights from the Behavioral and Brain Sciences 7 (2020), 141 – 148. [52] Paolo Gaudiano. 2021. Exposure doesn’t pay: Why tech conferences should compensate their speakers. https://www.forbes.com/sites/paologaudiano/2021/ 06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/. https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make- conference-speaker-fees-more-inclusive-and-equitable/
[23] Soon Kyu Choi, Shahrzad Divsalar, Jennifer Flórez-Donado, Krystal Kit- STRESS, https:
tle, Andy Lin, Ilan H. Meyer, and Prince Torres-Salazar. 2019. HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA. //www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/ IESOGI/Academics/1912_Colombia_Report_English_FINAL.pdf
[24] Camille Cobb, Ted McCarthy, Annuska Perkins, Ankitha Bharadwaj, Jared Comis, Brian Do, and Kate Starbird. 2014. Designing for the deluge: understand- ing & supporting the distributed, collaborative work of crisis volunteers. In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing. 888–899. [25] Patricia Hill Collins. 2019.
[53] Timnit Gebru and Emily Denton. 2021. Beyond Fairness. https://neurips.cc/
virtual/2021/tutorial/21889
[54] Christine Geeng, Mike Harris, Elissa Redmiles, and Franziska Roesner. 2021.
Queer Security Advice in the US. (2021).
Intersectionality as critical social theory. Duke
University Press.
[55] A Gomes, D Antonialli, and T Dias-Oliva. 2019. Drag queens and artificial intelligence. Should computers decide what is toxic on the internet. Internet Lab blog (2019). https://internetlab.org.br/en/news/drag-queens-and-artificial- intelligence-should-computers-decide-what-is-toxic-on-the-internet/ [56] Mary L Gray and Siddharth Suri. 2019. Ghost work: How to stop Silicon Valley
[26] Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality. John Wiley & Sons. [27] Susan E Collins, Seema L Clifasefi, Joey Stanton, Kee JE Straits, Eleanor Gil- Kashiwabara, Patricia Rodriguez Espinosa, Andel V Nicasio, Michele P Andrasik, Starlyn M Hawes, Kimberly A Miller, et al. 2018. Community-based participatory research (CBPR): Towards equitable involvement of community in psychology research. American Psychologist 73, 7 (2018), 884.
from building a new global underclass. Eamon Dolan Books.
[57] LW Green, MA George, et al. 2003. Appendix C: Guidelines for participatory research in health promotion. In Community-based participatory research for health, M. Minkler and N. Wallerstein (Eds.). San Francisco, CA, Jossey-Bass.
[28] Bill Cooke and Uma Kothari. 2001. Participation. Zed Books, London, England. [29] Sasha Costanza-Chock. 2018. Design justice: Towards an intersectional feminist framework for design theory and practice. Proceedings of the Design Research Society (2018).
[58] Christina E. Gringeri, Stéphanie Wahab, and Ben Anderson-Nathe. 2010. What Makes it Feminist?: Mapping the Landscape of Feminist Social Work Re- search. Affilia 25, 4 (2010), 390–405. https://doi.org/10.1177/0886109910384072 arXiv:https://doi.org/10.1177/0886109910384072
[30] Jakub Dalek, Nica Dumlao, Miles Kenyon, Irene Poetranto, Adam Senft, Caroline Wesley, Arturo Filastò, Maria Xynou, and Amie Bishop. 2021. No Access: LGBTIQ Website Censorship in Six Countries. (2021). https://citizenlab.ca/2021/08/no- access-lgbtiq-website-censorship-in-six-countries/
[59] Kevin Guyan. 2022. Fixing the Wrong Problems: Queer Communities and the False Promise of Unbiased and Equal Data Systems. European Data Protection Law Review 8, 4 (2022). https://doi.org/10.21552/edpl/2022/4/5
[31] Deep Learning Indaba 2017. https://deeplearningindaba.com/2021/ [32] Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff Phillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Chal- lenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 1968–1994. https://doi.org/10.18653/v1/2021.emnlp-main.150 [33] Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018. ’Too Gay for Facebook’: Presenting LGBTQ+ Identity Throughout the Personal Social Media Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 1–23.
[60] Karen Hacker and J. Glover Taylor. 2011. Community-Engaged Research https://catalyst.harvard.edu/publications-documents/community-
101. engaged-research-101-2/
[61] Oliver Haug. 2021. TikTokers Are Using Grindr to Out LGBTQ+ Olympians, Potentially Endangering Their Lives. Them (2021). https://www.them.us/story/ tiktokers-use-grindr-out-lgbtq-olympians/
IEEE Author Name Change Policy.
[62] IEEE. (n.d.).
https://conferences. ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-author- name-change-policy/ [Accessed Feb 2023].
[63] DisAbility in AI. (n.d.). https://elesa.github.io/ability_in_AI [64] Indigenous in AI (n.d.). https://indigenousinai.org/ [65] Khari Johnson. 2021. Black and Queer AI Groups Say They’ll Spurn Google Funding. Wired (2021). https://www.wired.com/story/black-queer-ai-groups- spurn-google-funding/
[34] Michael A DeVito, Ashley Marie Walker, Caitlin Lustig, Amy J Ko, Katta Spiel, Alex A Ahmed, Kimberley Allison, Morgan Scheuerman, Briana Dym, Jed R Brubaker, et al. 2020. Queer in HCI: Supporting LGBTQIA+ Researchers and Research Across Domains. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1–4.
[66] Khari Johnson. 2022. How Wrongful Arrests Based on AI Derailed 3 Men’s Lives. Wired (2022). https://www.wired.com/story/wrongful-arrests-ai-derailed-3- mens-lives/
[35] Catherine D’ignazio and Lauren F Klein. 2020. Data feminism. MIT press. [36] Diversity in AI (n.d.). http://www.diverseinai.org [37] Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. arXiv preprint arXiv:2104.08758 (Nov. 2021), 1286–1305. https://doi.org/10.18653/v1/ 2021.emnlp-main.98
[67] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A A Kohl, Andrew J Bal- lard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Bergham- mer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021. Highly accurate protein structure prediction with AlphaFold. Nature 596, 7873 (2021), 583–589. https://doi.org/10.1038/s41586-021-03819-2
[38] Jack Drescher. 2015. Out of DSM: Depathologizing homosexuality. Behavioral
sciences 5, 4 (2015), 565–575.
[39] Ashe Dryden. 2013. CODES OF CONDUCT 101 + FAQ. Link. [40] Ashe Dryden. 2013. Increasing Diversity at Your Conference. Link. [41] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S. Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference. https://doi.org/10.1145/2090236. 2090255
[68] Pratyusha Kalluri. 2020. Don’t ask if artificial intelligence is good or fair, ask
how it shifts power. Nature 583, 169 (2020).
[69] Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler, Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situated interventions for algorithmic equity: lessons from the field. In Proceedings of the 2020 conference on fairness, accountability, and transparency. 45–55.
[42] Russell Rowe Dynes. 1970. Organized behavior in disaster. Heath Lexington
Books.
[43] Val Elefante. 2021. Lips. Queer in AI Workshop at International Conference on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-


1894
Queer In AI: A Case Study in Community-Led Participatory AI
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
[70] Os Keyes. 2018. The misgendering machines: Trans/HCI implications of auto- matic gender recognition. Proceedings of the ACM on human-computer interaction 2, CSCW (2018), 1–22. https://doi.org/10.1145/3274357
Virtual Conferences Queer-Friendly: A Guide. In Proceedings of the 2021 Work- shop on Widening NLP. Conference on Empirical Methods in Natural Language Processing, Punta Cana, Dominican Republic. queerinai.org/diversity-guide
[71] Os Keyes. 2019. Counting the Countless: Why data science is a profound threat
[102] Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam Madge, et al. 2021. Skilful precipitation nowcasting using deep generative models of radar. Nature 597, 7878 (2021), 672–677.
for queer people. Real Life 2 (2019).
[72] Os Keyes, Zoë Hitzig, and Mwenza Blell. 2021. Truth from the machine: artificial intelligence and the materialization of identity. Interdisciplinary Science Reviews 46 (2021), 158 – 175.
[103] Eva Reid. 2021. How To Make Conference Speaker Fees More Inclusive And Equitable. hhttps://technical.ly/2021/07/22/conferences-pay-speakers//. https: //technical.ly/2021/07/22/conferences-pay-speakers/
[73] Khipu. (n.d.). https://khipu.ai/committee-2023/ [74] Andrey Kormilitzin, Nenad Tomasev, Kevin R McKee, and Dan W Joyce. 2023. A participatory initiative to include LGBT+ voices in AI for mental health. Nature Medicine (2023), 1–2.
[104] Christina R. Richey, Katharine M N Lee, Erica M. Rodgers, and Kathryn B. H. Clancy. 2019. Gender and sexual minorities in astronomy and planetary sci- ence face increased risks of harassment and assault. Bulletin of the American Astronomical Society 51 (2019), 0206.
[75] Gary A Kreps and Susan Lovegren Bosworth. 1994. Organizing, role enactment,
and disaster: A structural theory. University of Delaware Press.
[105] Nancy Russell, Susan Igras, Nalin Johri, Henrietta Kuoh, Melinda Pavin, and Jane Wickstrom. 2008. ACQUIRE Project Working Paper. https://pdf.usaid. gov/pdf_docs/Pnadm497.pdf
[76] Katie Langin. 2023. NSF still won’t track sexual orientation among scientific workforce, prompting frustration. https://www.science.org/content/article/nsf- still-won-t-track-sexual-orientation-among-scientific-workforce-prompting
[77] LatinX in AI (n.d.). https://www.latinxinai.org [78] Neil Lawrence. 2021. Comment on pull request: Fix author name. //github.com/mlresearch/v119/pull/4#issuecomment-760081621
[106] Morgan Klaus Scheuerman, Aaron Jiang, Katta Spiel, and Jed R. Brubaker. 2021. Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non- )Binary People. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI ’21). Association for Computing Machinery, New York, NY, USA, Article 400, 18 pages. https://doi.org/10.1145/ 3411764.3445742
https:
[79] Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman, Ashley Cordes, Joel Davison, et al. 2020. Indigenous protocol and artificial intelligence position paper. (2020).
[107] Morgan Klaus Scheuerman, Madeleine Pape, and Alex Hanna. 2021. Auto- essentialization: Gender in automated facial analysis as extended colonial project. Big Data & Society 8, 2 (2021), 20539517211053712.
[80] Yanan Long. 2021. Automatic Gender Recognition: Perspectives from Phe- nomenological Hermeneutics. Queer in AI Workshop at International Confer- ence on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in- ai/icml-2021#h.lx7wo16mt2ax
[108] Morgan Klaus Scheuerman, Jacob M Paul, and Jed R Brubaker. 2019. How computers see gender: An evaluation of gender classification in commercial facial analysis services. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1–33.
[81] Christina Lu, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctu- ating identities: Re-learning human categorization. In 2022 ACM Conference on Fairness, Accountability, and Transparency. 1005–1015.
[109] Natalie Schluter. 2018. The glass ceiling in NLP. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing. 2793–2798.
[82] Sarah Maiter, Laura Simich, Nora Jacobson, and Julie Wise. 2008. Reciprocity: An ethic for community-based participatory action research. Action research 6, 3 (2008), 305–325.
[110] Sarah Schulman. 2021. Let the Record Show: A Political History of ACT UP New
York, 1987-1993. Farrar, Straus and Giroux.
[111] Tom Simonite. 2021. AI and the List of Dirty, Naughty, Obscene, and Otherwise Bad Words. Wired (2021). https://www.wired.com/story/ai-list-dirty-naughty- obscene-bad-words/
[83] Miranda Marquit. 2018. Survey: 60% of LGBTQ Student Borrowers Regret Taking Out Student Loans. (2018). https://www.lendingtree.com/student/lgbtq- student-borrowers-regret-loans-survey/ [84] Masakhane (n.d.). https://www.masakhane.io [85] Lyndsey McMillon-Brown. 2021. Implementing diversity, equity and inclusion
[112] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Par- ticipation Is Not a Design Fix for Machine Learning. In Equity and Access in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO ’22). Association for Computing Machinery, New York, NY, USA, Article 1, 6 pages. https://doi.org/10.1145/3551624.3555285
efforts at conferences. Nature Energy 6, 11 (2021), 1000–1002.
[86] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM Comput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. https://doi.org/10.1145/ 3457607
[113] Shakira Smith, Oliver L Haimson, Claire Fitzsimmons, and Nikki Echarte Brown. 2021. Censorship of Marginalized Communities on Instagram. Salty (2021). https://saltyworld.net/exclusive-report-censorship-of-marginalized- communities-on-instagram-2021-pdf-download/
[87] Doug Meyer. 2015. Violence against queer people: Race, class, gender, and the
persistence of anti-LGBT discrimination. Rutgers University Press.
[88] Muslims in ML. (n.d.). http://www.musiml.org/ [89] Name Change Policy Working Group (n.d.). Name Change Policy Working
[114] Dean Spade. 2020. Mutual aid: Building solidarity during this crisis (and the next).
Verso Books. [115] Robyn Speer. 2021.
Google Scholar deadnames trans authors and ob- https://docs.google.com/document/d/
Group. https://ncpwg.org/
[90] NeurIPS. (n.d.). NeurIPS Proceedings: Name Change Policy. https://papers.nips.
Link.
structs their name change. 1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE
cc/, “Name Change Policy” link in footer [Accessed Feb 2023].
[91] North Africans in ML. (n.d.). https://sites.google.com/view/northafricansinml [92] Molly Olmstead. 2021. A Prominent Priest Was Outed for Using Grindr. Experts Say It’s a Warning Sign. Slate (2021). https://slate.com/technology/2021/07/ catholic-priest-grindr-data-privacy.html
[116] Robyn Speer. 2021. Google Scholar has failed us. (2021). https://scholar.hasfailed.
us/
[117] Kate Starbird and Leysia Palen. 2011. "Voluntweeters" self-organizing by digital volunteers in times of crisis. In Proceedings of the SIGCHI conference on human factors in computing systems. 1071–1080.
[93] ORCID (n.d.). Open Researcher and Contributor ID (ORCID). https://orcid.org/ [94] Matt Payton. 2021. Egyptian police ’are using Grindr to find and arrest LGBT people’. The Independent (2021). https://www.independent.co.uk/news/world/ africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbian- homophobia-a7211881.html
[118] Luke Stark and Jevan Hutson. 2021. Physiognomic Artificial Intelligence. Avail-
able at SSRN 3927300 32, 4 (2021), 922.
[119] Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen, Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, and Catherine D’Ignazio. 2022. Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection. In 2022 ACM Conference on Fairness, Accountability, and Transparency (Seoul, Republic of Korea) (FAccT ’22). Association for Computing Machinery, New York, NY, USA, 667–678. https: //doi.org/10.1145/3531146.3533132
[95] Billy Perrigo. 2023. OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic. Time (2023). https://time.com/6247678/openai- chatgpt-kenya-workers/
[96] Anthony T Pinter, Morgan Klaus Scheuerman, and Jed R Brubaker. 2021. Enter- ing Doors, Evading Traps: Benefits and Risks of Visibility During Transgender Coming Outs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3 (2021), 1–27.
[120] Danica J. Sutherland. 2022. Name Change Policies: A Brief (Personal) Tour. Queer in AI workshop, NeurIPS 2022; https://djsutherland.ml/slides/qai-name- change.
[97] Anastasia Powell, Adrian J Scott, and Nicola Henry. 2020. Digital harassment and abuse: Experiences of sexuality and gender minority adults. European journal of criminology 17, 2 (2020), 199–223.
[121] Rajesh Tandon. 1988. Social transformation and participatory research. Conver-
gence 21, 2 (1988), 5.
[98] ACL Pubcheck. (n.d.). https://github.com/acl-org/aclpubcheck [Accessed Feb
[122] Theresa Jean Tanenbaum, Irving Rettig, H Michael Schwartz, BM Watson, Teddy G Goetz, Katta Spiel, and Mike Hill. 2021. A vision for a more trans- inclusive publishing world: guest article. Committee on Publication Ethics. https: //publicationethics.org/news/vision-more-trans-inclusive-publishing-world.
2023].
[99] Queer in AI at NeurIPS 2021. http://queerinai.org/neurips-2021 [100] Queer in AI Organizers. 2019. Code of Conduct. https://sites.google.com/view/
queer-in-ai/code-of-conduct.
[123] NAACL DEI Team. (n.d.). NAACL Citation Name Change Procedure. https:
//2021.naacl.org/blog/name-change-procedure/ [Accessed Feb 2023].
[101] Organizers of QueerInAI, A Pranav, MaryLena Bleile, Arjun Subramonian, Luca Soldaini, Danica J. Sutherland, Sabine Weber, and Pan Xu. 2021. How to Make
[124] Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed. 2021. Fairness for Unobserved Characteristics: Insights from Technological Impacts on Queer


1895
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Organizers of Queer in AI, et al.
Communities. arXiv preprint arXiv:2102.04257 (2021). https://doi.org/10.1145/ 3461702.3462540
[129] Lindsay Weinberg. 2022. Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches. Journal of Artificial Intelligence Research 74 (2022), 75–109.
[125] Paige Yes Treebridge. 2021. Crowdsourcing a Corpus of Dogwhistle Transphobia. Queer in AI Workshop at International Conference on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax What can we learn from longitudinal studies https://ccwt.wisc.edu/wp-
[130] Widening NLP (n.d.). http://www.winlp.org [131] Bianca DM Wilson, Soon Kyu Choi, Gary W Harper, Marguerita Lightfoot, Stephen Russell, and Ilan H Meyer. 2020. Homelessness among LGBT adults in the US. https://williamsinstitute.law.ucla.edu/publications/lgbt-homelessness- us/
[126] Fangjing Tu. 2022.
on the impacts of college internships? content/uploads/2022/04/Final_CCWT_report_LR-What-can-we-learn- from-longitudinal-studies-on-the-impacts-of-college-internships.pdf [127] Ayesha IT Tulloch. 2020. Improving sex and gender identity equity and inclusion at conservation and ecology conferences. Nature Ecology & Evolution 4, 10 (2020), 1311–1320.
[132] Women in Machine Learning. 2021. Code of Conduct. https://wimlworkshop.
org/conduct/.
[133] Women in Machine Learning (n.d.). https://wimlworkshop.org [134] Aman Yadav, Christopher D Seals, Cristina M Soto Sullivan, Michael Lachney, Quintana Clark, Kathy G Dixon, and Mark JT Smith. 2020. The forgotten scholar: underrepresented minority postdoc experiences in STEM fields. Educational Studies 56, 2 (2020), 160–185.
[128] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer, et al. 2019. Applications of machine learning in drug discovery and development. Nature Reviews Drug discovery 18, 6 (2019), 463–477.