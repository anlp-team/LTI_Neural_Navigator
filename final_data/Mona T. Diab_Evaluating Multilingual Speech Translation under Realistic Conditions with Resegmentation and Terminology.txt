2https://aclanthology.org/2023.iwslt-1.2
EvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.
Figure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.
1https://www.2022.aclweb.org/dispecialinitiative
62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62–78 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics


3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:§A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof∼11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-
Mostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi´c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5
--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see§A.2.
63


90Word count
160Num. Segments
50
50
250
200
120
60
60
80
80
10
10
7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(§2.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin§A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-
sentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in§A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially∼11.5minuteaudiofilesintosegmentsofapproximately30secondsorless
0
0
0
0
30
subtitles
subtitles
30Seconds
300
150
VAD
VAD
100
100
25
40
40
140
350
15
sentences(a)Speechsegmentlengthdistribution
5
20
20
20
400Num. Segments
70
64


REF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS
Figure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex‘Thank.You.’)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(‘CONEL’→‘CONLL’or‘positionor’→‘po-sitional’),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-
REF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD
REF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS
Figure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in§A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI’sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.
8Subtitleguidelinesareshownin§A.7.
65


evalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4
devchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4
9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O’Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin§A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.
Table1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see§2.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin§A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(§3.7)usingthemet-ricsdiscussedin§2.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7×greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is
Metricardefafrjanlptrutrzh
66


TER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(ρ=0.41),whileTERisonlyweaklysuggestedbyCOMET(ρ=0.29)andisnegativelycorrelatedwithchrFandBLEU(−0.63,−0.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe
nl
nl
50
8
fa
fa
ja
ja
10
10
4
0
zh
zh
30
Figure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe
fr
fr
12
tr
tr
14
de
de
11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.
ar
ar
TER [dev]
2
40
pt
pt
6
ru
ru
20
67


zhFigure7:RangeinTERbytalkperlanguage.
nl
nl
nl
50
0.8
12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4×larger,thoughoverallperformanceimproves.Atworst,the∆WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea
8
fa
fa
fa
ja
ja
ja
Manualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4
0.2
10
4
3
0
0
zh
30
fr
fr
fr
1
tr
tr
tr
7
60TER
0.0
de
de
de
ar
ar
ar
0.6
Table2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.
2
40
pt
pt
pt
6
9Talk idx
1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4×byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.
ASRMTSegmentationdevtestdevtest
ru
ru
ru
5
0.4
20
zh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61
68


terminology: ASR
nl
50
Metric
fa
terminology: MT
ja
60
80
10
0
30
fr
90
tr
de
ar
100
ofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(ρ=0.8)asmeasuredbychrF.
zhLanguage
40
pt
ru
20
chrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMartínezAlonso,2018;Jinetal.,2013)andconceptrelation(Gáboretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily‘generaldomain.’Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(ˇCuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.
70
69


LimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT’23evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC’14),pages1856–1862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,OndˇrejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEstéve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,DávidJa-vorský,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPolák,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianStüker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,LoïcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,OndˇrejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEstève,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,DávidJavorský,V˘eraKloudová,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaNˇadejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianStüker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98–157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,OndˇrejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianStüker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th
70


InternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1–29,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,OndˇrejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianStüker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1–34,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,OndˇrejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71–79,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62–69,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798–805.OliverˇCuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106–114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012–2017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataGábor,HaïfaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC’16),pages3694–3701,Portorož,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb’seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535–1546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839–850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-Sánchez,J.A.Silvestre-Cerdà,J.Jorge,N.Roselló,A.Giménez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229–8233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780–790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684–7689.
71


JérômeLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOndˇrejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688–725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO’Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83–136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311–318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79–90,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers’Track,pages86–91,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFrançoisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi´c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392–395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186–191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314–1324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685–2702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEsplà-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandHéctorMartínezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,OndˇrejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223–231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.Gállego,JoséA.R.Fonol-losa,andMartaRuizCosta-jussà.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197–4203,Marseille,France.EuropeanLanguageResourcesAssociation.
72


VilémZouhar,MartinPopel,OndˇrejBojar,andAlešTamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204–10214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.
73


MChineseChinaChina0:12:03NLPApplicationsM—BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications
0:57:13Totaldevelopmentsetduration
0:59:22Totalevaluationsetduration
Woman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1
TOTAL3170100
Table3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.
Table4:AggregatestatisticsongenderofACL2022conferenceparticipants.
MKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M——USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP
GenderL1CountryAffiliationTimeTrack
AAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers’listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.
13Thoughwenotepronounsdonotalwaysindicategender.
Gender#%
74


MuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-Sánchezetal.,2020)ensome(4)de,fr,pt,tr
CorpusSrcTgt
Table5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows–Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.•Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon’tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel“#Unclear”.•Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).•Donotparaphrase.Donotcorrectthespeaker’sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:“hewere”,itshouldbetranscribedasiswithoutcorrection).•Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.•Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.•ForeignwordsshouldbetransliteratedusingLatinletters.•Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.•Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.•Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.•Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(•Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>•Usedoubledashes“--”toindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor–).
A.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.
75


Figure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:•Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.•Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform•Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby‘:::’.Thetranslatorshouldpicktheproperonebasedonthecontext•Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform
14https://site.matecat.com/
76


devSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0
evalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2
Table6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:•Noonesegmentisallowedtobelongerthan30seconds.•Eachlinecannotbelongerthan42characters.•Amaximumof2linesoftextcanbeshownonscreenatonce.•Thesubtitlereadingspeedshouldkepttoamaximumof∼20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).
Figure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison
15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.
SetSegmentationardefafrjanlptrutrzhAvg.
77


Figure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.
A.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom§A.7.
78