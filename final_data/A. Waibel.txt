A. Waibel8027573719
Papers that are published on 2023 and have open access are listed below with their titles, years, publication venues, as well as the author lists and abstracts are listed below 
['SYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'Conventional multi-speaker text-to-speech synthesis (TTS) is known to be capable of synthesizing speech for multiple voices, yet it cannot generate speech in different accents. This limitation has motivated us to develop SYNTACC (Synthesizing speech with accents) which adapts conventional multi-speaker TTS to produce multi-accent speech. Our method uses the YourTTS model and involves a novel multi-accent training mechanism. The method works by decomposing each weight matrix into a shared component and an accent-dependent component, with the former being initialized by the pretrained multi-speaker TTS model and the latter being factorized into vectors using rank-1 matrices to reduce the number of training parameters per accent. This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition. Our SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents.', ['Tuan-Nam Nguyen', 'Ngoc-Quan Pham', 'A. Waibel']]
['KIT’s Multilingual Speech Translation System for IWSLT 2023', '2023', ['International Workshop on Spoken Language Translation', 'IWSLT', 'Int Workshop Spok Lang Transl'], 'Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.', ['Danni Liu', 'T. Nguyen', 'Sai Koneru', 'Enes Yavuz Ugan', 'Ngoc-Quan Pham', 'Tuan-Nam Nguyen', 'Tu Anh Dinh', 'Carlos Mullov', 'A. Waibel', 'J. Niehues']]
['Convoifilter: A case study of doing cocktail party speech recognition', '2023', ['arXiv.org', 'ArXiv'], "This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR's word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter.", ['T. Nguyen', 'A. Waibel']]
['Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users. Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.', ['Peter Polák', 'Brian Yan', 'Shinji Watanabe', 'A. Waibel', 'Ondrej Bojar']]
['End-to-End Evaluation for Low-Latency Simultaneous Speech Translation', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user.', ['Christian Huber', 'Tu Anh Dinh', 'Carlos Mullov', 'Ngoc-Quan Pham', 'T. Nguyen', 'Fabian Retkowski', 'Stefan Constantin', 'Enes Yavuz Ugan', 'Danni Liu', 'Zhaolin Li', 'Sai Koneru', 'J. Niehues', 'A. Waibel']]
['FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN', '2023', ['International Workshop on Spoken Language Translation', 'IWSLT', 'Int Workshop Spok Lang Transl'], 'This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.', ['Sweta Agrawal', 'Antonios Anastasopoulos', 'L. Bentivogli', 'Ondrej Bojar', 'Claudia Borg', 'Marine Carpuat', 'Roldano Cattoni', 'Mauro Cettolo', 'Mingda Chen', 'William Chen', 'K. Choukri', 'Alexandra Chronopoulou', 'Anna Currey', 'T. Declerck', 'Qianqian Dong', 'Kevin Duh', 'Y. Estève', 'Marcello Federico', 'Souhir Gahbiche', 'B. Haddow', 'B. Hsu', 'Phu Mon Htut', 'H. Inaguma', 'Dávid Javorský', 'J. Judge', 'Yasumasa Kano', 'Tom Ko', 'Rishu Kumar', 'Peng Li', 'Xutai Ma', 'Prashant Mathur', 'E. Matusov', 'Paul McNamee', 'John P. McCrae', 'Kenton Murray', 'Maria Nadejde', 'Satoshi Nakamura', 'Matteo Negri', 'H. Nguyen', 'J. Niehues', 'Xing Niu', 'Atul Kr. Ojha', 'John E. Ortega', 'Proyag Pal', 'J. Pino', 'Lonneke van der Plas', 'Peter Polák', 'Elijah Matthew Rippeth', 'Elizabeth Salesky', 'Jiatong Shi', 'Matthias Sperber', 'Sebastian Stüker', 'Katsuhito Sudoh', 'Yun Tang', 'Brian Thompson', 'Ke M. Tran', 'M. Turchi', 'A. Waibel', 'Mingxuan Wang', 'Shinji Watanabe', 'Rodolfo Zevallos']]
