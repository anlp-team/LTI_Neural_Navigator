Alexander I. Rudnicky427639264
Papers that are published on 2023 and have open access are listed below with their titles, years, publication venues, as well as the author lists and abstracts are listed below 
['Advancing Regular Language Reasoning in Linear Recurrent Neural Networks', '2023', ['arXiv.org', 'ArXiv'], 'In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.', ['Ting-Han Fan', 'Ta-Chung Chi', 'Alexander I. Rudnicky']]
['Structured Dialogue Discourse Parsing', '2023', ['SIGDIAL Conferences', 'SIGDIAL', 'SIGDIAL Conf', 'Annu Meet Spéc Interest Group Discourse Dialogue', 'Annual Meeting of the Special Interest Group on Discourse and Dialogue'], 'Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model’s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).', ['Ta-Chung Chi', 'Alexander I. Rudnicky']]
['A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech', '2023', ['AAAI Conference on Artificial Intelligence', 'National Conference on Artificial Intelligence', 'National Conf Artif Intell', 'AAAI Conf Artif Intell', 'AAAI'], 'Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.', ['Li-Wei Chen', 'Shinji Watanabe', 'Alexander I. Rudnicky']]
['Overview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4', '2023', ['', ''], 'The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics’ correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.', ["Mario Rodr'iguez-Cantelar", 'Chen Zhang', 'Chengguang Tang', 'Ke Shi', 'Sarik Ghazarian', 'João Sedoc', 'L. F. D’Haro', 'Alexander I. Rudnicky']]
['Learning to Ask Questions for Zero-shot Dialogue State Tracking', '2023', ['Annual International ACM SIGIR Conference on Research and Development in Information Retrieval', 'International ACM SIGIR Conference on Research and Development in Information Retrieval', 'Int ACM SIGIR Conf Res Dev Inf Retr', 'SIGIR', 'Annu Int ACM SIGIR Conf Res Dev Inf Retr'], 'We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.', ['Diogo Tavares', 'David Semedo', 'Alexander I. Rudnicky', 'João Magalhães']]
