Chenyan Xiong35504894
Papers that are published on 2023 and have open access are listed below with their titles, years, publication venues, as well as the author lists and abstracts are listed below 
['Text Matching Improves Sequential Recommendation by Reducing Popularity Biases', '2023', ['International Conference on Information and Knowledge Management', 'Conference on Information and Knowledge Management', 'Conf Inf Knowl Manag', 'Int Conf Inf Knowl Manag', 'CIKM'], 'This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.', ['Zhenghao Liu', 'Senkun Mei', 'Chenyan Xiong', 'Xiaohua Li', 'Shi Yu', 'Zhiyuan Liu', 'Yu Gu', 'Ge Yu']]
['Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval', '2023', ['arXiv.org', 'ArXiv'], 'Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.', ['S. Yu', 'Cheng-Chung Fan', 'Chenyan Xiong', 'David Jin', 'Zhiyuan Liu', 'Zhenghao Liu Tsinghua University', 'Huazhong University of Science', 'Technology', 'Microsoft Research', 'M. I. O. Technology', 'N. University']]
['OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit', '2023', ['Annual International ACM SIGIR Conference on Research and Development in Information Retrieval', 'International ACM SIGIR Conference on Research and Development in Information Retrieval', 'Int ACM SIGIR Conf Res Dev Inf Retr', 'SIGIR', 'Annu Int ACM SIGIR Conf Res Dev Inf Retr'], 'Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.', ['Shi Yu', 'Zhenghao Liu', 'Chenyan Xiong', 'Zhiyuan Liu']]
