Eric Nyberg386031216
Papers that are published on 2023 and have open access are listed below with their titles, years, publication venues, as well as the author lists and abstracts are listed below 
['GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets', '2023', ['Conference of the European Chapter of the Association for Computational Linguistics', 'Conf Eur Chapter Assoc Comput Linguistics', 'EACL'], 'The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.', ['Njall Skarphedinsson', 'Breki Gudmundsson', 'Steinar Smari', 'M. Lárusdóttir', 'H. Einarsson', 'Abuzar Khan', 'Eric Nyberg', 'H. Loftsson']]
['InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers', '2023', ['arXiv.org', 'ArXiv'], 'We carried out a reproducibility study of InPars recipe for unsupervised training of neural rankers. As a by-product of this study, we developed a simple-yet-effective modification of InPars, which we called InPars-light. Unlike InPars, InPars-light uses only a freely available language model BLOOM and 7x-100x smaller ranking models. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7-30%) and statistically significant improvements over BM25 in nDCG or MRR using only a 30M parameter six-layer MiniLM ranker. In contrast, in the InPars study only a 100x larger MonoT5-3B model consistently outperformed BM25, whereas their smaller MonoT5-220M model (which is still 7x larger than our MiniLM ranker), outperformed BM25 only on MS MARCO and TREC DL 2020. In a purely unsupervised setting, our 435M parameter DeBERTA v3 ranker was roughly at par with the 7x larger MonoT5-3B: In fact, on three out of five datasets, it slightly outperformed MonoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used in InPars. We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.', ['Leonid Boytsov', 'Preksha Patel', 'Vivek Sourabh', 'Riddhi Nisar', 'Sayan Kundu', 'R. Ramanathan', 'Eric Nyberg']]
['Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA', '2023', ['Workshop on Document-grounded Dialogue and Conversational Question Answering', 'DialDoc', 'Workshop Doc Dialogue Conversational Quest Answering'], 'The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.', ['Srinivas Gowriraj', 'Soham Dinesh Tiwari', 'Mitali Potnis', 'Srijan Bansal', 'T. Mitamura', 'Eric Nyberg']]
['Chain-of-Skills: A Configurable Model for Open-Domain Question Answering', '2023', ['Annual Meeting of the Association for Computational Linguistics', 'Annu Meet Assoc Comput Linguistics', 'Meeting of the Association for Computational Linguistics', 'ACL', 'Meet Assoc Comput Linguistics'], 'The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.', ['Kaixin Ma', 'Hao Cheng', 'Yu Zhang', 'Xiaodong Liu', 'Eric Nyberg', 'Jianfeng Gao']]
