3 2 0 2
y a M 7 1
] L C . s c [
2 v 9 6 9 7 0 . 5 0 3 2 : v i X r a
GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content
Yutian Chen† School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213 yutianch@andrew.cmu.edu
Hao Kang† School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213 haok@andrew.cmu.edu
Vivian Zhai† College of Engineering Carnegie Mellon University Pittsburgh, PA 15213 yiyanz@andrew.cmu.edu
Liangze Li Language Technologies Institute Carnegie Mellon University Pittsburgh, PA 15213 liangzel@andrew.cmu.edu
Rita Singh Language Technologies Institute Carnegie Mellon University Pittsburgh, PA 15213 rsingh@cs.cmu.edu
Bhiksha Raj Language Technologies Institute Carnegie Mellon University Pittsburgh, PA 15213 bhiksha@cs.cmu.edu
Abstract
This paper presents a novel approach for detecting ChatGPT-generated vs. human- written text using language models. To this end, we ﬁrst collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two dif- ferent models for text classiﬁcation, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model’s ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our ﬁndings provide important insights into the effective use of language models to detect generated text.
1
Introduction
The development of an algorithm that can accurately distinguish between machine-generated text and human-generated text has become crucial in contexts where verifying the authenticity of information is essential, such as in legal proceedings and news reporting. Although traditional statistical techniques such as logistic regression and support vector machines (SVM) have been used for this purpose in the past [1], the emergence of Large Language Models (LLMs) like InstructGPT [2] and the availability of its free deployment, ChatGPT, has presented signiﬁcant challenges to existing detection methods. As a result, the need to develop novel algorithms that can accurately distinguish between machine and human-generated text has become more pressing than ever before.
†Three authors contribute equally to this work.


To address this issue, we focused on ﬁne-tuning approaches to distinguish human-written and ChatGPT-generated text. We ﬁrst collected the data from ChatGPT and established the OpenGPTText data set. Section 3 of the paper provides a detailed description of the data collection process, including the criteria to select the samples and the methods to ﬁlter out irrelevant and undesired noise in the collected text. We then trained the frozen RoBERTa with MLP and ﬁne-tuned the T5 model on this data set for classiﬁcation. The resulting model is what we referred to as GPT-Sentinel. More details about the model can be found in Section 4 of the paper.
The rest of this paper is structured as follows: We ﬁrst discuss related work in Section 2; illustrate OpenGPTText data set in Section 3; present our model and the training details in Section 4; evaluate the performance using various metrics in Section 5; interpret the basis for the model’s prediction in Section 6; point out future work in Section 7; and conclude in Section 8.
2 Related Work
The work by Jawahar et al. identiﬁed ﬁve key characteristics that a state-of-the-art detector for content generated by LLMs should possess: accuracy, data efﬁciency, generalizability, and interpretability [3]; where accuracy means the model should be able to distinguish between LLM-generated and human-written text while achieving an appropriate trade-off between precision and recall rates; data efﬁciency means that the detector should be able to operate with as few examples as possible from the language model; generalizability means that the detector should be able to work consistently, regardless of any change in the model architecture, prompt length, or training dataset; interpretability means the detector should provide clear explanations for the reasoning behind its decisions. These ﬁve principles is used as our guidance when designing the GPT-Sentinel.
Approaches to machine-generated text detection can be divided into three categories: traditional statistical approach (by analyzing statistical abnormality in text sample), unsupervised-learning approach (by zero-shot classiﬁcation of LLM), and supervised-learning approach (by ﬁne-tuning a language model with or without a classiﬁcation module attached).
2.1 Statistical Methods
The ﬁrst approach to the problem is via the use of statistics. For instance, the work by Solaiman et al. [4] demonstrated that using a logistic regression model to differentiate between text generated by GPT-2 models vs. text written by humans could achieve an accuracy ranging from 88% (on 124 million parameter variants of GPT-2 model) to 74% (on 1.5 billion parameter variants of GPT-2 model). Moreover, the work by Ippolito et al. [5] showed that the top-k sampling method used in popular LLMs could over-sample high-likelihood words, and thus the generated text exhibited statistical anomalies, which could be further used for detection. Moreover, the statistical methods called the Giant Language Model Test Room (GLTR) designed by Gehrmann et al. [6] consists of three tests: Tests 1 and 2 checked if a generated word is sampled from the top of the distribution, and Test 3 veriﬁed if the system is overly conﬁdent in its next prediction due to familiarity with the previously generated context. A human-subject study found that GLTR improved the human detection rate of fake text from 54% to 72% without prior training.
2.2 Zero-Shot Classiﬁcation
The second detection approach is by zero-shot classiﬁcation (i.e., using a pre-trained LLM to detect its own generation or that of a similar model). In the work by Solaiman et al. [4], a baseline method that used an LLM to evaluate the log-probability and the corresponding threshold for making classiﬁcation decisions was proposed. However, this zero-shot approach performs poorly compared to the statistical methods.
2.3 Fine-Tuning Language Model
The last approach is to ﬁne-tune an existing language model. For example, Zeller et al. [7] ﬁne-tuned a linear layer to identify if the input was generated by the GROVER model or by a human, using the hidden states in the encoder of GROVER. Also, Solaiman et al. [1, 4] ﬁne-tuned a pre-trained RoBERTa model on a labeled dataset to create a content detector that achieved state-of-the-art
2


Table 1: Detailed statistics for OpenGPTText data set as of Apr 24, 2023. The subsets not listed in the table were not paraphrased in OpenGPTText. The category “Failed to Rephrase” corresponds to one of the following situations: 1. the content length exceeds the API limit, 2. the content is blocked by OpenAI content ﬁlter.
Subset
OpenGPTText
OpenWebText
Failed to Rephrase
Percentage
urlsf_00 urlsf_01 urlsf_02 urlsf_03 urlsf_04 urlsf_05 urlsf_06 urlsf_09
3, 888 3, 923 3, 260 3, 891 3, 684 3, 602 3, 494 3, 653
391, 590 392, 347 391, 274 390, 161 390, 250 389, 874 390, 339 389, 634
27 0 652 10 218 296 409 243
0.99% 1.00% 0.83% 1.00% 0.94% 0.92% 0.90% 0.94%
Total
29, 395
3, 125, 469
1, 885
0.94%
performance of 90% accuracy in detecting text generated by GPT-2. However, the supervised learning method requires a large amount of labeled data, in contrast to previously discussed methods. The ﬁne-tuned model on RoBERTa by Solaiman et al. required 200k labeled training data.
3 Data Set Collection
ChatGPT is a language model based on the GPT-3.5 architecture. It succeeded InstructGPT, which was previously published by Ouyang et al. [2]. As it was introduced by OpenAI on November 30, 2022, there is currently no publicly available data set that systematically collects the outputs generated by ChatGPT as far as we know. Consequently, we undertook the task of creating our own data set for ChatGPT outputs. Building upon the work of Gokaslan et al. [8] and their OpenWebText corpus. We named the data set OpenGPTText.
3.1 OpenGPTText Overview
The OpenGPTText data set consists of paraphrased textual samples that were generated by the gpt-3.5-turbo language model using the OpenWebText corpus as its source. The data set contains 29,395 textual samples, each corresponding to a piece human-written text from the OpenWebText corpus that shares a same unique identiﬁer (UID).
Up to April 24, 2023, the OpenGPTText only contains approximately 1% of paraphrased samples of the OpenWebText data set in some speciﬁc subsets. The number of samples in each subset is listed in table 1.
3.2 Data Source
The OpenWebText data set [8] is a publicly available resource that comprises web content sourced from URLs shared on Reddit with a minimum of three votes. This data set is a reconstitution of the original WebText corpus, which was initially described by Radford et al. [9]. Since the data set was compiled in 2019, it is improbable that the textual content it contains was algorithmically generated.
3.3 Data Collection Method
The rephrasing procedure used OpenAI’s API on gpt-3.5-turbo model, with the prompted instruc- tion: “Rephrase the following paragraph by paragraph”. However, it should be noted that the samples with length larger than 2,000 words were ﬁltered out as the gpt-3.5-turbo can only take in at most 3,000 tokens. Some text samples blocked by OpenAI content ﬁlter was also excluded from OpenGPTText. The number of texts that were not successfully paraphrased due to either of the two reasons is reported in the “Failed to Rephrase” column in table 1.
3


3
4
3
3
OpenWebText-Original
2
2
1
1
0
0
2
OpenWebText-Final
1
1
5
PCA projection of hidden state ofRoBERTa-Sentinel on OpenWebText before and after sanitize
PCA projection of hidden state ofRoBERTa-Sentinel on OpenGPTText before and after sanitize
4
3
0
1
1
0.0
1.5
OpenGPTText-Final
OpenGPTText-Original
1.0
0.5
0.5
2
2
2.0
Figure 1: PCA of hidden state distribution of RoBERTa-Sentinel model on OpenWebText (Left) and OpenGPTText (Right) before and after cleaning. Note that the cleaning process affected the distribution of OpenWebText signiﬁcantly.
3.4 Data Set Cleaning
Upon inspecting the OpenGPTText data set, we observed certain stylistic disparities between Chat- GPT’s output and the corpus in OpenWebText. Speciﬁcally, our analysis revealed that ChatGPT’s output tend to include the Unicode character “right double quotation mark” (U+201D) in place of the ASCII character “quotation mark” (U+0022) used in the OpenWebText corpus. Furthermore, ChatGPT also tends to incorporate two consecutive new-line characters between paragraphs, whereas the OpenWebText corpus utilizes two to six new-line characters consecutively.
In an effort to enhance the resilience of our classiﬁer and eliminate the potential inﬂuence of these susceptible features, we undertook measures to sanitize both the OpenWebText and OpenGPTText data sets. To achieve this, we implemented a cleaning procedure that involved removing excessive new-line characters and mapping Unicode characters onto the ASCII character set. These steps were taken to mitigate any possible confounding effects of these variables on the performance of our classiﬁer. Pincipal Component Analysis (PCA) of hidden state distribution in ﬁgure 1 shows that the cleaning process has signiﬁcantly changed the distribution of dataset.
The resulting, clean data set are called OpenWebText-Final and OpenGPTText-Final in the discussion below.
3.5 Data Set Release
Our plan entails the release of both OpenGPTText and OpenGPTText-Final on Kaggle in May 2023.
4 Method
The following models were trained using the OpenWebText-Final and OpenGPTText-Final data set, partitioning 80% of the data set for training, 10% for validation, and the remaining 10% for testing. Given that the texts in the data set have varying lengths, we truncated input text to a maximum of 512 tokens to improve training efﬁciency, while also padding any text with less than 512 tokens with additional <PAD> tokens. To address memory constraints while using a relatively large batch size during ﬁne-tuning, we performed gradient accumulation, whereby the optimizer was updated after a certain number of forward passes.
4.1 RoBERTa-Sentinel Model
The ﬁrst method we proposed is to leverage the pretrained RoBERTa model [10] to extract relevant features from the input text, followed by an MLP with gaussian error linear units (GELU, [11]) and two fully connected layers for classiﬁcation. To preserve the general linguistic knowledge of the
4


12
𝑇1(1)
𝐸1
𝑇1
𝑇1
𝑇1(2)
𝑃(Human)𝑃(ChatGPT)
MLP
𝑇2
𝑇2
RoBERTa-BaseThisisGPT
𝑇
𝑇
…768768
𝐸[𝐶𝐿𝑆]
𝐶𝐿𝑆(1)
12
1
1
𝑇𝑁
𝑇𝑁
𝑇𝑁
𝑇𝑁
𝑇[𝐶𝐿𝑆]
𝑇2
𝐸2
𝑇2(12)
…
…
…
…
…
𝑇[𝐶𝐿𝑆](12)
2
2
…
…
…
…
…
𝐸𝑁
𝐶𝐿𝑆(2)
…
Figure 2: The depicted ﬁgure illustrates the RoBERTa-Sentinel architecture, wherein the dashed line connecting RoBERTa-Base and MLP module indicates the non-propagation of gradient back to the former.
Table 2: Training conﬁguration for RoBERTa-Sentinel and T5-Sentinel. Where “AdamW” refers to the “Adaptive Momentum Estimation with Weight Decay” optimizer proposed by Loshchilov et al. in [13]. “Cosine annealing” refers to the learning rate schedul proposed by Loschilov et al. in [14]
Hyper-Parameters RoBERTa-Sentinel
T5-Sentinel
Epoch Batch Size Learning Rate Weight Decay Optimizer Loss Function Scheduler Data Set
15 512 1 × 10−4 1 × 10−3 AdamW Cross entropy Cosine annealing OpenGPTText-Final
5 512 5 × 10−4 1 × 10−3 AdamW Cross entropy Cosine annealing OpenGPTText-Final
model while adapting it to the speciﬁc task at hand, we decided to “freeze” the RoBERTa model, allowing the loss to only backpropagate through the MLP module.
Let E represent the input embedding, V represent the vocabulary size, and H denote the dimension of the last hidden state in RoBERTa. The input text with length N can be expressed as a sequence of embedding, E[CLS], E1, · · · , EN , where E[CLS], Ei ∈ RV . Here, E[CLS] denotes the embedding of the special [CLS] token, as descried in the original BERT implementation [12]. We use the ﬁnal hidden state vector T[CLS] ∈ RH that corresponds to the ﬁrst [CLS] token as the features of the input text. This extracted feature vector C is then forward to the MLP for classiﬁcation, as shown in ﬁgure 2.
The detailed training conﬁguration for RoBERTa-Sentinel can be found in table 2.
4.2 T5-Sentinel Model
The second methodwe proposed involves ﬁne-tuning the T5 model [15] for classiﬁcation tasks. Unlike the RoBERTa-Sentinel which uses an MLP module to classify the hidden state vector of input, this approach directly encodes the task as a sequence-to-sequence (seq-to-seq) problem.
During the training, the input sequence consists of a text sample from OpenGPTText-Final, and the output sequence represents the classiﬁcation result as either “positive </s>” or “negative </s>”, where “</s>” is the end-of-sequence token. During the inference, we limit the vocabulary down to only two words (i.e. “positive” and “negative”), and select the one with the maximum probability as the classiﬁcation result. This process is further shown in Figure 3.
5


𝐸2
Feed Forward
Human=
Feed-forward MLP
⋯Next-wordProbability Distribution
𝐸1
×6
⋯T5 Encoder Block
×6
“Positive”“Negative”
𝐸<𝑠>
Self-Attention
𝑃
𝐸𝑁
ChatGPT=,𝑃
T5 Decoder Block
⋯
Masked Multi-head Attention
Masked Multi-head Attention
𝐸<𝑃𝐴𝐷>
Figure 3: Architecture for T5-Sentinel. After input the entire token sequence, we provide the T5- Decoder with a <PAD> token and predict if the input text is by human or generated based on the probability of speciﬁc word “Positive” and “Negative” in the output word probability distribution.
The detailed training conﬁguration of T5-Sentinel can be found in table 2.
5 Evaluation
5.1 Evaluation Metric
In our study, we assess the performance of the RoBERTa-Sentinel and T5-Sentinel through the application of ﬁve distinct evaluation metrics, namely the F1 score, receiver operating characteristic (ROC) curve, detection error trade-off (DET), area under curve (AUC), and model conﬁdence score. In this paper, the term “positive” refers to the input text is ChatGPT-generated, while “negative” , means that the data is written by human.
Given the true positive (T P ), true negative (T N ), false positive (F P ) and false negative (F N ) count, we can calculate the metrics as following:
F1 Score =
T P
T P + 1
2 (F P + F N )
TPR =
T P T P + F N
FPR =
F P F P + T N
TNR =
T N T N + F P
FNR =
F N F N + T P
5.2 F1 Score, False Positive Rate and False Negative Rate
The F1 score, false positive rate and false negative rate of RoBERTa-Sentinel and T5-Sentinel is evaluated on original data set (OpenGPTText), cleaned data set (OpenGPTText-Final), and the GPT2-Output1 data set [16]. The evaluation results when taking 0.5 as the threshold probability for positive are shown in the table 3. For more detailed data on evaluation result, we included the true positive rate, true negative rate and sample count for each metric in table 6 in appendix B.
An important observation is that even though T5-Sentinel and RoBERTa-Sentinel models exhibit high accuracy in the OpenGPTText data set, both prior to and post cleaning, they do not perform as effectively on the GPT2-Output data set, displaying an exceptionally high FNR. This disparity may be attributed to the distinctive quality of text generated by GPT2 and ChatGPT models, as well as the dissimilar nature of the samples in the OpenGPTText data set, which are all rephrased from
1There exist multiple variants of GPT2-Output data set, unless explicitly stated otherwise, in this paper we
refer to the GPT2-Output data set with GPT2 Extra Large (1542M parameter) with pure sampling method.
6


Table 3: The evaluation result for T5-Sentinel, RoBERTa-Sentinel, ZeroGPT [17], OpenAI-Detector [18], and GPT-2 Detector from Solaiman et al. [4] on three data sets under threshold probability of 0.5. F1 stands for “F1-score”. FPR and FNR data are in percentage.
Model
OpenGPTText-Final
OpenGPTText
GPT2-Output
F1
FPR
FNR
F1
FPR FNR
F1
FPR FNR
T5 RoBERTa
0.98 0.94
2.8 9.0
1.3 3.2
0.98 0.89
3.5 21.6
1.3 1.9
0.06 0.16
5.9 17.2
96.7 89.6
ZeroGPT OpenAI-Detector GPT2
0.43 0.32 0.23
26.3 4.9 2.8
65.0 79.8 86.8
0.40 0.26 0.22
16.5 1.6 4.1
71.3 85.2 87.2
0.14 0.66 0.93
23.4 13.6 6.4
90.5 44.0 7.4
Table 4: AUC Value for each combination of data set and model
Model
OpenGPTText-Final
OpenGPTText
GPT2-Output
T5-Sentinel RoBERTa-Sentinel
0.993 0.986
0.992 0.976
0.463 0.423
ZeroGPT OpenAI-Detector GPT2-Detector
0.526 0.765 0.610
0.555 0.752 0.600
0.413 0.770 0.976
human-written articles, in contrast to the GPT2-Output data set that contains randomly generated text.
Likewise, it is worth noting that the baseline model, GPT2-Detector by Solaiman et al., did not succeed in transferring its learned experience from the GPT2 output detection task to the task of detecting ChatGPT generated text, despite the ﬁndings presented in [4], which indicate that GPT2-Detector is capable of detecting diverse variants of the GPT2 model.
5.3 ROC / DET Curve and AUC
The ROC curve is a common graph used to evaluate and compare classiﬁers and can explicitly visualize the sensitivity/speciﬁcity trade-off of classiﬁer for all thresholds [19]. The ROC curve of T5-Sentinel, RoBERTa-Sentinel and GPT2-Detector on OpenGPTText, OpenGPTText-Final and GPT2-Output are shown in ﬁgure 4 separately. Upon analyzing the ROC curves for the same model across different data sets, as illustrated in Figure 5, we observe that the T5-Sentinel demonstrates greater robustness as compared to RoBERTa-Sentinel.
The area under curve (AUC) is a single-number summary for the ROC curve. The AUC result for each combination of model and dataset is listed in table 4.
We also plot the detector error trade-off (DET) curves across different models (ﬁgure 6) and across different data sets (ﬁgure 7).
ZeroGPT
0.6
0.4
GPT2-Detector
0.8
T5-Sentinel
1.0True Positive Rate
0.6
OpenAI-Detector
0.8
0.0
0.0
0.2
0.2
RoBERTa-Sentinel
ROC Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPTOpenAI-Detector and GPT2-Detector on OpenGPTText-Final
0.4
1.0False Positive Rate
RoBERTa-Sentinel
0.2
0.0
OpenAI-Detector
0.6
1.0False Positive Rate
1.0True Positive Rate
0.2
ZeroGPT
0.8
ROC Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPTOpenAI-Detector and GPT2-Detector on OpenGPTText
0.4
GPT2-Detector
0.6
T5-Sentinel
0.8
0.0
0.4
0.0
RoBERTa-Sentinel
0.0
OpenAI-Detector
1.0True Positive Rate
ROC Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPTOpenAI-Detector and GPT2-Detector on GPT2-Output
ZeroGPT
0.6
0.6
0.4
0.4
GPT2-Detector
0.2
1.0False Positive Rate
0.2
0.8
T5-Sentinel
0.8
Figure 4: ROC Curves for models across different data sets. OpenGPTText-Final (Left), OpenGPTText (Middle), and GPT2-Output (Right)
7


0.2
1.0False Positive Rate
0.2
0.4
0.4
0.6
0.0
OpenGPTText-Final
0.0
1.0True Positive Rate
0.8
0.8
OpenGPTText
0.6
GPT2-Output
ROC Curves of T5-Sentinel Across Three Data Sets
0.4
0.4
ROC Curves of RoBERTa-Sentinel Across Three Data Sets
1.0False Positive Rate
1.0True Positive Rate
0.0
0.0
OpenGPTText
0.2
0.2
0.8
0.8
GPT2-Output
0.6
0.6
OpenGPTText-Final
Figure 5: ROC Curves for same model under different data sets T5-Sentinel (Left) and RoBERTa- Sentinel (Right). Note that the performance of RoBERTa-Sentinel signiﬁcantly deteriorates when transfer to original version of OpenGPTText while T5-Sentinel does not.
RoBERTa-Sentinel
GPT2-Detector
False Negative Rate
100
OpenAI-Detector
ZeroGPT
103
103
102
T5-Sentinel
False Positive Rate
100
101
102
DET Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPT OpenAI-Detector GPT2-Detector on OpenGPTText-Final
101
101
False Negative Rate
GPT2-Detector
ZeroGPT
100
100
RoBERTa-Sentinel
DET Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPT OpenAI-Detector and GPT2-Detector on OpenGPTText
103
101
False Positive Rate
OpenAI-Detector
102
103
T5-Sentinel
102
ZeroGPT
GPT2-Detector
100
T5-Sentinel
101
101
RoBERTa-Sentinel
OpenAI-Detector
False Positive Rate
DET Curves of T5-Sentinel, RoBERTa-Sentinel, ZeroGPTOpenAI-Detector and GPT2-Detector on GPT2-Output
103
103
100
102
102
False Negative Rate
Figure 6: DET Curves of different models under OpenGPTText-Final (Left), OpenGPTText (Mid- dle) and GPT2-Output (Right) under logarithmic axis.
5.4 Conﬁdence Score
Assessing the reliability and conﬁdence of a machine learning model’s predictions is crucial for evaluating its performance. To this end, we calculated conﬁdence scores for each combination of data sets and models, and plot them in ﬁgure 8. The resulting conﬁdence scores range from 0 to 1 and provide a measure of the model’s certainty about its predictions.
In our analysis, we investigated the distribution of conﬁdence scores and their correspondence with accuracy. Our result indicates that the T5-Sentinel model achieved higher conﬁdence scores compared to RoBERTa-Sentinel. In contrast, the RoBERTa-Sentinel model had lower conﬁdence scores than T5-Sentinel and showed greater conﬁdence when detecting text generated by human than that by Chat-GPT.
Overall, our ﬁndings suggest that the T5-Sentinel model is more reliable and decisive than RoBERTa- Sentinel, particularly when dealing with OpenGPTText. Further investigation is needed to fully understand the reasons for these differences and to optimize the performance of these models for speciﬁc applications.
False Positive Rate
103
102
103
OpenGPTText
False Negative Rate
101
101
GPT2-Output
102
100
DET Curves of T5-Sentinel Across Three Data Sets
OpenGPTText-Final
100
False Negative Rate
OpenGPTText
102
101
OpenGPTText-Final
DET Curves of RoBERTa-Sentinel Across Three Data Sets
102
GPT2-Output
101
False Positive Rate
100
100
103
103
Figure 7: DET Curves of T5-Sentinel (Left) and RoBERTa-Sentinel (Right) on different data sets.
8


0.8
60
1500
1000
100Confidence level (%)
3000Data Count
0.6
80
40
0.4
20
0
0
2500
OpenGPTText
1.0
0.0
2000
0.2
500
OpenGPTText-Final
Confidence level of T5-Sentinel on OpenGPTText-Final, OpenGPTText data sets
0.6
OpenGPTText
0
2000Data Count
0
OpenGPTText-Final
1500
100Confidence level (%)
0.0
80
20
0.4
1.0
40
Confidence level of RoBERTa-Sentinel on OpenGPTText-Final, OpenGPTText data sets
0.2
500
0.8
1000
60
Figure 8: Conﬁdence Scores for T5-Sentinel and RoBERTa-Sentinel on OpenGPTText-Final and OpenGPTText data set. The histogram represents the number of sample under certain range of probability for the sample to be positive.
10
0
0
4
OpenWebText
8
4
4
2
PCA projection of decoder hidden stateT5-Sentinel on OpenGPTText-Final
OpenGPTText
6
2
6
4
6
6
2
2
OpenWebText
5
4
2.0
2.0
PCA projection of hidden state ofRoBERTa-Sentinel on OpenGPTText-Final
3
1.5
1.5
0.0
1
4
3
0
1
0.5
1.0
2
2
OpenGPTText
0.5
1.0
Figure 9: PCA projection of hidden states for T5-Sentinel (Left) and RoBERTa-Sentinel (Right)
6
Interpretability Study
6.1 Principal Component Analysis on Hidden State
To offer greater insight into the functioning of the models we proposed, T5-Sentinel and RoBERTa- Sentinel, we conducted a PCA on their respective hidden states.
For RoBERTa-Sentinel, we extracted the hidden state from last layer of attached MLP and the output of last decoder block for T5-Sentinel and recorded their values with input of all data in test set sampled from OpenGPTText-Final. As shown in ﬁgure 9, both models successfully mapped the input text into two different clusters in hidden space, indicating that both models were able to extract implicit characteristics of ChatGPT rephrased text.
To investigate the properties of the data along each direction of the projection subspace, we conducted a sampling of the data point outliers in the PCA projection subspace.
Figure 10 displays the position of four samples in the PCA projection subspace. Upon manual inspection of these samples, we discovered that Sample 1 was a brief car advertisement that utilized simple language and comprised of very short paragraphs (split by images in the original web page). Sample 2 was a sport news article with lengthy paragraphs, while Sample 3 constituted a sequence of developing tool names that lacked any actual meaning. Sample 4 was a brief report on children’s attitudes towards clowns. These observations suggest that our model may have learned to distinguish the length of paragraphs and potentially discern whether a given text sample is informative and meaningful. We have provided detailed textual samples along with their unique identiﬁers (UIDs) from the OpenGPTText data set in Appendix B.
9


0
0
Outliers in Hidden Feature Space after PCARoBERTa-Sentinel on OpenGPTText-Final Dataset
3
4
4
1
1
Sample 1
Sample 2
OpenGPTText
2
2
2
2
Sample 4
Sample 3
OpenWebText
6
Figure 10: Outliers in PCA projection space drawn for manual inspection.
6.2
Integrated Gradient
We utilized the integrated gradient analysis technique, as proposed by Sundararajan et al. [20], to gain insights into the contribution of individual tokens in a given input text towards the overall “GPT-ness” of the text. Our approach involved initially passing the input text through the model and computing the loss function under the assumption that the text label was “human”. Following this, we executed back-propagation to obtain the gradients associated with each input token. This statement conformed to the formal style and technical language typically employed in academic writing.
The rationale underlying our method is rooted in the observation that tokens with gradients close to zero tend to align well with the human label, thereby necessitating minimal modiﬁcation. Conversely, tokens with large gradients are indicative of a misalignment with the human label, suggesting a higher degree of resemblance to GPT-like characteristics.
We further developed a visualization tool that shows the contribution of each input token to the overall GPT-ness of the text. The darker the background token is, the more GPT-like that token is. Below we show a sample2 visualization result drawn from the test set of OpenGPTText-Final data set before and after the rephrasing.
Original Text: Predict as human with probability of 0.998, with conﬁdence of 0.994
Apple started an ava lan che of activity with the introduction of the iPad . Companies shifted gear s to go after this un discovered new tablet market . In spite of the number of players in tablets , no company has discovered the magic bullet to knock the iPad off the top of the tablet heap . Col league Adrian Kings ley - H ugh e s has a thoughtful piece bla m ing Amazon and Google for killing the tablet market . His reasoning is that by releasing the Kindle Fire and the Nex us 7 at $1 99 , Amazon and Google have started a " race to the bottom " of the tablet market that will ensure no profitability for anyone . Adrian ’ s reasoning is solid , but it overlook s one thing I have said for a long time . There is no proven tablet market . (... Truncated)
Rephrased Text: Predict as generated with probability of 1.000, with conﬁdence of 0.985
2With data unique identiﬁer (UID): [urlsf_subset00]-[309279]
10


t-SNE Plot on Hidden State of T5-Sentinelon OpenGPTText-Final
0
OpenGPTText
40
0
60
60
40
20
20
20
20
40
OpenWebText
40
0
80
60
80
0
60
OpenGPTText
40
40
40
40
OpenWebText
t-SNE Plot on Hidden State of RoBERTa-Sentinelon OpenGPTText-Final
20
20
20
20
Figure 11: Hidden states of T5-Sentinel (Left) and RoBERTa-Sentinel (Right) on urlsf-04 subset of OpenGPTText-Final after t-SNE dimensionality reduction.
Following the release of the iPad , the tablet market became a popular area for companies to explore . Despite many companies entering the market , no one has managed to out per form the iPad on sales . There is a belief that Amazon and Google have caused this , due to the release of the Kindle Fire and Nex us 7 at $1 99 , starting a " race to the bottom ." There is a concern that this will ensure there will be no profitability for anyone . However , this belief overlook s the fact that there is no proven market for tablets , only a proven market for iPad s . Other than Apple , Samsung is the only company with notable tablet sales . Even though they released several tablets , in various shapes and sizes , they still could not compete with the iPad . (...Truncated)
6.3
t-distributed Stochastic Neighbor Embedding Visualization
t-distributed Stochastic Neighbor Embedding (t-SNE) projection proposed by Maatan et al. [21] is applied on the hidden state vector of both T5-Sentinel and RoBERTa-Sentinel. Results in ﬁgure 11 indicate that T5-Sentinel model can better separate the data set, which aligns with the performance of both models on test data set.
7 Future Work
Although our current model has shown promising results, there are certain limitations in our current model. First and foremost, both T5-Sentinel and RoBERTa-Sentinel are trained with English corpus only. As a result, their performance on other languages such as Spanish or Chinese may not be optimal. To address this limitation, ﬁne-tuning the models with non-English text can be helpful. However, it’s worth noting that the pretrained version of the T5 model only supports English, French, Romanian, and German. Therefore, classiﬁcation tasks involving languages other than these may require more than just ﬁne-tuning alone.
In addition, the OpenGPTText-Final data set is collected with the prompt “Rephrase the fol- lowing paragraph by paragraph”, so the model trained on such data set might not perform well to other language tasks that ChatGPT is popularly used on, such as question answering or text generation. In the future, we plan to collect data sets involving a different textual context, like eli5 [22] and SQuAD [23], to further assess the accuracy of the RoBERTa-Sentinel and T5-Sentinel on different tasks.
8 Conclusion
In conclusion, we have introduced a high-quality data set called OpenGPTText, which we have rephrased using the ChatGPT model. Additionally, we have designed, implemented, and trained
11


two text classiﬁcation models using RoBERTa and T5 architectures. Our models have achieved remarkable results, with accuracy exceeding 97% on the test data set, as evaluated using various metrics.
Moreover, we have conducted an interpretability study to demonstrate our models’ ability to extract and differentiate key features between human-written and ChatGPT-generated text. The study’s results show that our models are effective in identifying the differences between the two types of text, providing insight into the strengths and limitations of the models and demonstrating their potential for real-world applications.
9 Acknowledgement
We would like to express our sincere appreciation to Professor Bhiksha Raj and our TA mentor Liangze (Josh) Li for their invaluable guidance, insightful comments, and constant support throughout the course of this research. Their expertise in the ﬁeld have been instrumental in shaping our work.
References
[1] Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks V. S. Lakshmanan. Automatic detection
of machine generated text: A critical survey. CoRR, abs/2011.01314, 2020.
[2] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback, 2022.
[3] Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks V. S. Lakshmanan. Automatic detection
of machine generated text: A critical survey. CoRR, abs/2011.01314, 2020.
[4] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGufﬁe, and Jasmine Wang. Release strategies and the social impacts of language models, 2019.
[5] Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, and Douglas Eck. Automatic In Annual Meeting of the
detection of generated text is easiest when humans are fooled. Association for Computational Linguistics, 2019.
[6] Sebastian Gehrmann, Hendrik Strobelt, and Alexander M. Rush. GLTR: statistical detection
and visualization of generated text. CoRR, abs/1906.04043, 2019.
[7] Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roes- ner, and Yejin Choi. Defending against neural fake news. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Informa- tion Processing Systems, volume 32. Curran Associates, Inc., 2019.
[8] Aaron Gokaslan and Vanya Cohen. Openwebtext corpus. http://Skylion007.github.io/
OpenWebTextCorpus, 2019.
[9] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language
models are unsupervised multitask learners. In NeurIPS, 2019.
[10] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019.
[11] Dan Hendrycks and Kevin Gimpel. Bridging nonlinearities and stochastic regularizers with
gaussian error linear units. ArXiv, abs/1606.08415, 2016.
[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR, abs/1810.04805, 2018.
[13] Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. CoRR,
abs/1711.05101, 2017.
12


[14] Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradient descent with restarts. CoRR,
abs/1608.03983, 2016.
[15] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. CoRR, abs/1910.10683, 2019.
[16] OpenAI. Gpt2-output. https://github.com/openai/gpt-2-output-dataset, 2019. [17] ZeroGPT. AI Detector. https://www.zerogpt.com, January 2023. [18] OpenAI. https://beta.openai.com/ai-text-classifier, January 2023. [19] Francisco Melo, Werner Dubitzky, Olaf Wolkenhauer, Kwang-Hyun Cho, and Hiroki Yokota. Receiver Operating Characteristic (ROC) Curve, pages 1818–1823. Springer New York, New York, NY, 2013.
[20] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In
International Conference on Machine Learning, 2017.
[21] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine
Learning Research, 9:2579–2605, 2008.
[22] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: long form question answering. In Anna Korhonen, David R. Traum, and Lluís Màrquez, editors, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages 3558–3567. Association for Computational Linguistics, 2019.
[23] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ ques- tions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383–2392, Austin, Texas, November 2016. Association for Computational Linguistics.
13


Table 5: Baseline evaluation on GPT2-output data set
Small
Medium
Large
Extra Large
Metrics
top-k
pure
top-k
pure
top-k
pure
top-k
pure
Accuracy False Positive False Negative
0.9648 0.0070 0.0319
0.9623 0.0122 0.0319
0.9627 0.0114 0.0319
0.9567 0.0238 0.0319
0.9616 0.0137 0.0319
0.9449 0.0472 0.0319
0.9498 0.0376 0.0319
0.9310 0.0734 0.0319
Figure 12: Confusion matrices of baseline model on GPT2-output data set under pure sampling method
A GPT2-Detector Baseline Analysis
A.1 Evaluation on GPT2-Baseline
We reproduced the GPT2-Detector proposed by Solaiman et al. [4] as the baseline model and performed evaluation on GPT2 output data set released by OpenAI [16]. The results are shown below.
The GPT2-output data set contains random output from four variants of GPT2 model: small (117M parameter), medium (354M parameter), large (762M parameter) and extra-large (1542M parameter) and we have evaluate our baseline model on all of them. The result is shown in table 5.
The confusion matrices for every variant (small, medium, large, extra-large) and every sampling method (top-k and pure) is shown in ﬁgure 12 and ﬁgure 13.
A.2 Trend Between Language Model Scale and Classiﬁcation Accuracy
When running baseline test of GPT2-Detector, we noticed that there is an approximately linear relationship between classiﬁcation accuracy and the scale of language model, as illustratd in 14.
A.3 PCA Analysis for Baseline Model
Despite the baseline model’s strong performance in detecting GPT-2 generated content, it encounters signiﬁcant challenges when tasked with detecting GPT-3.5 generated content. In fact, without any additional training, the baseline model achieved a mere 54.98% accuracy on the OpenGPTText dataset, only slightly better than random chance. This signiﬁcant drop in accuracy highlights the challenges of differentiating between human-generated and GPT-3.5 generated content, likely due to the increased complexity of the GPT-3.5 model.
14


Figure 13: Confusion matrices of baseline model on GPT2-output data set under top-k sampling (k = 40)
0.20
0.05
1200
800
1200
0.0070.0120.0110.0230.0130.0460.0370.074False positive rate v.s. #Parameters in GPT2 variants
0.80
0.95
0.85
1600#Parameter in GPT2 variant (Million)
1600#Parameter in GPT2 variant (Million)
400
0.90
800
200
1400
200
600
600
1000
1000
1.00Accuracy
1400
0.9620.9650.9570.9630.9450.9620.9310.95Accuracy v.s. #Parameters in GPT2 variants
0.00
Top-k Sampling (k=40)
Top-k Sampling (k=40)
0.25False Negative Rate
0.15
400
0.10
Random Sampling
Random Sampling
0.75
Figure 14: As the number of parameter in language model increase, the detector’s accuracy decreases linearly, while the false positive rate increases.
Figure 15: PCA Projection: GPT-2 vs. GPT-3.5 Turbo
15


Another notable observation is the difference in PCA projections between GPT-2 and GPT-3.5 generated content. The PCA projection for GPT-2 indicates that human-generated and GPT-2 generated content are clearly distinguishable from each other. However, the same distinction is not as clear in the GPT-3.5 projection, as shown in ﬁgure 15.
16


Table 6: Evaluation Result on OpenGPTText-Final (Row 1-3), OpenGPTText-Original (Row 4-7), and GPT2-Output (Row 8-11). TPR stands for “True Positive Rate”, TPC stands for “True Positive Count”, TNR stands for “True Negative Rate”, TNC stands for “True Negative Count”.
Model
Accuracy
TPR, (TPC)
TNR, (TNC)
FPR, (FPC)
FNR, (FNC)
T5 RoBERTa OpenAI ZeroGPT GPT2
97.98% 98.71%, (2906) 93.92% 96.81%, (2850) 57.68% 20.24%, (596) 54.36% 34.99%, (1030) 13.21%, (389) 38.5%
97.25%, (2863) 91.03%, (2680) 95.11%, (2800) 73.74%, (2171) 97.16%, (1233)
2.75%, (81) 8.97%, (264) 4.89%, (144) 26.26%, (773) 2.84%, (36)
1.29%, (38) 3.19%, (94) 79.76%, (2348) 65.01%, (1914) 86.79%, (2555)
T5 RoBERTa OpenAI ZeroGPT GPT2
97.64% 98.74%, (2907) 88.28% 98.13%, (2889) 14.84%, (437) 56.64% 28.67%, (844) 56.1% 12.84%, (378) 37.86%
96.54%, (2842) 78.43%, (2309) 98.44%, (2898) 83.53%, (2459) 95.9%, (1217)
3.46%, (102) 21.57%, (635) 1.56%, (46) 16.47%, (485) 4.1%, (52)
1.26%, (37) 1.87%, (55) 85.16%, (2507) 71.33%, (2100) 87.16%, (2566)
T5 RoBERTa OpenAI ZeroGPT3 GPT2
3.3%, (165) 48.68% 46.56% 10.36%, (518) 71.22% 56.02%, (2801) 43.09% 93.1%
9.52%, (476) 92.58%, (4629)
94.06%, (4703) 82.76%, (4138) 86.42%, (4321) 76.64%, (3832) 93.62%, (4681)
5.94%, (297) 17.24%, (862) 13.58%, (679) 23.36%, (1168) 6.38%, (319)
96.7%, (4835) 89.64%, (4482) 43.98%, (2199) 90.48%, (4522) 7.42%, (371)
B Detailed Information for Evaluation
B.1 Evaluation Result
As shown in table 5. The metrics are calculated under the positive probability threshold of 0.5.
B.2 Content Sample
B.2.1 Sample 1 - [urlsf_subset04]-[236996]-web
Lexus IS 250 is the entry model among IS sedans . Pictured is the
optional F Sport package that firms already stiff suspension and adds some distinguishing visuals . ( Photo11 : Lexus )
Lexus gave us enough go - fast imagery in its Super Bowl ads last Sunday
that it almost seemed to be saying , " See , see , are too sporty ." And , yes , some malingerers still might be insisting , " Are not ," and
need nudging .
After all , Lexus ’ reputation for years has been luxury at the expense of handling and performance . But the brand is trying to transform so
that you ’ ll compare it with BMW instead of Buick .
The ES , at the lower end , and the LS , at the top , still could be
considered luxo - machines more than yippee - mobiles . But most Lexus models we ’ ve driven lately behave in sporty fashion when prodded that direction by the driver .
(... Truncated )
B.2.2 Sample 2 - [urlsf_subset04]-[246672]-gpt
After succumbing to a hip injury , Nick Kyrgios has come to the
decision to take rest and heal . This has led him to reflect on 2017 , with its highs and lows , from consecutive wins against great tennis players to the difficulties he faced at Grand Slams . However , his fondest memories were from team events , particularly the Laver Cup and the Davis Cup . Kyrgios reveals that tennis can be a lonely sport , and he often struggles with it . However , he praises the team
3ZeroGPT failed to process two data entries (with ID: 255332 and 258673 in xl-1542M.test.jsonl) in
the GPT2-Output data set, those two entries are not counted in the calculation of metrics.
17


spirit in Davis Cup , highlighting how they all support each other , win or lose , and says it made him feel like he was part of the team .
Rusty , Davis Cup captain , created a WhatsApp group a year and a half
ago , which includes all the Davis Cup players . Kyrgios recounts how ,
after his semi - final win in Beijing , his phone was flooded with
loyal messages from the coaches and players . This sparked his realization that it had become bigger than tennis , and they had become a family trying to keep in touch no matter how far apart they
all were . He feels it has helped provide a support system for everyone , both on and off the court , at a time when they really needed it the most .
(... Truncated )
B.2.3 Sample 3 - [urlsf_subset04]-[230559]-web
Add DevOps Tools to your Pipeline Densify XL Impact Bitbucket Bitbucket Server Bower Crucible Deveo
Fisheye Gerrit Git GitHub GitLab Gogs Helix ISPW Kallithea Mercurial
Micro Focus AccuRev Micro Focus StarTeam Perforce HelixCore
Rational Clearcase Rational Team Concert Subversion Team Foundation Server Team Foundation Version Control
(... Truncated )
Kubernetes Engine Kubernetes Linux Containers Marathon Mesos
Mesosphere DC / OS Nomad OpenVZ Portainer Rancher Solaris Containers Supergiant Swarm Sysdig Tectonic Weaveworks rkt OpsGenie DBmaestro Datical Delphix Flyway Idera Liquibase Quest Toad Redgate Redgate SQL Toolbelt
Add tools from the Periodic Table of DevOps or select from the full
list above .
Click " Visualize My Pipeline !" to view your pipeline in the DevOps
Diagram Generator .
B.2.4 Sample 4 - [urlsf_subset04]-[313139]-web
A carnival reveller dressed as a clown celebrates on the street in
Berlin February 18 , 2007. REUTERS / Pawel Kopczynski
LONDON ( Reuters ) - Bad news for Coco and Blinko -- children don ’ t like
clowns and even older kids are scared of them .
The news that will no doubt have clowns shedding tears was revealed in
a poll of youngsters by researchers from the University of
Sheffield who were examining how to improve the decor of hospital children ’ s wards .
The study , reported in the Nursing Standard magazine , found all the
250 patients aged between four and 16 they quizzed disliked the use of clowns , with even the older ones finding them scary .
" As adults we make assumptions about what works for children ," said Penny Curtis , a senior lecturer in research at the university .
" We found that clowns are universally disliked by children . Some found
them quite frightening and unknowable ."
( End of File )
18