{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Large_Language_Models_Enable_Few-Shot_Clustering_2024-02-27_01-10-55_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of using an LLM in the text?,        answer: To generate keyphrases relevant to the clustering need.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " How are keyphrases generated in the text?,        answer: Keyphrases are generated by a large language model.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " How are keyphrases encoded in the text?,        answer: Keyphrases are encoded by an embedding model and concatenated to the original document embedding.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " What is the purpose of using a BERT encoder in entity clustering?,        answer: To specialize in clustering Wikipedia sentences.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " What is the purpose of pairwise constraint clustering?,        answer: To ensure that clusters follow the grouping described by a user or an oracle.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " How does the Explore-Consolidate algorithm work in text clustering?,        answer: It collects a diverse set of pairs from embedding space to identify linked points and nearby points to find points that cannot be linked.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " What is the role of the pseudo-oracle LLM in clustering?,        answer: To amplify expert guidance by providing constraints for clustering.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " How are clusters generated using pairwise constraints?,        answer: Clusters are generated with the PCKMeans algorithm by applying penalties for cluster assignments that violate constraints.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " What is the purpose of reranking low-confidence points in clustering?,        answer: To improve cluster quality by potentially reassigning points to more suitable clusters based on LLM predictions.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}, {"question": " What is the task of entity canonicalization described in the text?,        answer: To group noun phrases into subgroups that refer to the same entity.    ", "ref_chunk": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}], "doc_text": "to globally highlight these aspects (and thereby specify the task em- phases) beforehand. To do so, we use an LLM to make every document\u2019s textual representation task- dependent, by enriching and expanding it with evi- dence relevant to the clustering need. Specifically, each document is passed through an LLM which generates keyphrases, these keyphrases are en- coded by an embedding model, and the keyphrase embedding is then concatenated to the original doc- ument embedding. Keyphrases:[\"card status\",\"card location\"] Text:How do I locate my card? OriginalVector KeyphraseVector Figure 2: We expand document representations by concatenating them with keyphrase embeddings. The keyphrases are generated by a large language model. We generate keyphrases using GPT-3 (specifi- cally, gpt-3.5-turbo-0301). We provide a short prompt to the LLM, starting with an instruction (e.g. \u201cI am trying to cluster online banking queries based on whether they express the same intent. For each query, generate a comprehensive set of keyphrases that could describe its intent, as a JSON-formatted list.\u201d). The instruction is followed by four demon- strations of keyphrases (example shown in Fig- ure 2). Examples of full prompts are shown in Appendix B. We then encode the generated keyphrases into a single vector, and concatenate this vector with the original document\u2019s text representation. To disen- tangle the knowledge from an LLM with the bene- fits of a better encoder, we encode the keyphrases using the same encoder as the original text.2 2An exception to this is entity clustering. There, the BERT encoder has been specialized for clustering Wikipedia sen- 2.2 Pseudo-Oracle Pairwise Constraint Clustering We explore the situation where a user conceptually describes which kinds of points to group together and wants to ensure the final clusters follow this grouping. Arguably, the most popular approach to semi- supervised clustering is pairwise constraint cluster- ing, where an oracle (e.g. a domain expert) selects pairs of points which must be linked or cannot be linked (Wagstaff and Cardie, 2000), such that more abstract clustering needs of experts can be implic- itly induced from the concrete feedback. We use this paradigm to investigate the poten- tial of LLMs to amplify expert guidance during clustering, using an LLM as a pseudo-oracle. To select pairs to classify, we take different strategies for entity canonicalization and for other text clustering tasks. For text clustering, we adapt the Explore-Consolidate algorithm (Basu et al., 2004) to first collect a diverse set of pairs from embedding space (to identify pairs of points that must be linked), then collect points that are nearby to already-chosen points (to find pairs of points that cannot be linked). For entity canonicalization, where there are so many clusters that very few pairs of points must be linked, we simply identify the closest distinct pairs of points in embedding space. We prompt an LLM with a brief domain-specific instruction (provided in entirety in Appendix A), followed by up to 4 demonstrations of pairwise con- straints, obtained from test set labels. We use these pairwise constraints to generate clusters with the PCKMeans algorithm of Basu et al. (2004). This algorithm applies penalties for cluster assignments that violate any constraints, weighted by a hyperpa- rameter w. Following prior work (Vashishth et al., 2018), we tune this parameter on each dataset\u2019s validation split. 2.3 Using an LLM to Correct a Clustering We finally consider the setting where one has an existing set of clusters, but wants to improve their quality with minimal local changes. We use the same pairwise constraint pseudo-oracle as in sec- tion 2.2 to achieve this, and we illustrate this pro- cedure in Figure 3. We identify the low-confidence points by finding the k points with the least margin between the near- est and second-nearest clusters (setting k = 500 tences, so we use DistilBERT to support keyphrase clustering. \uff1f 3rd Closest Cluster Current Cluster 2nd Closest Cluster Figure 3: After performing clustering, we identify low- confidence points. For these points, we ask an LLM whether the current cluster assignment is correct. If the LLM responds negatively, we ask the LLM whether this point should instead be linked to any of the top-5 nearest clusters, and correct the clustering accordingly. for our experiments). We textually represent each cluster by the entities nearest to the centroid of that cluster in embedding space. For each low- confidence point, we first ask the LLM whether or not this point is correctly linked to any of the representative points in its currently assigned clus- ter. If the LLM predicts that this point should not be linked to the current cluster, we consider the 4 next-closest clusters in embedding space as candi- dates for reranking, sorted by proximity. To rerank the current point, we ask the LLM whether this point should be linked to the representative points in each candidate cluster. If the LLM responds positively, then we reassign the point to this new cluster. If the LLM responds negatively for all al- ternative choices, we maintain the existing cluster assignment. 3 Tasks 3.1 Entity Canonicalization In entity canonicalization, we must group Task. a collection of noun phrases M = {mi}N 1 into sub- groups {Cj}K 1 such that m1 \u2208 Cj and m2 \u2208 Cj if and only if m1 and m2 refer to the same entity. For example, the noun phrases President Biden (m1), Joe Biden (m2) and the 46th U.S. President (m3) should be clustered in one group (e.g., C1). The set of noun phrases M are usually the nodes of an \u201copen knowledge graph\u201d produced by an OIE system.3 Unlike the related task of entity link- ing (Bunescu and Pasca, 2006; Milne and Witten, 3Open Information Extraction (OIE) is the task of extract- ing surface-form (subject; relation; object)-triples from nat- ural language text in a schema-free manner (Banko et al., 2007). 2008), we do not assume that any curated knowl- edge graph, gazetteer, or encyclopedia contains all the entities of interests. Entity canonicalization is valuable for motivat- ing the challenges of semi-supervised clustering. Here, there are hundreds or thousands of clusters and relatively"}