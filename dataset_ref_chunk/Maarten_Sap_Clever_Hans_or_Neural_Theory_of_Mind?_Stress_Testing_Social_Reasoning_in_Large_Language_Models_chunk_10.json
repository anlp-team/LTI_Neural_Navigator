{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Maarten_Sap_Clever_Hans_or_Neural_Theory_of_Mind?_Stress_Testing_Social_Reasoning_in_Large_Language_Models_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What type of belief does the unexpected transfer test discuss?", "answer": " The unexpected transfer test discusses a false belief rather than a true belief.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " Why does ChatGPT solve the false belief task but fails on the true belief task?", "answer": " ChatGPT likely fails on the true belief task due to its exposure to the Salley-Anne task.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " What variations proposed by Ullman are illustrated in Figures 6 and 7?", "answer": " Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " What setup was used as input to the LLMs for the prompts?", "answer": " An MC-probing setup, which involves concatenation of the original test with all possible answers and an instruction to choose an option, was used as input to the LLMs for the prompts.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " In the false belief scenario with Natalie and Michal, where does Natalie mistakenly think the ring is?", "answer": " Natalie mistakenly thinks the ring is still in box A, where she initially put it.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " Why does the triangle hesitate to open the door in the example from the Triangle COPA task?", "answer": " The triangle hesitates to open the door because it is unsure if it wants to let the circle in.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " In the story with Abby and her father, did someone say something that they should not have said?", "answer": " No", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " What decoding parameters were selected for the analysis of the stories?", "answer": " Hyperparameters were chosen to minimize randomness, predict the most probable answer, and allow for a sufficient number of tokens.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " According to the results obtained from the well-organized code, how did task 2 (Unexpected Transfer Task) score compared to the reported score for GPT 3.5?", "answer": " Task 2 scored lower than reported for GPT 3.5, with either 85% or 90% accuracy.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}, {"question": " What is the purpose of using a second, secret test set for SocialIQa?", "answer": " The purpose of the second, secret test set for SocialIQa is to determine whether LLMs generalize or memorize when they solve the ToM tasks and to avoid data contamination.", "ref_chunk": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}], "doc_text": "shows an example from the Tomi dataset. The unexpected transfer test discusses an unex- pected (false belief) rather than trivial (true belief) case. ChatGPT solves the more complex task (false belief) while failing on the trivial task, likely due to its exposure to the Salley-Anne task. 8.2 Ullman\u2019s Variations Figures 6 and 7 illustrate the variations proposed by Ullman for the examples in ToM-k. 8.3 Generative LLMs We provide the technical details regarding the prompts (\u00a78.3.1) and decoding parameters (\u00a78.3.2). 8.3.1 Prompts As input to the LLMs, we used (unless written oth- erwise) an MC-probing setup (\u00a74.2), i.e., concate- nation of the original test with all possible answers and an instruction to choose an option. Table 6 exemplifies the prompt for each task. False Belief (Positive Example) True Belief (Negative Example) Natalie and Michal are in the same room. Natalie puts a ring in box A. Natalie leaves the room. Michal opens box A, takes the ring from inside and transfers it to box B. Where will Natalie look for the ring? Natalie enters the room. Where will Natalie look for the ring? Natalie and Michal are in the same room. Natalie puts a ring in box A. Michal opens box A, takes the ring from inside and transfers it to box B. ChatGPT: Natalie will look for the ring in box A, where she initially put it. She is not aware of Michal\u2019s actions and assumes that the ring is still in the original box. Therefore, her natural inclination would be to look in the place where she left it. ChatGPT: Natalie will most likely look in box A, where she initially put the ring. Since Natalie did not witness Michal moving the ring to box B, she would assume that the ring is still in box A. It is possible that Natalie may eventually check box B, but her initial instinct would be to look in box A. Table 5: An example of ChatGPT failure on an instance from ToMi. Dataset Example Prompt Triangle COPA A circle knocks on the door. A triangle goes to the door, but hesitates to open it. Why does the triangle hesitate to open the door? a. The triangle hesitates to open the door because it is unsure if it wants to let the circle in. b. The triangle hesitates to open the door because it is excited to see the circle. Answer with \u201ca\u201d or \u201cb\u201d. Answer: epistemic reasoning Premise: Olivia suspects that Evelyn understands that a man plays a piano painted with an image of a woman on it. Hypothesis: Evelyn understands that a man plays a piano painted with an image of a woman on it. Is entailment? answer with \u201c0\u201d or \u201c1\u201d. Answer: FauxPas EAI Abby\u2019s father publishes short stories in the newspaper every week. She told him \u201cDad, I want to learn how to write just like you!\u201d and he replied: \u201cWell then my dear why don\u2019t you go to a writing class?\u201d Abby goes to a first lesson in a class she found and David the teacher says: \u201cToday we\u2019ll look at some bad and good examples of story-writing\u201d. He shows the class a story Abby\u2019s father wrote last week and says: \u201cAnd now I\u2019ll give you a good example of the writer Pichnik and you will say what the differences are.\u201d In the story did someone say something that they should not have said? Answer with \u201cYes\u201d or \u201cNo\u201d only, without explanations. In case of doubt, answer according to the most probable answer. Answer: Table 6: An example prompt used for each task. 8.3.2 Decoding Parameters A single sample (the first) was selected from each model for the analysis of the stories. We used the hyperparameters detailed below. We chose hyper- parameters that minimize randomness and predict the most probable answer (i.e., low temperature, sampling method), and allow for sufficient number of tokens. google/flan-t5-xl, google/flan-t5-xxl; ture=0.0001 tempera- 2022). Python FlanUl2 implementation package (T5ForConditionalGeneration, AutoTok- enizer); torch; Generation by generate function; tempera- do_sample=True; max_length=50; ture=0.0001 (Tay et transformers al., FlanT5 (Chung et al., 2022). Python pack- age transformers implementation (AutoMod- elForSeq2SeqLM, AutoTokenizer); torch; Gen- eration by generate function; do_sample=True; max_length=50, from_pretrained:google/flan-t5- small, google/flan-t5-base, google/flan-t5-large, GPT (Brown et al., 2020). Python package openai model=text-davinci-002, text-davinci-003; Generation by Completion.create function; temper- ature=0, max_tokens=50 14 Figure 6: An illustration of Ullman\u2019s Variations for the unexpected contents task. Image taken from Ullman (2023). Figure 7: An illustration of Ullman\u2019s Variations for the unexpected transfer task. Image taken from Ullman (2023). 15 ChatGPT.11 Python package openai model=gpt- 3.5-turbo-0301, gpt-4-0314; Generation by Chat- Completion.create function; temperature=0 AI21.12 Python package ai21 model=j2-jumbo- instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large; Generation by Completion.execute func- tion; topKRe- turn=0, topP=1, without any panalty temperature=0, max_tokens=50, 8.4 Complete Results Table 7 contains the exhaustive accuracy results for all LLMs on all datasets. Running the well-organized code provided by Kosinski (2023) we found that task 2 (Unexpected Transfer Task) scored lower than reported for GPT 3.5. Specifically, two samples resulted in clear mispredictions and one sample had borderline pre- dictions that provided the correct answer but in a format that differed from the expected answer (i.e., the first word was not the expected answer). As a result, the score for task 2 was either 85% or 90%, and the average score across the two tasks was either 85% or 87.5%, which is lower than the reported average of 93%. 8.5 \u201cEmergence\u201d or test data contamination? We would like to determine whether LLMs gener- alize or memorize when they solve the ToM tasks (Daum\u00e9, 2017). We explored the possibility that the increase in performance is a result of training on the test data itself. for that purpose we used a second, secret, test set for SocialIQa that was purposefully kept hidden to avoid data contamina- tion and is only available to the original SocialIQa authors as well as through the AI2 leaderboard.13 For each test set (i.e., the standard and secret test sets) we randomly sample 11 subsets of 100 ques- tions"}