{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/A._Waibel_Incremental_Blockwise_Beam_Search_for_Simultaneous_Speech_Translation_with_Controllable_Quality-Latency_Tradeoff_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the proposed method to improve the blockwise beam search method for simultaneous speech translation?", "answer": " The proposed method is a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality-latency control.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What is the ultimate goal of simultaneous speech translation (SST) according to the text?", "answer": " The ultimate goal of SST is a real-time user experience that maximizes translation quality and minimizes latency.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What are the advantages of blockwise self-attentional encoder models for simultaneous speech translation?", "answer": " The advantages include reducing computational complexity for encoder networks and performing adaptive inference based on hypothesis reliability scoring.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What are the key characteristics desired in blockwise beam search (BWBS) models for SST applications?", "answer": " The key characteristics desired are incremental translations and mechanisms for controlling the quality vs. latency tradeoff during inference.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What is the main limitation of the previously proposed BWBS scheme for SST systems?", "answer": " The limitation is that it maintains multiple hypotheses until the entire speech input is consumed, rather than showing a single incremental translation result.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " How does the proposed IBWBS algorithm modify the stopping criterion of the original BWBS?", "answer": " The IBWBS algorithm stops only the affected beam when an unreliable hypothesis is detected, allowing the remaining beams to continue expanding.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What are some alternative solutions proposed for controlling the quality vs. latency tradeoff in simultaneous speech translation?", "answer": " Alternative solutions include wait-k policy, leaving the model to generate the whole translation and heuristically deciding reliable portions, as well as using incremental blockwise beam search with local agreement or hold-n policies.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What is the significance of blockwise processing for simultaneous speech translation?", "answer": " Block processing is an effective way to reduce computational complexity for encoder networks and achieve simultaneous translation by encoding source speech into blocks of acoustic features.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " What is the contribution of the proposed IBWBS algorithm to model architectures?", "answer": " The IBWBS algorithm can onlinize models with both limited (e.g., contextual block) and full-context encoders, demonstrating versatility in model architecture.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}, {"question": " How do the experimental results on the MuST-C corpus validate the effectiveness of IBWBS?", "answer": " The experimental results show improvements of 0.6-3.6 BLEU without changing latency for contextual block models and 0.8-1.4 sec latency improvement for full-context models, compared to the original BWBS.", "ref_chunk": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}], "doc_text": "3 2 0 2 p e S 0 2 ] L C . s c [ 1 v 9 7 3 1 1 . 9 0 3 2 : v i X r a Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff Peter Pol\u00b4ak1, Brian Yan2, Shinji Watanabe2, Alex Waibel2, Ond\u02c7rej Bojar1 1Charles University, Czechia 2Carnegie Mellon University, USA polak@ufal.mff.cuni.cz Abstract Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultane- ous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. How- ever, this method maintains multiple hypotheses until the entire speech input is consumed \u2013 this scheme cannot directly show a single incremental translation to users. Further, this method lacks mechanisms for controlling the quality vs. latency trade- off. We propose a modified incremental blockwise beam search incorporating local agreement or hold-n policies for quality- latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU im- provement without changing latency or 0.8-1.4 s latency im- provement without changing quality. Index Terms: simultaneous speech translation, beam search decoding, blockwise encoder with blockwise beam search (BWBS) [11, 12]. This approach is advantageous in that blockwise processing reduces computa- tional complexity for encoder networks. Further, BWBS per- forms an adaptive inference in which a hypothesis reliability score is used to determine whether the decoding should wait for more input speech in order to produce a higher quality trans- lation [11]. However, BWBS, which was originally proposed for ASR, lacks several key characteristics which are commonly desired in SST applications. In particular, we are interested in BWBS models that 1) produce incremental translations (see Section 2.2 and Figure 1) and 2) have mechanisms for controlling the quality vs. latency tradeoff during inference. The previously proposed BWBS scheme maintains multiple hypotheses until the entire speech input is consumed, while SST systems are often expected to show only one translation result, which is gradually incre- mented to the user. The previously proposed BWBS scheme also only controls the quality-latency by changing the block du- ration, which may require training a new model and is not a fine-grained control mechanism. 1. Introduction Simultaneous speech translation (SST) is the task of translating speech into a different language before the utterance is finished. Traditionally, this task has been addressed by a cascade of auto- matic speech recognition (ASR) and machine translation (MT) [1]. More recently, E2E approaches have emerged, demonstrat- ing reduced latency [2, 3]. The ultimate goal of SST is a real-time user experience, i.e., the goal is not only maximal translation quality but also minimal latency. Several solutions for this problem have been proposed, for example, the wait-k [4] policy which limits the number of emitted tokens by the number of valid source tokens. However, wait-k cannot directly use beam search, and its direct application to speech input is also complicated [5]. Alterna- tively, we can leave the model to generate the whole translation for the current context and heuristically decide which portion of the translation is reliable [6, 7]. However, relying on attention can lead to over-generation and low-quality translation [7, 8]. We propose an incremental blockwise beam search (IB- WBS) using local agreement or hold-n policies for quality- latency control. Our IBWBS algorithm also modifies the stop- ping criterion of the original BWBS, which we found to be overly conservative for translation. Instead of stopping the whole beam search when an unreliable hypothesis is detected, we stop only the affected beam, and we continue to expand the remaining beams. We apply IBWBS to models with limited (e.g. contextual block [11]) and full-context encoders. The original BWBS used only contextual block encoders, but we extend to full-context encoders as well, demonstrating that this framework can onlinize models with conventionally offline ar- chitectures. Our experiments on the MuST-C corpus show an improvement of 0.6-3.6 BLEU without changing latency for contextual block models, and latency improvement of 0.8-1.4 sec for full-context models with IBWBS compared to the orig- inal BWBS. Additionally, we show that the proposed IBWBS improves the translation quality by 5-8 BLEU when used with the local agreement policy or lowers the computational com- plexity by 20-30 % when used with the hold-n policy. Other approaches include more flexible solutions that leave the decision of how much input to read before generating trans- lations to the model. One such approach is monotonic (chunk- wise) attention [9, 10]; however, these methods rely on strong monotonic restrictions that may limit the performance. Another such approach is blockwise self-attentional encoder models 2. Background In this section, we first review blockwise processing for SST. We then describe the differences between re-translation and in- cremental models. Finally, we review quality-latency controls. 1This work has received support from the project \u201cGrant Schemes at CU\u201d (reg. no. CZ.02.2.69/0.0/0.0/19 073/0016935), the grant 19- 26934X (NEUREM3) of the Czech Science Foundation, and by the Charles University, project GA UK No 244523. 2.1. Blockwise Streaming Encoder and Beam Search Previous studies have shown that block processing can be an effective way to reduce the computational complexity for on- hat <sos> Pruned Pruned hat has has (b) Incremental the the the the bat bat bat bat a a a a bat bat bat bat a a a is cat cat is <sos> in hat hat Block 2 cat cat (a) Re-translation Block 1 in in Figure 1: Re-translation vs. Incremental Decoding. line Encoder [11\u201314] for speech recognition and translation. Specifically, the source speech is split into blocks of equal size [11]. Each block is encoded using the block\u2019s acoustic features and a contextual embedding inherited from the previ- ous block. The encoded source features of the i-th block are Bi = (Bi 1, ..., Bi T ), where T is block size. To achieve a simultaneous translation, [11] proposes"}