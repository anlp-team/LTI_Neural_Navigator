{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_UNSSOR:_Unsupervised_Neural_Speech_Separation_by_Leveraging_Over-determined_Training_Mixtures_chunk_14.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are the parameters used for the STFT applied in the given text?", "answer": " A window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " What type of loss is used to train the network in the given text?", "answer": " Only the MC loss is used, and the ISMS loss is not used", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " What observations are made about the frequency permutation on the SMS-WSJ dataset when using UNSSOR?", "answer": " Minor frequency permutation is observed", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " How are the results obtained on the SMS-WSJ dataset using UNSSOR presented?", "answer": " The results are presented in Table 10", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " What method is compared with UNSSOR in the given text?", "answer": " MixIT, which also deals with unsupervised separation", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " Why is the comparison between UNSSOR and MixIT considered in appendix?", "answer": " MixIT needs to be trained on synthetic mixtures of mixtures, which makes the comparison difficult", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " How is the scenario created to report the results of MixIT ideal in the given text?", "answer": " By randomly adding two extra speakers in the same simulated room to create an MoM for training MixIT for 4-speaker separation", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " What architecture and training configurations are used for MixIT in the given text?", "answer": " The same as that in UNSSOR and PIT", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " What is used as the loss function for the MixIT model in the given text?", "answer": " Defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}, {"question": " How are the evaluation scores obtained for the 2-speaker separation on SMS-WSJ reported in the given text?", "answer": " The results are shown in Table 11", "ref_chunk": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}], "doc_text": "in the time domain, and then apply STFT (with a window size of 32 ms, a hop size of 8 ms, and the square-root of Hann window) to obtain \u02c6Z(c) for each speaker c. The network is trained by only using the MC loss in (9) and not using the ISMS loss in (10). Although the ISMS loss is not used, we only observe minor frequency permutation on the SMS-WSJ dataset. All the other procedures are the same as the TF-GridNet based UNSSOR system. The results on SMS-WSJ, obtained by using six-channel input and loss, are presented in Table 10. We observe that UNSSOR also works with DPRNN to some degrees, and the results are not as good as the ones in Table 1. L Comparison with MixIT This section compares the results of UNSSOR with MixIT [30], which also deals with unsupervised separation. We put this comparison only in appendix, considering that MixIT may not be an ideal baseline to UNSSOR. Notice that MixIT needs to be trained on synthetic mixtures of mixtures (MoM), which ideally would require the two mixtures used in creating each MoM to be recorded in the same room using the same device. Differently, UNSSOR is designed to be trained directly on existing mixtures. In this case, the two models would be trained on different training examples, and this would make the comparison difficult. In the main body of this paper, we hence only consider methods that can be trained (or performed) directly on existing mixtures (such as IVA, spatial clustering and iRAS) as baselines. To report the results of MixIT, we create a particular scenario (ideal for MixIT), where, for each existing SMS-WSJ mixture (y = x(1) + x(2) + n with n denoting noise), we randomly add two extra speakers in the same simulated room and use the same array placed at the same location so that we can have two 2-speaker mixtures (i.e., an existing SMS-WSJ mixture 1: y(1) = x(1)(1) + x(1)(2) + n(1) and a newly-simulated mixture 2: y(2) = x(2)(1) + x(2)(2) + n(2) where the superscript (1) denotes mixture 1 and (2) denotes mixture 2) to create an MoM for training MixIT for 4-speaker separation. Similarly to n(1), n(2) is sampled such that the SNR between x(2)(1) + x(2)(2) and n(2) is in the range of [20, 30] dB. The DNN architecture and training configurations for MixIT are the same as that in UNSSOR and PIT. The loss function is defined similarly to (5) on the real, imaginary and magnitude of the reconstructed mixtures weighted by the summation of mixture magnitudes. Similarly to our proposed technique, we can feed 1-, 3- or 6-channel mixtures to TF-GridNet-based MixIT. At run time, the trained MixIT model is used to separate the existing two-speaker mixtures in SMS-WSJ to four outputs, and the two outputs with the highest energy are selected for evaluation. 21 Table 11: Averaged results of 2-speaker separation on SMS-WSJ, obtained by using MixIT [30]. Val. set Test set Row Systems SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 5a 5b 5c One-channel MixIT Three-channel MixIT Six-channel MixIT 6.7 0.1 8.2 6.6 0.1 8.0 6.3 0.0 7.8 2.21 1.91 2.43 0.691 0.608 0.745 This way, the evaluation scores can be pretty much directly compared with the ones obtained by UNSSOR. The results are shown in Table 11. They are not as good as the ones reported in Table 1, 2, 3 and 4. For unknown reasons, three-channel MixIT fits the loss well but fails at separating speakers. 22"}