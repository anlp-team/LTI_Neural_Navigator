{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_Memory-adaptive_Depth-wise_Heterogenous_Federated_Learning_chunk_9.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What conference did T.; Hospedales, T. M.; and Lu present their work on Deep mutual learning in?,        answer: Proceedings of the IEEE conference on computer vision and pattern recognition    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What is the title of the paper by Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. from 2023?,        answer: A Comprehensive Survey on Pre-trained Foundation Models: A History from BERT to ChatGPT    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " How many clients were considered in the large-scale FL experiments described in the text?,        answer: 100    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What is the fairness measure used in the evaluation according to the definition of fairness in FL from (Li et al. 2021)?,        answer: std of test accuracy    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " Which dataset is derived from partitioning 3597 writers from EMNIST?,        answer: FEMNIST    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What is the participation rate used in the experiments conducted on EMNIST with 500 and 1000 clients?,        answer: 0.1    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What is the local training time (in seconds) for SplitMix in one round of training?,        answer: 1.90 \u00b1 0.60    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What type of client statistical heterogeneity is visualized in Figure 8 on the CIFAR-10 dataset?,        answer: Among partial clients    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What does the y-axis indicate in Figure 8 for statistical heterogeneity among partial clients on the CIFAR-10 dataset?,        answer: Class labels    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}, {"question": " What is the title of the paper by Zhu, Z.; Hong, J.; and Zhou, J. from 2021?,        answer: Data-free knowledge distillation for heterogeneous federated learning    ", "ref_chunk": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}], "doc_text": "T.; Hospedales, T. M.; and Lu, H. 2018. Deep mutual learning. In Proceedings of the IEEE conference on com- puter vision and pattern recognition, 4320\u20134328. Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. Zhou, C.; Li, Q.; Li, C.; Yu, J.; Liu, Y.; Wang, G.; Zhang, K.; Ji, C.; Yan, Q.; He, L.; et al. 2023. A Comprehensive Survey on Pre- trained Foundation Models: A History from BERT to ChatGPT. arXiv preprint arXiv:2302.09419. Zhu, Z.; Hong, J.; and Zhou, J. 2021. Data-free knowledge distil- lation for heterogeneous federated learning. In International Con- ference on Machine Learning, 12878\u201312889. PMLR. Visualization of Label Distribution We consider 100 clients in all experiments, and in Figure 8, we show label distributions of 5 out of 100 clients under balanced \u03b1(0.3), \u03b1(1.0) and unbalanced \u03b1u(0.3), \u03b1u(1.0) splits of CIFAR- 10. Extensive Experimental Results Large-scale FL experiments We also conducted experiments on EMNIST with 500 and 1000 clients, respectively, with the 0.1 participation rate, and fair budget with \u03b1(1). Additionally, we report the results on FEMNIST (Cal- das et al. 2018), a natural-split FL dataset derived from partition- ing 3597 writers from EMNIST. Furthermore, we present results on TinyImageNet under with 100 clients and 0.1 participation rate. The results are shown in the following table. Datasets EMNIST (0.5K) EMNIST (1.0K) FEMNIST TinyImageNet FedAvg HeteroFL SplitMix DepthFL 77.44 74.24 62.69 21.00 79.26 77.95 71.05 23.98 70.94 62.04 54.62 30.87 73.88 70.18 73.80 30.89 FEDEPTH m-FEDEPTH 82.07 81.91 78.07 33.97 81.73 81.68 76.24 37.79 Fairness evaluation According to the definition of fairness in FL from (Li et al. 2021), we can take the std of test accuracy as a fairness measure. Here we use the std of testing accuracy across 100 clients with the Cifar10 dataset as shown in the following table. Besides, we compare the local training time (in seconds) of each client in one round in the table below. Metric Time (s) Fairness FedAvg 0.42 \u00b1 0.05 0.05253 HeteroFL 0.75 \u00b1 0.09 0.03888 SplitMix 1.90 \u00b1 0.60 0.04919 FEDEPTH m-FEDEPTH 2.32 \u00b1 0.93 2.49 \u00b1 0.93 0.04762 0.04596 Figure 8: Visualization of statistical heterogeneity among partial clients on CIFAR-10 dataset, where the x-axis indicates client IDs, the y-axis indicates class labels, and the size of scattered points indicates the number of training samples for a label available to the client."}