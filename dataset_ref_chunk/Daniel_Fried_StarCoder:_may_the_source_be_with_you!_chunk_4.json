{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Daniel_Fried_StarCoder:_may_the_source_be_with_you!_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What filter was developed to remove files with fewer than 25% alphabetic characters?,        answer: An alpha filter    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " Why did the alpha filter show a high rate of false positives for certain programming languages like Assembly?,        answer: The filter was tested on a small subset of data.    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What type of content does the custom HTML filter specifically target?,        answer: Excessive HTML boilerplate and links    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What ratio of visible text in an HTML file must be present for the file to be kept by the custom HTML filter?,        answer: At least 20%    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " For JSON files, what percentage of alphabetic characters is required to keep the file?,        answer: More than 50%    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What percentage of YAML files is removed by the applied filters?,        answer: Around 20%    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " How much of the volume of JSON files is removed by the filters?,        answer: 98%    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What programming language had the highest number of detections and received manual verification after applying the alpha filter?,        answer: MATLAB    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What does the custom HTML filter consider as the minimum length for visible text in a file?,        answer: 100 characters    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}, {"question": " What was the issue observed when the alpha filter was tested on a small subset of data?,        answer: High rate of false positives    ", "ref_chunk": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}], "doc_text": "we applied it to all programming languages except for XSLT, which uses XML syntax. Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied. HTML We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters. JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50\u20135000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50\u20135000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume. 5 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada agda alloy antlr applescript assembly augeas awk batchfile bluespec c c-sharp clojure cmake coffeescript common-lisp cpp css cuda dart dockerfile elixir elm emacs-lisp erlang f-sharp fortran glsl go groovy haskell html idris isabelle java java-server-pages javascript json julia kotlin lean literate-agda literate-coffeescript literate-haskell lua makefile maple markdown mathematica matlab 31,291 17,608 5,374 7,983 4,906 248,396 195 10,430 252,514 5,940 8,625,559 10,839,399 126,191 186,517 227,889 101,370 6,377,914 2,994,829 58,355 932,583 572,186 282,110 62,861 54,768 99,368 127,161 165,446 175,576 4,730,461 251,627 544,969 9,533,367 8,060 5,086 20,151,565 214,133 21,108,587 17,012,912 298,672 2,242,771 16,891 523 1,138 6,135 558,861 661,424 1,259 21,045,171 26,895 967 0.30 0.07 0.01 0.05 0.01 1.58 0.00 0.02 0.29 0.03 57.43 46.29 0.49 0.45 0.69 1.68 50.89 22.61 0.59 3.86 0.42 0.74 0.34 0.43 0.73 0.90 1.84 0.57 25.74 0.94 2.36 146.76 0.03 0.09 89.30 1.03 141.65 338.34 1.54 5.77 0.10 0.01 0.01 0.05 3.28 1.49 0.01 75.25 1.72 0.04 30,934 17,554 5,368 7,917 4,737 247,919 180 10,289 239,568 5,928 8,536,791 10,801,285 125,163 186,375 226,209 98,733 6,353,527 2,721,616 58,151 928,415 571,506 281,016 62,033 52,838 98,447 124,066 158,792 167,701 4,700,526 250,834 541,454 3,299,965 8,042 5,001 20,071,773 210,816 19,544,285 4,751,547 295,364 2,239,354 16,870 523 1,133 6,104 549,459 657,349 1,152 21,029,287 22,653 93 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 11.93 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 5.62 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.26 0.07 0.01 0.05 0.01 1.56 0.00 0.02 0.23 0.03 53.89 44.66 0.46 0.45 0.64 1.40 48.92 3.00 0.56 3.66 0.42 0.71 0.30 0.41 0.70 0.61 1.78 0.40 23.78 0.91 2.23 29.36 0.03 0.08 86.94 0.98 64.71 1.00 1.31 5.68 0.09 0.01 0.01 0.05 2.87 1.31 0.01 74.93 1.25 0.00 0.034 0.009 0.001 0.007 0.001 0.203 0 0.003 0.03 0.004 7.027 5.823 0.06 0.059 0.083 0.183 6.379 0.391 0.073 0.477 0.055 0.093 0.039 0.053 0.091 0.08 0.232 0.052 3.101 0.119 0.291 3.828 0.004 0.01 11.336 0.128 8.437 0.13 0.171 0.741 0.012 0.001 0.001 0.007 0.374 0.171 0.001 9.77 0.163 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. 6 Published in Transactions on Machine Learning Research (12/2023) Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml pascal perl php powershell prolog protocol-buffer python r racket restructuredtext rmarkdown ruby rust sas scala scheme shell smalltalk solidity sparql sql stan standard-ml stata systemverilog tcl tcsh tex thrift typescript verilog vhdl visual-basic xslt yacc yaml zig 159,734 118,675 392,108 15,904,518 271,487 1,023 98,246 12,962,249 39,194 4,201 905,679 5,389 3,405,374 1,386,585 9,772 1,362,426 44,261 2,236,434 592,999 164,242 14,173 994,019 5,441 48,995 31,282 46,915 50,579 4,911 547,888 4,663 10,637,070 77 60,027 163,291 43,095 25,775 5,282,081 15,913 1.11 1.71 2.63 66.84 1.25 0.01 0.44 64.30 0.30 0.04 3.42 0.06 7.14 9.53 0.13 4.86 0.30 3.38 0.74 1.21 0.04 12.22 0.01 0.52 0.41 0.41 0.40 0.02 5.44 0.01 28.82 0.001 1.12 1.49 0.56 0.41 28.36 0.18 158,356 110,981 365,491 15,683,017 267,627 968 97,167 12,866,649 39,042 3,688 896,880 5,386 3,390,320 1,380,468 9,226 1,355,788 41,890 2,206,327 587,748 153,194 13,716 975,420 5,429 19,630 24,208 46,270 49,335 4,806 522,778 4,661 10,547,331 75 58,208 161,239 6,513 7,451 3,995,948 15,850 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 3.76 0.18 1.03 1.68 2.23 60.89 1.12 0.01 0.31 60.40 0.30 0.03 3.32 0.06 6.81 9.11 0.12 4.69 0.20 3.09 0.58 0.85 0.04 11.09 0.01 0.19 0.33 0.39 0.35 0.02 5.20 0.01 26.52 0.001 0.94 1.42 0.05 0.11 1.00 0.18 0.134 0.219 0.291 7.939 0.146 0.001 0.04 7.875 0.039 0.004 0.433 0.008 0.888 1.188 0.016 0.612 0.026 0.403 0.076 0.111 0.005 1.446 0.001 0.025 0.043 0.051 0.046 0.003 0.678 0.001 3.458 0 0.123 0.185 0.007 0.014 0.13 0.023 GitHub issues Git commits notebook scripts notebook structured \u223c 30,900,000 7,674,345 914,000 668,743 54.40 64.00 7.12 6.00 54.40 32.00 7.12 6.00 7.093 4.172 0.928 0.782 305,929,658 815.68 799.37 100 Table 2: Overview of the training data for StarCoder. For the selected"}