{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Maarten_Sap_Don't_Take_This_Out_of_Context!_On_the_Need_for_Contextual_Models_and_Evaluations_for_Stylistic_Rewriting_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main focus of the text?,        answer: The main focus is on the importance of integrating contextual models and evaluations for stylistic text rewriting.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " Why do existing stylistic text rewriting methods often fail?,        answer: Existing methods often fail because they operate on a sentence level and ignore the broader context of the text.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " What is the purpose of the new composite contextual evaluation metric CtxSimFit?,        answer: CtxSimFit combines similarity to the original sentence with contextual cohesiveness to evaluate the quality of rewrites in stylistic text rewriting.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " How do human preferences compare between contextual and non-contextual rewrites?,        answer: Human significantly prefer contextual rewrites as more fitting and natural over non-contextual rewrites.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " What is one example provided in the text that illustrates the importance of context in stylistic rewriting?,        answer: An example is provided where a contextual rewriting model uses broader conversational context to produce a more specific and natural formal rewrite compared to a non-contextual model.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " Why is context important in automatic evaluations for stylistic rewriting?,        answer: Context is important in automatic evaluations to ensure that the quality of rewrites, in terms of naturalness and intended meaning preservation, is accurately assessed.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " What is CtxSimFit and how does it aim to bridge the gap between contextual understanding and automated metrics?,        answer: CtxSimFit is a composite metric that combines original sentence similarity and contextual cohesiveness to evaluate rewrites, aiming to align automated metrics with human preferences.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " What are some of the contributions highlighted in the text?,        answer: The contributions include investigating the need for context in text rewriting, analyzing the importance of context in automatic evaluations, and proposing metrics to bridge the gap between contextual understanding and automated metrics.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " Why do current methods for stylistic rewriting rely primarily on parallel source-to-target sentence pairs?,        answer: Current methods rely on parallel data because of a lack of datasets that include contextual information.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}, {"question": " What is the overall goal of the research presented in the text?,        answer: The overall goal is to develop more effective and reliable stylistic text rewriting techniques by emphasizing the importance of incorporating context in the generation and evaluation stages.    ", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}], "doc_text": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 5 7 4 1 . 5 0 3 2 : v i X r a \u201cDon\u2019t Take This Out of Context!\u201d On the Need for Contextual Models and Evaluations for Stylistic Rewriting Akhila Yerukola\u2661 Xuhui Zhou\u2661 Elizabeth Clark\u2662 Maarten Sap\u2661\u2663 \u2661Language Technologies Institute, Carnegie Mellon University \u2662Google DeepMind \u2663Allen Institute for AI # ayerukol@andrew.cmu.edu Abstract Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambigu- In this paper, ous, and incoherent rewrites. we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the orig- inal sentence with contextual cohesiveness. We comparatively evaluate non-contextual and con- textual rewrites in formality, toxicity, and senti- ment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic met- rics (e.g., ROUGE, SBERT) correlate poorly with human preferences (\u03c1=0\u20130.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (\u03c1=0.7\u20130.9) as well as proposed context-infused versions of com- mon metrics (\u03c1=0.4\u20130.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evalua- tion stages of stylistic text rewriting. Non-contextual RewriteIndeed, I concur. I am inundated with them. Or make it less toxic / change to positive sentiment Informal response: \u201cI know, right? I'm drowning in them.\u201d Contextual rewriteIndeed, I concur. The workload is quite overwhelming. Preceding Dialog: \u201cI can't believe how much work we have to do.\u201d Rewrite it as formal Figure 1: Example of using the preceding dialog utter- ance to help with stylistic rewriting: here, we transform an informal response into formal language. Incorporat- ing \u201cworkload\u201d and \u201coverwhelming\u201d enhances the con- textual cohesiveness of the rewritten text, while solely using \u201cinundated\u201d results in a more generic rewrite. 1 Introduction Existing methods for stylistic text rewriting, i.e., adapting the text to a particular style while preserv- ing its originally intended meaning, often fail to ac- count for a statement\u2019s context (e.g., Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Li et al., 2018; Lample et al., 2019; Madaan et al., 2020; Hallinan et al., 2023). As a result, these systems may change the speakers\u2019 original communicative intents and generate contextually irrelevant and generic out- puts. For example, in Figure 1, a non-contextual model rewriting an informal response to a formal one simply replaces words with more formal syn- onyms, whereas a contextual rewriting model can use the broader conversational context to produce a more specific and natural formal rewrite. Similarly, preceding textual context has largely been overlooked in automatic evaluations for stylis- tic rewriting, with most work focusing on sentence- level metrics (e.g., Li et al., 2018; Reif et al., 2022). This lack of context at the modeling and evaluation stages hinders the creation of effective AI-assisted rewriting tools for users (e.g., for assistive writing tools; MacArthur, 2009; Clark et al., 2018). In this paper, we present a comprehensive analy- sis of the need for context in stylistic rewriting and its evaluation, on three different rewriting tasks (formality transfer, sentiment change, and text detoxification) and two types of textual con- texts (preceding turns in a conversation, preceding sentences in a document). To study these effects, we design a contextual human evaluation frame- work (\u00a75) to comparatively evaluate non-contextual and contextual rewriting methods built on few-shot prompted large language models (\u00a74). We show that human evaluators prefer contex- tual rewrites in terms of naturalness, style strength, and intended meaning preservation, across all three tasks. However, non-contextual automatic met- rics for lexical or semantic meaning preservation correlate poorly with these preferences (\u03c1=0\u20130.3; \u00a76), despite being commonly used in previous style transfer work to measure meaning preservation (Mir et al., 2019; Madaan et al., 2020). To address the need for context in automatic eval- uations, we introduce CtxSimFit, a new composite metric that combines original sentence similarity and contextual cohesiveness to evaluate the quality of rewrites, taking into account the preceding con- text (\u00a77). Additionally, we propose context-infused versions of commonly used automatic metrics for meaning preservation. Our results show that hu- man preferences are significantly correlated with these contextual metrics\u2014especially CtxSimFit (\u03c1=0.7\u20130.9), much more than non-contextual ones. Our contributions are summarized as follows: (1) We investigate the need for context in text rewriting, showing that incorporating it, whether at the docu- ment or conversational level, leads to contextually coherent and relevant rewrites preferred by human annotators across style transfer tasks. (2) We con- duct a comprehensive analysis on the need for con- text in automatic evaluation, revealing that existing metrics don\u2019t align with human preferences. (3) We propose a custom metric, CtxSimFit, along with context-infused versions of common auto- matic metrics, to bridge the gap between contextual understanding and automated metrics. Overall, our contributions provide a more nuanced understand- ing of the importance of context, which is criti- cal for development of more effective and reliable stylistic text rewriting techniques. 2 Background & Related Work In this section, we discuss the increasing interest in incorporating context into NLP tasks and motivate the significance of context during the rephrasing and evaluation phases of stylistic text rewriting. Stylistic Text Rewriting Despite being intro- duced over ten years ago (Xu et al., 2012), cur- rent methods for stylistic rewriting (e.g. Shen et al., 2017; Xu et al., 2018b; Fu et al., 2018; Lample et al., 2019; Jin et al., 2022; Chawla and Yang, 2020; Yerukola et al., 2021; Dale et al., 2021; Lo- gacheva et al., 2022, etc.) still rely solely on paral- lel source-to-target sentence pairs, primarily due to a lack of datasets that include contextual informa- tion. While new models have emerged that do not require parallel data for training (Hu et al., 2017;"}