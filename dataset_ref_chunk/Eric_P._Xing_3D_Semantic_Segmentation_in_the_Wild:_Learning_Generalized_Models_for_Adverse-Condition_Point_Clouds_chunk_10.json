{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_3D_Semantic_Segmentation_in_the_Wild:_Learning_Generalized_Models_for_Adverse-Condition_Point_Clouds_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the probability of adding 0-2,000 random points into the 3D space of each LiDAR scan?", "answer": " 0.5", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " With what probability are LiDAR point clouds coordinates flipped along the x or y axis?", "answer": " 0.5", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What is the range of random coordinate shifts added into LiDAR points with a probability of 0.5?", "answer": " [-0.05, 0.05] meters", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What optimizer is employed in training the oracle model?", "answer": " SGD optimizer", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What are the hyperparameters used for training the oracle model?", "answer": " Initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e-4, and dampening at 0.1", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " How many epochs are used to train the segmentation model?", "answer": " 500 epochs", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What GPU model is used for training the segmentation model?", "answer": " NVIDIA 2080Ti with 11GB GPU memory", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What is the batch size set as in training the segmentation model?", "answer": " 4", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What learning rate policy is used in training the segmentation model?", "answer": " Poly learning rate policy with power= 0.9", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}, {"question": " What data augmentation techniques are adopted according to [43]?", "answer": " Random rotation ([-\u03c0, \u03c0]) and scaling ([0.95, 1.05])", "ref_chunk": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}], "doc_text": "input LiDAR scans with a probability of 0.5. As for noise perturbation, 0 \u2212 2, 000 random points are added into the 3D space of each LiDAR scan with a probability of 0.5. When using flipping, we randomly flip coordinates of LiDAR point clouds along x or y axis with a probability of 0.5. As for jittering, random coordinate shifts with a range of [\u22120.05, 0.05] meters are added into LiDAR points with a probability of 0.5. In training the oracle model, we employ the SGD optimizer with the hyperparameters including initial learning rate at 0.1, momentum at 0.9, weight decay at 1.0e \u2212 4, and dampening at 0.1. We train the segmentation model with 500 epochs using a single NVIDIA 2080Ti with 11GB GPU memory. The batch size is set as 4. We use Poly learning rate policy with power= 0.9. As for data augmentations, we follow [43] and adoptes random rotation ([\u2212\u03c0, \u03c0]) and scaling ([0.95, 1.05]); We also adopts PolarMix [50] with following parameter settings: Rotation angles along the Z-axis, denoted as \u2126, are randomly scaled within normal distributions with a mean of \u00b5 = 0 and standard deviation of \u03c3 = 2 3 \u03c0. We keep the original instance classes for rotate-pasting in PolarMix. A.2. Evaluation of individual adverse weather conditions We noticed that for certain individual adverse weather conditions, some class has no data captured in the validation set of SemanticSTF. Specifically, there are no points of bicycle and motorcycle in the validation set of dense fog; no points of bicyclist and motorcyclist in the validation set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark \u201cSemanticKITTI\u2192SemanticSTF\u201d: 1) The Baseline is a source-only model that is trained by using the training data of Se- manticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmen- tation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the pro- posed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter \u03bbcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different \u03bbcl produce quite different mIoUs. The best mIoU is obtained when \u03bbcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. 12 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(dense fog) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 74.7 67.5 68.6 52.3 75.5 64.3 69.2 - - - - - - - - - - - - 7.8 1.9 8.8 17.2 0.3 11.7 7.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.4 8.9 6.0 3.6 4.2 0.6 2.4 8.9 2.8 0.0 0.0 0.0 0.0 6.7 SynLiDAR\u2192SemanticSTF(dense fog) 0.0 0.0 0.0 19.3 0.0 0.0 0.0 72.2 70.9 66.6 75.2 75.4 72.4 73.5 0.6 5.6 14.8 0.0 11.2 3.8 8.5 33.8 29.0 24.3 28.7 33.6 31.3 33.6 0.0 0.8 0.1 0.6 0.5 0.8 0.2 59.6 64.6 52.2 62.4 64.8 63.1 65.6 48.7 44.0 43.5 49.5 51.7 46.5 47.6 56.9 60.0 60.1 60.5 64.7 65.7 63.6 27.4 31.6 19.4 29.0 26.1 19.4 31.0 56.4 60.6 54.1 55.4 62.3 64.3 60.7 25.7 2.4 38.3 1.0 30.0 5.2 27.7 1.7 30.6 2.5 29.0 1.1 31.9 5.7 Table 7. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of dense fog in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 21.6 12.7 13.3 15.8 26.5 22.9 42.5 - - - - - - - - - - - - 6.4 7.7 10.4 10.6 12.7 20.1 16.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.7 1.9 4.3 1.5 2.7 2.2 2.4 2.9 0.4 2.8 1.7 4.0 6.2 3.2 18.9 2.5 19.1 3.5 22.3 28.3 12.2 0.0 0.1 0.7 0.0 0.0 0.0 0.2 7.7 10.2 8.8 9.9 9.4 9.2 9.0 1.0 0.3 1.2 0.3 0.0 2.6 0.8 41.2 37.3 30.5 46.2 31.6"}