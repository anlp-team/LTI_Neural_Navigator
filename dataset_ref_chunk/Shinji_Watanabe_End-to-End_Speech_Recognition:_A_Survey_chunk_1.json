{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the title of the article mentioned in the text?", "answer": " End-to-End Speech Recognition: A Survey", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What has brought considerable reductions in word error rate in automatic speech recognition research?", "answer": " The introduction of deep learning", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What are end-to-end (E2E) models in the context of automatic speech recognition?", "answer": " Highly integrated, completely neural ASR models that rely strongly on general machine learning knowledge", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What are some aspects of E2E ASR covered in the survey mentioned?", "answer": " Modeling, training, decoding, external language model integration, performance, deployment opportunities, and potential future developments", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " How is classical acoustic modeling typically based on?", "answer": " Hidden Markov models (HMMs)", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What has deep learning replaced in acoustic modeling within the classical approach?", "answer": " Gaussian mixture distributions or augmented the acoustic feature set", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What is the primary objective when developing automatic speech recognition systems?", "answer": " To minimize the expected word error rate", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What are some potential benefits of E2E approaches to ASR?", "answer": " Support for genericity of modeling, faster development cycles, reduction in memory footprint, power consumption, and avoidance of spurious optima", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " According to the text, what may end-to-end joint training help to avoid?", "answer": " Spurious optima from intermediate training stages", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}, {"question": " What license is this work published under?", "answer": " Creative Commons Attribution 4.0 License", "ref_chunk": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}], "doc_text": "This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 End-to-End Speech Recognition: A Survey Rohit Prabhavalkar, Member, IEEE, Takaaki Hori, Senior Member, IEEE, Tara N. Sainath, Fellow, IEEE, Ralf Schl\u00a8uter, Senior Member, IEEE, and Shinji Watanabe, Fellow, IEEE Abstract\u2014In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain- specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments. Index Terms\u2014end-to-end, automatic speech recognition. I. INTRODUCTION The classical1 statistical architecture decomposes an auto- matic speech recognition (ASR) system into four main compo- nents: acoustic feature extraction from speech audio signals, acoustic modeling, language modeling and search based on Bayes\u2019 decision rule [1], [2], [3]. Classical acoustic modeling is based on hidden Markov models (HMMs) to account for speaking rate variation. Within the classical approach, deep learning has been introduced into acoustic and language mod- eling. In acoustic modeling, deep learning has replaced Gaus- sian mixture distributions (hybrid HMM [4], [5]) or augmented the acoustic feature set (e.g., non-linear discriminant/tandem approach [6], [7]). In language modeling, deep learning has re- placed count-based approaches [8], [9], [10]. However, in these early attempts at introducing deep learning, the classical ASR architecture was unmodified. Classical state-of-the-art ASR systems today are composed of many separate components and knowledge sources: especially speech signal preprocessing; methods for robustness with respect to recording conditions; phoneme inventories and pronunciation lexica; phonetic clus- tering; handling of out-of-vocabulary words; various methods for adaptation/normalization; elaborate training schedules with different objectives including sequence discriminative training, etc. The potential of deep learning, on the other hand, initiated successful approaches to integrate formerly separate modeling steps, e.g., by integrating speech signal pre-processing and feature extraction into acoustic modeling [11], [12]. More consequently, the introduction of deep learning to ASR also initiated research to replace classical ASR archi- tectures based on hidden Markov models (HMM) with more integrated joint neural network model structures [13], [14], [15], [16]. These ventures might be seen as trading specific speech processing models for more generic machine learning approaches to sequence-to-sequence processing \u2013 akin to how statistical approaches to natural language processing have come to replace more linguistically oriented models. For these all-neural approaches recently the term end-to-end (E2E) [14], [17], [18], [19] has been established. Therefore, first of all an attempt to define the term end-to-end in the context of ASR is due in this survey. According to the Cambridge Dictionary, the adjective \u201cend-to-end\u201d is defined as: \u201cinclud- ing all the stages of a process\u201d [20]. We therefore propose the following definition of end-to-end ASR: an integrated ASR model that enables joint training from scratch; avoids separately obtained knowledge sources; and, provides single- pass recognition consistent with the objective to optimize the i.e., usually label (word, task-specific evaluation measure, character, subword, etc.) error rate. While this definition suffices for the present discussion, we note that such an idealized definition hides many nuances involved in the term E2E and lacks distinctiveness; we elaborate on some of these nuances in Sec. II to discuss the various connotations of the term E2E in the context of ASR. What are potential benefits of E2E approaches to ASR? The primary objective when developing an ASR systems is to minimize the expected word error rate; secondary objectives are to reduce time and memory complexity of the resulting decoder, and \u2013 assuming a constrained development budget \u2013 genericity, and ease of modeling. First of all, an integrated ASR system, defined in terms of a single neural network structure supports genericity of modeling and may allow for faster development cycles when building ASR systems for new languages or domains. Similarly, ASR models defined by a single neural network structure may become more \u2018lean\u2019 compared to classical modeling, with a simpler decoding process, obviating the need to integrate separate models. The resulting reduction in memory footprint and power consump- tion supports embedded ASR applications [21], [22]. Further- more, end-to-end joint training may help to avoid spurious optima from intermediate training stages. Avoiding secondary knowledge sources like pronunciation lexica may be helpful for languages/domains where such resources are not easily available. Also, secondary knowledge sources may themselves be erroneous; avoiding these may improve models trained directly from data, provided that sufficient amounts of task- specific training data are available. 1 The term \u201cclassical\u201d here refers to the former, long-term, state-of-the-art ASR architecture based on the decomposition into acoustic and language model, and with acoustic modeling based on hidden Markov models. With the current surge of interest in E2E ASR models and an This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 increasing diversity of corresponding work, the authors of this review think it is time to provide an overview"}