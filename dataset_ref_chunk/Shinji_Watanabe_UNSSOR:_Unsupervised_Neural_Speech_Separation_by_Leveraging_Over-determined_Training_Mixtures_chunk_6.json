{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_UNSSOR:_Unsupervised_Neural_Speech_Separation_by_Leveraging_Over-determined_Training_Mixtures_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What evaluation metrics were used to assess the separation results?", "answer": " Signal-to-distortion ratio (SDR), scale-invariant SDR (SI-SDR), perceptual evaluation of speech quality (PESQ), and extended short-time objective intelligibility (eSTOI)", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What did the first microphone correspond to in the evaluation setup?", "answer": " The reference microphone", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What is the purpose of using supervised learning with PIT for addressing the permutation problem?", "answer": " To obtain a performance upper bound of unsupervised separation", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " How does UNSSOR perform at promoting separation based on the reported results?", "answer": " UNSSOR produces reasonable separation of speakers, improving the SDR significantly", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What was used to obtain oracle frequency alignment for comparison?", "answer": " Oracle target speech", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What was found to be very effective at dealing with the frequency permutation problem?", "answer": " Including ISMS (LMC+ISMS) in the training of DNNs", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " In which cases was the performance almost the same as using oracle frequency alignment?", "answer": " When including ISMS in the training", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What was the purpose of training UNSSOR for monaural unsupervised separation?", "answer": " To assess its performance when using only the mixture at the reference microphone", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " What was tuned for the six-microphone case to address the permutation problem?", "answer": " The weighting term \u03b3 in the ISMS loss", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}, {"question": " Why was non-causal filtering needed in the training of UNSSOR for monaural separation?", "answer": " To prevent overfitting to the reference microphone and optimize performance for all microphones", "ref_chunk": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}], "doc_text": "0.867 0.871 2a 2b 2c UNSSOR UNSSOR + Corr. based freq. align. UNSSOR + Oracle freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 19 0 LMC+ISMS 15.7 15.7 15.8 15.4 15.4 15.4 14.4 14.4 14.5 3.20 0.874 3.20 0.875 0.876 3.20 3a 3b 3c 3d Spatial clustering + Corr. based freq. align. [44] IVA [44] iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - - - - - - LiRAS LiRAS 9.6 11.6 5.1 4.6 9.5 12.0 4.8 4.5 8.5 10.7 2.7 2.2 2.52 2.67 1.88 1.87 0.759 0.802 0.588 0.579 4a PIT (supervised) [23] 17.4 16.8 16.3 3.91 0.924 which is quadratic and has a closed-form solution. The separation result is computed as \u02c6xWF p (c) = \u02c6hp(c) \u2217 \u02c6z(c). Following [36], we use 512 filter taps, and filter the future 100, the current, and the past 411 samples (i.e., non-causal filtering). We can also filter the current and the past 511 samples (i.e., causal filtering), and additionally experiment with a filter length (in time) same as the length of the FCP filters (see Appendix J). For comparison, we also include MixIT [30], which requires using synthetic mixtures of mixtures. We report the result of using supervised learning, where PIT [5] is used to address the permutation problem. This result can be viewed as a performance upper bound of unsupervised separation. We use the same DNN and training configurations as those in UNSSOR for a fair comparison. 5.2 Evaluation setup and metrics We designate the first microphone as the reference microphone, and use the time-domain signal corresponding to X1(c) of each speaker c for metric computation. The evaluation metrics include signal-to-distortion ratio (SDR) [70], scale-invariant SDR (SI-SDR) [71], perceptual evaluation of speech quality (PESQ) [72], and extended short-time objective intelligibility (eSTOI) [73]. SI-SDR and SDR evaluate the sample-level accuracy of predicted signals, and PESQ and eSTOI are objective metrics of speech quality and intelligibility respectively. For all the metrics, the higher, the better. 6 Evaluation results This section reports evaluation results on SMS-WSJ and compares the performance of various setups. 6.1 Effectiveness of UNSSOR at promoting separation Table 1 and 2 respectively report the results of using six- and three-microphone input and loss. After hyper-parameter tuning, in default we use the loss in (9) for DNN training, set I = 19 and J = 0 (defined below (6)) for FCP (i.e., causal FCP filtering with 20 taps), and set \u03b1p = 1 (meaning no 8 Table 3: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 6-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 13.0 12.5 11.9 3.27 0.832 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS 7.5 10.7 7.2 10.5 5.6 9.7 2.03 2.80 0.641 0.778 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 Table 4: Averaged results of 2-speaker separation on SMS-WSJ (1-channel input and 3-channel loss). Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 1a UNSSOR 19 1 LMC+ISMS 12.5 12.0 11.4 3.18 0.822 2a 2b iRAS w/ causal 512-tap filters iRAS w/ non-causal 512-tap filters (100 future taps) - - LiRAS LiRAS \u22120.1 11.0 \u22120.3 10.7 \u22123.0 9.9 1.62 2.81 0.453 0.783 3a Monaural PIT (supervised) [23] 16.2 15.7 15.3 3.79 0.907 weighting is applied for different microphones). For the 3-microphone case, we use the mixtures at the first, third, and fifth microphones for training and testing. Notice that for two-speaker separation, the cases with six or three microphones are both over-determined. In both tables, from row 1a we observe that UNSSOR produces reasonable separation of speakers, improving the SDR from 0.1 to, for example, 12.5 dB in Table 1, but its output suffers from the frequency permutation problem (see Appendix D for an example). In row 1c, we use oracle target speech to obtain oracle frequency alignment and observe much better results over 1a. This shows the effectiveness of LMC at promoting separation of speakers and the severity of the frequency permutation problem. In row 1b, we use a frequency alignment algorithm (same as that used in the spatial clustering baseline) [46, 64] to post-process the separation results of 1a. This algorithm leads to impressive frequency alignment (see 1b vs. 1c), but it is empirical and has a complicated design. 6.2 Effectiveness of ISMS loss at addressing frequency permutation problem We train DNNs using LMC+ISMS defined in (11). In each case (i.e, six- and three-microphone), we separately tune the weighting term \u03b3 in (11) based on the validation set. In both table, comparing row 2a-2c with 1a-1c, we observe that including LISMS is very effective at dealing with the frequency permutation problem, yielding almost the same performance as using oracle frequency alignment. 6.3 Results of training UNSSOR for monaural unsupervised separation Table 3 and 4 use the mixture only at the reference microphone 1 as the network input, while computing the loss respectively on three and six microphones. We tune J to 1 (i.e., non-causal FCP filter), considering that, for a specific target speaker, the reference microphone may not be the microphone closest to that speaker5. See an interpretation on why non-causal filtering is needed in Appendix G.2. We still set the microphone weight \u03b1p to 1.0 for non-reference microphones (i.e., when p \u0338= 1), but tune \u03b11 to a smaller value based on the validation set. Without using a smaller \u03b11, we found that the DNN easily overfits to microphone 1, as we use the mixture at microphone 1 as the only input and compute the MC loss also on the mixture at microphone 1. The DNN can just aggressively optimize LMC,p to zero at microphone 1 and not optimize that at other microphones. From row 1a of both tables, strong performance is observed"}