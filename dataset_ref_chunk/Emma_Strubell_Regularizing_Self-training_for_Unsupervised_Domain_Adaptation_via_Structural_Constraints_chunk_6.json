{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Emma_Strubell_Regularizing_Self-training_for_Unsupervised_Domain_Adaptation_via_Structural_Constraints_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of the DACS approach mentioned in the text?", "answer": " The purpose of the DACS approach is to maintain benchmark consistency across different base methods.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What backbone is used by both DACS and SAC for architecture?", "answer": " Both DACS and SAC use a standard DeepLabv2 backbone.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What is the significance of DACS and CAG baselines in evaluating the approach?", "answer": " DACS and CAG baselines serve as strong baselines for evaluating the approach as they achieve superior accuracies.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " According to Table 1, how does the base method regularized with the constraint perform compared to the unregularized version?", "answer": " The base method regularized with the constraint outperforms the unregularized version in terms of mIoU.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What are some categories that show improvement with the regularized version?", "answer": " Categories such as sidewalk, sky, traffic light, traffic sign, and bike show improvement with the regularized version.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What observation is made about large gains in both frequent and less-frequent classes?", "answer": " Large gains are observed in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What is suspected to be the reason for the observed uniformity in gains across different classes?", "answer": " The object-region aware constraint is suspected to be the reason for the observed uniformity in gains across different classes.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " In Figure 3, what does the blue dashed box highlight in the qualitative results on Cityscapes post adaptation from GTA?", "answer": " The blue dashed box highlights the semantic classes that the regularized version is able to predict more accurately than the base method.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What is visualized in Figure 3 regarding the predictions of DACS and DACS+PAC models?", "answer": " Figure 3 visualizes the predictions of DACS and DACS+PAC models on randomly selected examples from Cityscapes validation split.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}, {"question": " What is included in Table 4 as per the text?", "answer": " Table 4 includes the ablations that compare the effects of individual components of the regularizer (PAC) on final performance.", "ref_chunk": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}], "doc_text": "86.1 85.5 58.7 62.4 64.9 58.6 58.6 62.3 60.0 63.2 62.6 61.7 65.4 62.6 67.0 64.4 67.5 66.4 30.5 30.8 19.0 31.6 34.6 21.5 32.2 39.7 34.4 33.8 37.5 29.0 35.8 25.1 29.7 30.3 84.8 85.2 65.0 83.3 84.7 85.6 83.2 87.5 84.9 85.5 83.2 87.3 84.4 88.5 88.5 88.6 38.5 27.7 12.0 35.3 21.9 27.9 35.0 32.9 34.1 34.4 46.0 39.2 45.7 36.6 49.1 50.5 44.5 34.5 28.6 49.7 42.7 34.8 46.7 47.8 53.1 48.7 45.6 49.6 50.2 45.8 54.6 54.5 1.7 6.4 4.5 3.3 41.1 18.0 0.0 1.6 16.9 0.0 25.7 23.2 0.0 23.9 9.8 1.5 31.6 25.2 31.1 28.8 29.3 22.9 33.7 34.9 27.7 36.1 23.5 34.7 27.2 36.5 26.6 17.0 32.4 24.4 42.0 35.6 37.2 49.3 42.2 39.5 46.4 37.8 49.9 39.6 34.0 56.8 45.3 39.3 45.5 45.4 42.7 48.5 50.2 47.4 49.2 49.2 50.5 50.4 50.6 51.5 52.1 52.6 53.8 52.8 DACS + PAC (ours) 93.2 58.8 87.2 33.3 35.1 38.6 41.8 51.4 87.4 45.8 88.3 64.8 31.6 84.3 51.7 53.4 0.6 31.3 50.6 54.2 Table 3. SYNTHIA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our PAC-UDA with prior works. \u2020 de- notes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s e l b a t e g e v y k s n o s r e p r e d i r r a c s u b r o t o m e k i b mIoU SPIGAN [24] DCAN [56] DISE [7] AdvEnt [50] DADA [51] CAG-UDA [60] PIT [31] PyCDA\u2020 [26] FADA [52] DACS [47] IAST [32] RPT\u2020 [61] SAC [2] SAC* [2] 71.1 82.8 91.7 85.6 89.2 84.7 83.1 75.5 84.5 80.6 81.9 88.9 89.3 91.7 29.8 36.4 53.5 42.2 44.8 40.8 27.6 30.9 40.1 25.1 41.5 46.5 47.2 52.7 71.4 75.7 77.1 79.7 81.4 81.7 81.5 83.3 83.1 81.9 83.3 84.5 85.5 85.1 3.7 5.1 2.5 8.7 6.8 7.8 8.9 20.8 4.8 21.5 17.7 15.1 26.5 22.6 0.3 0.1 0.2 0.4 0.3 0.0 0.3 0.7 0.0 2.9 4.6 0.5 1.3 1.5 33.2 25.8 27.1 25.9 26.2 35.1 21.8 32.7 34.3 37.2 32.3 38.5 43.0 42.2 6.4 8.0 6.2 5.4 8.6 13.3 26.4 27.3 20.1 22.7 30.9 39.5 45.5 44.1 15.6 18.7 7.6 8.1 11.1 22.7 33.8 33.5 27.2 24.0 28.8 30.1 32.0 30.9 81.2 74.7 78.4 80.4 81.8 84.5 76.4 84.7 84.8 83.7 83.4 85.9 87.1 82.5 78.9 76.9 81.2 84.1 84.0 77.6 78.8 85.0 84.0 90.8 85.0 85.8 89.3 73.8 52.7 51.1 55.8 57.9 54.7 64.2 64.2 64.1 53.5 67.6 65.5 59.8 63.6 63.0 13.1 15.9 19.2 23.8 19.3 27.8 27.6 25.4 22.6 38.3 30.8 26.1 25.4 20.9 75.9 77.7 82.3 73.3 79.7 80.9 79.6 85.0 85.4 82.9 86.5 88.1 86.9 84.9 25.5 24.8 30.3 36.4 40.7 19.7 31.2 45.2 43.7 38.9 38.2 46.8 35.6 29.5 10.0 4.1 17.1 14.2 14.0 22.7 31.0 21.2 26.8 28.5 33.1 27.7 30.4 26.9 20.5 37.3 34.3 33.0 38.8 48.3 31.3 32.0 27.8 47.6 52.7 56.1 53.0 52.2 36.8 38.4 41.5 41.2 42.6 44.5 44.0 46.7 45.2 48.3 49.8 51.2 52.6 50.3 SAC + PAC (ours) 83.2 40.5 85.4 30.0 2.0 43.0 42.2 33.8 86.3 89.8 65.3 33.5 85.1 35.2 29.9 55.3 52.5 DACS approach, we adopt the training and validation splits of Cityscapes used in SAC to maintain benchmark consis- tency across different base methods. In terms of architec- ture, DACS and SAC use a standard DeepLabv2 [9] back- bone whereas CAG augments this backbone with a decoder model (see [60] for details). For the sake of fair compari- son, we try our best to achieve baseline accuracies that are at least as good as the published results. While we achieved slightly lower performance on SAC due to resource con- straints, we achieve superior accuracies for DACS and CAG baselines. Thus, these methods serve as strong baselines for evaluating our approach. From Table 1, we observe that base methods regularised with our constraint always, and sometimes signi\ufb01cantly, outperforms the unregularised version in terms of mIoU (by up to 2.2%). Secondly, the improvement is across various categories of both stuffs and things type. Some of these include sidewalk (up to 9.6%), sky (up to 2.4%), traf\ufb01c light (up to 2.1%), traf\ufb01c sign (up to 4.4%) and bike (up to 7.2%) classes under GTA\u2192Cityscapes while wall (up to 7.4%), fence (up to 2.0%), person (up to 2.5%) and bus (up to 5.7%) classes under SYNTHIA\u2192Cityscapes. While different adaptation settings favour different classes, a particularly striking observation is that large gains are ob- 7 Figure 3. Qualitative results on Cityscapes [12] post adaptation from GTA [37]: Blue dashed boxes highlight the semantic classes that our regularized version (DACS+PAC) is able to predict more accurately than the base method (DACS). Further visualisations are provided in the supplementary. tained in both frequent (sidewalk, wall) and less-frequent (bus, bike) classes. We suspect that such uniformity arises from our object-region aware constraint that is agnostic to the statistical dominance of speci\ufb01c classes. Finally, Fig. 3 visualises these observations by comparing the predictions of DACS and DACS+PAC models (trained on GTA) on ran- domly selected examples from Cityscapes validation split. Table 4. Ablations: Comparing the effects of individual components of the regulariser (PAC) on \ufb01nal performance (mIoU). Here, the full model is DACS+PAC, and the adaptation setting is GTA\u2192Cityscapes; hy- perparameters are: ks = 50, b = 200, \u03b4peak = 0.0025; \u201cPL\u201d refers to pseudo-labelling. We include classwise IoUs in the supplementary. Con\ufb01guration mIoU All Only PL Only Depth + RGB segments Only Depth segments w/ PL Only RGB segments w/ PL 54.2 49.3 51.9 51.7 52.1 4.2. Prior Works Comparison In this section, we compare our best"}