{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Jamie_Callan_KALE:_Using_a_K-Sparse_Projector_for_Lexical_Expansion_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " According to the text, what was the result of directly sparsifying the teacher vectors compared to when a student LM is learned?", "answer": " Directly sparsifying the teacher vectors resulted in lower performance compared to learning a student LM.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " Why did directly sparsifying the teacher vectors result in lower performance?", "answer": " The teacher LM vectors are real valued, causing the TopK operation to ignore dimensions with high absolute value but negative weight.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " How did the latencies behave in the experiments mentioned in the text?", "answer": " Latency depends on the posting list sizes of the added terms, and smaller vocabularies cause an increase in the average posting list size, making search slower.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " In the experiments, what effect did larger vocabularies have when complementing KALE with BM25?", "answer": " Adding larger vocabularies increased latency since queries were made longer, considering terms from both the English and KALE vocabularies.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " What did the experiments indicate about the efficiency and effectiveness of KALE versus the original BM25 baseline?", "answer": " KALE was able to significantly outperform the BM25 baseline in efficiency and effectiveness.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " How did experiments with larger vocabularies, in the KALE only setting, compare to the original BM25 baseline?", "answer": " Experiments with larger vocabularies in the KALE only setting were more efficient than the original BM25 baseline.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " What was observed regardless of the vocabulary size when using KALE alongside the lexical vocabulary?", "answer": " A significant improvement over BM25 was observed independently of the vocabulary size.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " What trade-off is expected when considering different expansion terms in the query/document, according to the text?", "answer": " A trade-off between efficiency and effectiveness is expected, where a higher number of terms should improve text representations but may hurt query latency.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " How did increasing the vocabulary size impact efficiency and effectiveness in the KALE only scenario?", "answer": " Increasing the vocabulary size consistently resulted in efficiency and effectiveness gains, although accuracy flattened.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}, {"question": " Why did leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduce noise in the passage representations?", "answer": " Forcing terms to exist across passages despite bearing no semantic similarity likely introduces noise in the passage representations.", "ref_chunk": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}], "doc_text": "0.518 0.538\u2020 0.540\u2020 0.569\u2020 0.562\u2020 0.565\u2020 0.639\u2020 0.646\u2020 0.649\u2020 0.626\u2020 0.627\u2020 0.624\u2020 0.637\u2020 0.624\u2020 0.606\u2020 Recall@10 0.164 0.207\u2020 0.166 0.164 0.159 0.173 0.169 0.182 0.178 0.167 0.213\u2020 0.219\u2020 0.206\u2020 0.204\u2020 0.206\u2020 0.205\u2020 0.214\u2020 0.194 0.212 QL 17 182 86 73 63 22 16 14 15 14 93 75 72 27 24 19 19 18 84 The last block of the table answers the question of whether there is a necessity of learning the student LM. The block tested a setting where sparsification, indexing, and consequent search occurred directly over the dense outputs of the Teacher LM, bypassing any additional training. Directly sparsifying the teacher vectors resulted in a lower performance compared to the setting where a student LM is learned and a new vocabulary vector is generated through the projector. This is likely because the teacher LM vectors are real valued (compared to projected vectors from KALE, which go through a ReLU operation), which causes the TopK operation to ignore dimensions with a high absolute value, but negative weight. The latencies behaved as expected. Every query was expanded with a fixed number of artificial terms, so latency depends on the posting list sizes of the added terms. Passages were also expanded with a constant number of KALE terms, meaning smaller vocabu- laries cause an increase in the average posting list size, therefore making search slower. Some experiments with larger vocabularies, in the KALE only setting, are more efficient than the original BM25 baseline. This may indicate that the KALE term posting list sizes are reasonably uniform, avoiding typical skews from the English vocabulary. When complementing KALE with BM25, latency in- creased since queries were made longer, considering terms from both the English and KALE vocabularies. in isolation were able to significantly outperform the BM25 base- line, both in efficiency and effectiveness. When augmenting the existing English vocabulary, larger vocabularies underperformed, possibly given the experimental decision of keeping a fixed num- ber of expansion terms. Nonetheless, KALE showed to be specially effective together with the lexical vocabulary. Moreover, a signifi- cant improvement over BM25 was observed independently of the vocabulary size, which indicates that regardless of the nature of the concepts being captured, KALE is consistently able to improve on the lexical vocabulary. Throughout the other tests KALE was therefore considered together with the lexical terms. 5.2 Evaluating the Number of Expansion Terms When considering different expansion terms in the query/document, a trade-off between efficiency and effectiveness is expected. A higher number of generated query/passage terms should improve the text representations, therefore increasing accuracy. However, adding new terms either causes the inverted lists to become longer (by increasing the number of passage terms), or forces retrieval and search over additional inverted lists (when adding query terms), hence hurting query latency. In summary, increasing the vocabulary size showed to be benefi- cial, specially in the KALE only scenario. In this setting, a larger vocabulary consistently resulted in efficiency and effectiveness gains, although accuracy flattened. Furthermore, the KALE terms This subsection reports tests varying the number of terms to expand the queries and passages, and Table 2 displays the exper- imental results. In general, an effectiveness stability is observed across the several vocabulary sizes, and the reported intuitions match the results. Regarding latency, an increase in expansion terms, whether in the query or the passages, did lead to an effi- ciency drop. Increasing the amount of query terms consistently lead KALE: Using a K-Sparse Projector for Lexical Expansion ICTIR \u201923, July 23, 2023, Taipei, Taiwan. Table 2: Experimental results when changing the number of query and passage terms in the KALE representations. KALE terms were used together with the lexical terms in BM25. QL denotes MSMARCO query latency, measured in milliseconds. MSMARCO Dev TREC DL 19 TREC DL 20 |V| 1024 1024 1024 1024 32768 32768 32768 32768 98304 98304 98304 98304 131072 131072 131072 131072 \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 8 8 16 16 16 16 32 32 16 16 32 32 16 16 32 32 \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 32 64 64 128 64 128 128 256 64 128 128 256 64 128 128 256 MRR@10 0.292 0.279 0.309 0.288 0.301 0.307 0.310 0.316 0.296 0.303 0.316 0.319 0.297 0.302 0.312 0.318 Recall@10 0.548 0.538 0.567 0.555 0.539 0.554 0.555 0.566 0.535 0.542 0.557 0.564 0.533 0.548 0.553 0.564 NDCG@10 0.592 0.603 0.630 0.631 0.615 0.607 0.628 0.633 0.628 0.625 0.647 0.646 0.613 0.627 0.640 0.657 Recall@10 0.127 0.138 0.133 0.143 0.126 0.134 0.133 0.135 0.132 0.136 0.137 0.142 0.112 0.124 0.133 0.131 NDCG@10 0.614 0.622 0.649 0.606 0.627 0.655 0.639 0.657 0.637 0.656 0.636 0.639 0.624 0.644 0.660 0.673 Recall@10 0.210 0.208 0.206 0.194 0.206 0.205 0.206 0.211 0.214 0.216 0.209 0.210 0.194 0.204 0.216 0.218 QL 31 36 72 86 24 27 41 52 19 19 21 26 18 20 22 25 to a higher accuracy, and increasing the number of passage terms also provided accuracy benefits, with the exception of a vocabulary of 1,024 terms. Leveraging smaller vocabularies and forcing every passage to be expanded with a large number of artificial terms likely introduces noise in the passage representations, since the terms are forced to exist across passages despite bearing no semantic similarity among themselves. Like in previous experiments, KALE showed robustness from an effectiveness perspective, regardless of vocabulary size, query terms, or passage terms. Overall, the results from these tests confirmed our expectations regarding the trade-offs between accuracy and efficiency. More expansion terms improved effectiveness, with a query latency cost. Given the conclusions from this subsection and from the previous subsection, a set of hyperparameters was chosen for subsequent ex- periments, in an attempt to balance accuracy and efficiency. Specif- ically, the vocabulary size was kept at 98,304, \ud835\udc58\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f \ud835\udc66 was set to 32, and \ud835\udc58\ud835\udc5d\ud835\udc4e\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc52 was set to 256. This configuration was kept throughout the remainder of the experiments. 5.3 Complementing Different Representations Previous subsections demonstrated KALE to be compatible with the English lexical vocabulary, through the BM25 retriever. Other learned sparse representations operate over the same or similar vocabularies, with different"}