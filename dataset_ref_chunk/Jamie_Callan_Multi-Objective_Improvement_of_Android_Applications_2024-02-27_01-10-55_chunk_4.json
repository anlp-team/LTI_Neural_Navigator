{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Jamie_Callan_Multi-Objective_Improvement_of_Android_Applications_2024-02-27_01-10-55_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some examples of successful techniques mentioned in the text?,        answer: Some examples of successful techniques mentioned are deep parameter optimization to reduce energy consumption of Android apps and reducing the time taken to move between Activities in Android apps.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " Why is multi-objective optimization important in genetic improvement?,        answer: Multi-objective optimization is important because performance properties like runtime and memory consumption often conflict with each other, and by using multi-objective algorithms, a Pareto front of non-dominated solutions can be found.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What is the difference between NSGA-II and NSGA-III in terms of selecting individuals for the next generation?,        answer: NSGA-II sorts the population into Pareto fronts based on fitness and selects individuals one by one, while NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " How does SPEA2 determine the strength of an individual?,        answer: SPEA2 calculates the individual strength based on the number of other individuals that the individual Pareto dominates.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What practical changes are highlighted when using genetic improvement for Android apps compared to traditional desktop environments?,        answer: Practical changes include the fact that Android apps use APIs for features only present on actual devices, and the Android library available when testing apps on desktop operating systems overwrites APIs causing errors.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What is the role of the Context class in Android applications?,        answer: The Context class in Android applications gives the code access to the shared state of the application but is only available on devices.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " How are Android apps generally built and why does it cause compatibility issues?,        answer: Android apps are generally built using Gradle with the Android Gradle plugin, causing compatibility issues with tooling surrounding automatic compilation and testing of code.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What does the GI framework for Android app improvement, shown in Figure 1, include?,        answer: The GI framework for Android app improvement includes mutation, crossover, Gradle compilation, fitness search, fitness results, new population, candidate patches, and selection.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What happens in the case of local search in the GI framework for Android app improvement?,        answer: In the case of local search, only mutation is applied.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " Why is it important to explore the capabilities of different multi-objective algorithms in genetic improvement?,        answer: It is important to explore the capabilities of different multi-objective algorithms because it is yet unclear which approach works best for genetic improvement, thus different algorithms need to be compared to determine their effectiveness.    ", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}], "doc_text": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}