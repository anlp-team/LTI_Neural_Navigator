{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Daphne_Ippolito_Extracting_Training_Data_from_Diffusion_Models_chunk_15.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What does Xrec represent in the context of the text?", "answer": " Xrec represents the reconstructed examples for a target x.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What is plotted in Figure 22a?", "answer": " In Figure 22a, the normalized (cid:96)2 distance between the reconstruction and target is plotted against the loss of the reconstructed examples.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What is the purpose of dividing the main loss by the support loss in Figure 22c?", "answer": " Dividing the main loss by the support loss in Figure 22c increases the correlation between the contrastive loss and the (cid:96)2 distance.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What relationship is observed between loss and (cid:96)2 distance in the text?", "answer": " There is a small positive correlation between loss and (cid:96)2 distance, indicating that some reconstructions are visually similar to the target while others show notable differences.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What is the effect of using a contrastive loss in the context of the text?", "answer": " Using a contrastive loss filters out examples that are seen as likely under both models, making reconstructions more visually similar to the target.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What is the significance of Figure 23 in the text?", "answer": " Figure 23 shows that the attack fails when the target image was not included in training, indicating that the model relies on memorization rather than generalization for correct inpainting.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " How many models were trained for each GAN architecture?", "answer": " A total of 256 models were trained for each GAN architecture.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What was different in the training setup for BigGAN architecture compared to StyleGAN and MHGAN?", "answer": " For BigGAN architecture, the number of training steps was increased to 200,000 to enhance image fidelity, unlike the default hyper-parameters used for StyleGAN and MHGAN.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " How were the models trained on CIFAR-10 dataset selected?", "answer": " The iteration that achieved the highest FID score on the test set was selected for each model trained on a randomly selected half of the CIFAR-10 dataset.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}, {"question": " What do Figures 24 and 25 show in the text?", "answer": " Figures 24 and 25 contain additional examples extracted from GANs trained on CIFAR-10, showcasing training examples for different GAN architectures.", "ref_chunk": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}], "doc_text": "As previously explained, for a target x, we create Xrec where |Xrec| = 5000. In Figure 22a, for every xrec \u2208 Xrec, we plot the normalized (cid:96)2 distance between the reconstruction and target, against the loss (at diffusion timestep 100) of xrec. We also plot in Figure 22d, the eight examples from Xrec that have the smallest loss on the main model. There is a small positive correlation between loss and (cid:96)2 distance; although some appear to be similar to x, there are notable differences. In Figure 22b we compare the loss of each reconstruction on the main model against the support model we will use to form the contrastive loss. We make this correlation more pronounced by dividing the main loss by the support loss in Figure 22c. This has the effect of increasing the correlation between the (now contrastive) loss and (cid:96)2 distance. This has the effect of \ufb01ltering out examples that are seen as likely under both models, and can be seen by inspecting the eight examples from Xrec that have have the smallest main model loss support model loss in Figure 22e. These examples look more visually similar to x in comparison to examples in Figure 22d. Figure 22 inspected the attack success when x was in the training set. We show in Figure 23 that the attack fails when x was not included in training; using a contrastive loss doesn\u2019t sign\ufb01cantly increase the Pearson correlation coef\ufb01cient. This means our attack is indeed exploiting the fact that the model can only inpaint correctly because of memorisation and not due to generalisation. 27 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 22: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. 28 (a) Loss (using the main model at diffusion timestep 100) on all 5,000 inpainted examples Xrec. (b) Comparison of loss on main and support models (at diffusion timestep 100) on all 5,000 inpainted examples. (c) Contrastive loss ( main model loss support model loss ) on all 5,000 inpainted examples Xrec. (d) 8 inpainted examples with the smallest loss. Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. (e) 8 inpainted examples with the smallest main model loss Leftmost is the original example, second to left is the masked example and the rest are inpainted examples. support model loss . Figure 23: Example of an inpainting attack (against a model we refer to as the main model) on an image of a bird from CIFAR-10 when that image is not included in training, and we mask out 60% of the central pixels. In (a) we plot the L2 distance between 5,000 inpainted reconstructions and the original (non-masked out) image and compare this to the loss with respect to the (main) model. In (b), we compare the loss of these reconstructions on the (main) model with a support model for which we know the image wasn\u2019t contained in the training set. In (c), we compare L2 distances between reconstructions with a contrastive loss which is given as the loss of the image with respect to the main model divided by the loss of the image with respect to the support model, and \ufb01nd there is stronger relationship between smaller L2 distances and smaller losses compared to (a). Figure (d) gives examples of reconstructions with small loss and Figure (e) gives examples of reconstructions with small contrastive loss. E GAN Training Setup We used on StudioGAN10 codebase for training GAN in this work. For the StyleGAN and MHGAN architectures, we followed the default hyper-parameters provided in the StudioGAN repository. However, for the BigGAN architecture, we increased the number of training steps to 200,000, which is different from the original hyper-parameters, to increase image \ufb01delity. We trained a total of 256 models for each GAN architecture, with each model being trained on a randomly selected half of the CIFAR-10 dataset. We selected the iteration that achieved the highest FID score on the test set for each model. F Additional GAN Extraction Results Figure 24 and Figure 25 contain additional examples extracted from GANs trained on CIFAR-10. 10https://github.com/POSTECH-CVLab/PyTorch-StudioGAN 29 (a) StyleGAN (b) MHGAN (c) BigGAN Figure 24: Training examples extracted from a CIFAR-10 GAN for different architectures across 107 generations. 30 (a) WGAN (b) E2GAN (c) NDA (d) DiffAugment-BigGAN (e) StyleGAN-ADA (f) DDPM Figure 25: Training examples extracted from different publicly available pretrained GANs"}