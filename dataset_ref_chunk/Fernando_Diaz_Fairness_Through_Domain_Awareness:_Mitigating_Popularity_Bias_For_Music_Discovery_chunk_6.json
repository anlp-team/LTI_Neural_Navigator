{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Fernando_Diaz_Fairness_Through_Domain_Awareness:_Mitigating_Popularity_Bias_For_Music_Discovery_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the significance of having a high percentage but low coverage in recommendations?,        answer: It means the same niche items are being selected many times.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " Explain the concept of high coverage but low percentage in recommendations.,        answer: It means the algorithm is selecting a diverse set of niche items but recommending them very rarely.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " What is the purpose of defining a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, in the context of music and fairness performance metrics?,        answer: To evaluate the performance metrics for artist recall and sound homogeneity.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " How is Artist Recall@100 metric calculated?,        answer: It is calculated as the number of unique artists in the ground truth set that are also recommended by the algorithm, divided by the total number of artists in the ground truth set.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " What does the metric Sound Homogeneity@100 measure?,        answer: It measures the cosine similarity between the musical feature vectors of recommended tracks in a playlist.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " What does the Artist Diversity (per playlist) metric in the fairness category measure?,        answer: It measures the ratio of the number of unique artists recommended in a playlist to the total number of recommended artists.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " How is the Percentage of Long Tail Items calculated in the context of fairness metrics?,        answer: It is calculated as the percentage of long tail items recommended in a playlist out of all recommended items.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " Explain the Coverage over Long Tail Items metric in fairness calculations.,        answer: It measures the coverage of long tail items in recommended items by considering the ratio of long tail items recommended to the total number of long tail items.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " What does the Coverage over Artists metric in fairness calculations evaluate?,        answer: It evaluates the coverage of unique artists in the recommended items by considering the ratio of unique recommended artists to the total number of unique artists.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}, {"question": " What are the two naive baselines used before the fairness mitigation techniques?,        answer: The baselines are using raw feature vectors and recommending the most popular tracks in each dataset.    ", "ref_chunk": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}], "doc_text": "over all recommendations. If a recommender has a high percentage but low coverage, the same niche items are being selected many times. Meanwhile, if an item has high coverage but a low percentage, the algorithm is selecting a diverse set of niche Conference\u201917, July 2017, Washington, DC, USA Table 2: Music and fairness performance metrics. We de- fine a ground truth set, \ud835\udc3a, and a recommended set, \ud835\udc45, we define the set of unique artists in a playlist as \ud835\udc34(.) and the \ud835\udc51-dimensional musical feature matrix associated with the tracks of a playlist as \ud835\udc39 (.) \u2208 R\u2223.\u2223\u00d7\ud835\udc51 . Metric Category Formulation Artist Recall@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 1 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d )\u2223 \u2223\ud835\udc34(\ud835\udc3a\ud835\udc5d ) \u2229 \ud835\udc34(\ud835\udc45\ud835\udc5d )\u2223 Sound Homogeneity@100 Music 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 cos(\ud835\udc39 (\ud835\udc61\ud835\udc56 ), \ud835\udc39 (\ud835\udc61\ud835\udc56 )) \u2200(\ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 ) \u2208 \ud835\udc45\ud835\udc5d Artist Diversity (per playlist) Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc34(\ud835\udc43 )\u2223 \u2223{\ud835\udc34(\ud835\udc45\ud835\udc5d )}\u2223 1 Percentage of Long Tail Items Fairness 1 \u2223\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223 \u2211\ud835\udc5d\u2208\ud835\udc43\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61 \u2223\ud835\udc5d\u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\ud835\udc5d \u2229 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc3f\ud835\udc47 }\u2223 1 Coverage over Long Tail Items Fairness \u2223\ud835\udc3f\ud835\udc47 \u2223 \u2223{\ud835\udc61\ud835\udc56 \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45 \u22c2 \ud835\udc61\ud835\udc56 \u2208 \u2223\ud835\udc3f\ud835\udc47 \u2223} 1 Coverage over Artists Fairness \u2223\ud835\udc34\u2223 \u2223{\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc51(\ud835\udc61\ud835\udc56 ) \u2236 \ud835\udc61\ud835\udc56 \u2208 \ud835\udc45\u2223} 1 content but recommending it very rarely. The gold standard is a high value on both metrics. 4.4 Baselines First, we use two naive baselines: (1) Features: Instead of the learned representations, we use the raw feature vectors and (2) MostPop: we calculate most popular tracks in each dataset and recommend them each time. Then, we select three state of the art fairness mitigation techniques: (1) ZeroSum[54]: an in-processing group fairness that defines a regularization term which forces scores within negative and positive item groups to remain close. Following their original implementation, we select LGCN [34] as the back- bone recommender. (2) MACR[62]: an inprocessing method which uses counterfactual estimation to denoise for the effects of popu- larity bias in user and item embeddings. Here too, Following their original implementation, we select LGCN [34] as the backbone rec- ommender, and (3) Smooth xQuAD[3]: a post-processing method that reranks recommendations to improved diversity. 4.5 Parameter Settings & Reproducibility Each of the baseline methods was tested with learning rates \u223c (0.01, 0.0001), embedding sizes of [10, 24, 64, 128] and batch sizes of [256, 512, 1024]. For the values in the tables below, each stochas- tic method was run 5 times and averaged. All details and further hyperparameter settings can be found on our GitHub repository 1. 5 Results In this section we present the results of our experimentation. First, we show the connections between individual fairness, popularity bias, and music discovery in the graph domain. Then, we evaluate our method, comparing with a series of the debiasing benchmarks. 5.1 RQ1: How does incorporating individual fairness improve the mitigation of popularity bias and facilitate music discovery? To showcase the performance of our algorithm in the discovery set- ting and motivate the need for individual fairness in the mitigation 1preliminary 9B7F/README.md version: https://anonymous.4open.science/r/RecSys23- Rebecca Salganik, Fernando Diaz, and Golnoosh Farnadi Figure 3: Simulating Popularity Bias: We select 100 of the most popular songs in MPD [57], duplicate their node level features, add them with new song track ids, and connecting them to one randomly selected playlist. Then, we analyze the distances between the embedding group centroids. We find that REDRESS and BOOST have the lowest distance between the original, popular and duplicated, unpopular track groups, showing the least amount of popularity bias. of popularity bias, we draw on the definition of music discovery presented in Section 3.3.2 by evaluating the effects of popularity bias on learned representations of popular and unpopular songs. To simulate a situation of maximal popularity bias, we consider the hypothetical example in which extremely popular songs are reversed to become unpopular and measure the effects of degree on their learned representations. From a discovery perspective, the purpose of this simulation is to imagine the most popular song by a listener\u2019s favorite artist before it became popular. Our simulation aims to approximate how likely it is that they have discovered the song in relation to its musical attributes, with and without debiasing for the effects of popularity. More formally, for each song track, \ud835\udc61\ud835\udc56 \u2208 \ud835\udc47\ud835\udc42\ud835\udc3a , we generate a counterfactual example song, \ud835\udc61 \u2217 \ud835\udc56 \u2208 \ud835\udc47\ud835\udc36\ud835\udc39 , where everything about the features is exactly the same and the only difference is that \ud835\udc61\ud835\udc56 appears in many playlists while \ud835\udc61 \u2217 \ud835\udc56 appears only once. We augment the original dataset to include these counterfactual songs, \ud835\udc47 = \ud835\udc47\ud835\udc42\ud835\udc3a \u22c3\ud835\udc47\ud835\udc36\ud835\udc39 . Then, we use five methods to learn the item level representations: one baseline recommender, PinSage, and four bias mitigation methods, ZeroSum [54], MACR [62], REDRESS, and BOOST. We apply 2-dimensional PCA to each embedding set and analyze the Euclidean distance between the centroids of original track embeddings, \u00af\ud835\udc47\ud835\udc42\ud835\udc3a , and counterfactual track embeddings, \u00af\ud835\udc47\ud835\udc36\ud835\udc39 . Due to the size of our dataset, we run this metric using the 100 most popular tracks in the MPD dataset and leave further exploration of this phenomenon for future work. Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery As shown in Figure 3, we find that all fairness interventions de- crease the distance between the two centroids. Furthermore, as the granularity of fairness increases, the distance between the centroids of learned representations decreases. For example, PinSage, which has no mitigation of popularity bias, has the largest distance of 0.172. ZeroSum [54], which considers group fairness, decreases the distance to 0.143, MACR [62], which uses counterfactual estimation, shrinks to 0.055. Finally, our methods, REDRESS and BOOST are able to achieve both the lowest distance and the correct orientation between the two embedding spaces. In these results, we see that the domain-awareness of our method- ology, which enables it to understand musical similarity between items, allows it to be robust to the effects of popularity bias on a learned song embedding. Thus, in the setting of musical discovery, it is able"}