{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_15.txt", "num_qa_pairs": 10, "qa_list": [{"question": " Which toolkits provide a vectorized beam search interface for sequence to sequence tasks?", "answer": " Tensorflow and FAIRESEQ", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What do toolkits like ESPnet, ESPRESSO, LINGVO, and RETURNN support?", "answer": " The vectorized beam search algorithm", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What scoring approach is used in time synchronous beam search to synchronize the word-based language model with a character-based end-to-end ASR?", "answer": " Word-based language model scores triggered by the word delimiter symbol", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " How is the word and character-based LM combination represented in [260] and [261]?", "answer": " Using look-ahead word probabilities to predict next characters instead of using the character-based LM", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What is the purpose of the multi-pass fusion method in the beam search algorithms?", "answer": " To perform n-best or lattice scoring by considering the entire context within an utterance", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What are some examples of two-pass algorithms that have been investigated for end-to-end ASR systems?", "answer": " RNN-T \u2192 AED and CTC \u2192 AED", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What is the purpose of generating a lattice output in addition to the N-best output in ASR systems?", "answer": " To provide richer hypothesis information for better multi-pass decoding", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What is one of the prominent properties shared between E2E and classical statistical ASR systems?", "answer": " The use of a single-pass decoding strategy", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " How does E2E beam search differ from classical search approaches in terms of beam size?", "answer": " E2E beam search usually uses very small beam sizes around 1 to 100", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}, {"question": " What is the role of external language models in E2E ASR systems?", "answer": " External LMs help improve recognition accuracy in E2E ASR for various reasons such as compensation for poor generalization, use of external text data, and domain adaptation", "ref_chunk": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}], "doc_text": "toolkits support this vectorization. For example, Tensorflow9 [269], and FAIRESEQ10 [270] pro- vide a vectorized beam search interface for a generic sequence to sequence task, and it can be used for attention-based end-to- end ASR. End-to-end ASR toolkits including ESPnet11 [259], ESPRESSO12[261], LINGVO [271], and, RETURNN13 [272] also support the vectorized beam search algorithm. Another approach used in the time synchronous beam search is to insert the word-based language model score triggered by the word delimiter (space) symbol [75]. To synchronize the word-based language model with a character-based end-to-end ASR, [260] combines the word and character-based LMs with the prefix tree representation, while [239], [261] uses look- ahead word probabilities to predict next characters instead of using the character-based LM. The prefix tree representation is also used for the sub-word token unit case [262], [263]. H. Multi-pass Fusion The previous fusion methods are performed during the beam search, which enables a one-pass algorithm. The popular alternative methods are based on multi-pass algorithms where we do not care about the synchronization and perform n-best or lattice scoring by considering the entire context within an ut- terance. [16] uses the N-best rescoring techniques to integrate a word-based language model. [55] combines forward and backward searches within a multi-pass decoding framework to combine bidirectional LSTM decoder networks. Recently two- pass algorithms of switching different end-to-end ASR systems have been investigated, including RNN-T \u2192 AED [264]; CTC \u2192 AED [265], [266]. This aims to provide streamed output in the first pass and re-scoring with AED in the second pass to refine the previous output, thus satisfying a real-time interface requirement while providing high recognition performance. In addition to the N-best output in the above discussion, there is a strong demand for generating a lattice output for better multi-pass decoding thanks to richer hypothesis information in a lattice. The lattice output can also be used for spoken term detection, spoken language understanding, and word posteriors. However, due to the lack of Markov assumptions, RNN-T and AED cannot merge the hypothesis and cannot generate a lattice straightforwardly, unlike the Relationship to Classical ASR One of the most prominent properties shared between E2E and classical statistical ASR systems is the use of a single- pass decoding strategy, which integrates all knowledge sources involved (models, components), before coming to a final decision [123]. This includes the use of full label context dependency both for E2E systems [229], [51], [77], [273], [174], [262], [274], [275], as well as classical systems via full- context language models [276], [244], [245], [277]. In classical ASR systems, even HMM alignment path summation may be retained in search [278]. Both E2E as well as classical ASR systems employ beam search in decoding. However, compared to classical search approaches, E2E beam search usually is highly simplified with very small beam sizes around 1 to 100 [15], [16], [77], [147]. Very small beam sizes also partly mask a length bias exhibited by E2E attention-based encoder- decoder models [279], [280], thus trading model errors against search errors [281]. An overview of approaches to handle the length bias beyond using small beam sizes in ASR is presented in [236]. Many classical ASR search paradigms are based on mul- tipass approaches that successively generate search space representations applying increasingly complex acoustic and/or language models [282], [283], [243]. However, multipass strategies also are employed using E2E models, which how- ever softens the E2E concept. Decoder model combination is pursued in a two-pass approach, while even retaining latency constraints as in [87]. Further multipass approaches include E2E adaptation approaches [284], [285], [286], [287]. 9 https://www.tensorflow.org/api docs/python/tf/contrib/seq2seq/BeamSearchDecoder 10 https://github.com/pytorch/fairseq/blob/master/fairseq/sequence generator.py 12 https://github.com/freewym/espresso 13 https://github.com/rwth-i6/returnn 11 https://github.com/espnet/espnet This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 VII. LM INTEGRATION This section discusses language models (LMs) used for E2E ASR. Hybrid ASR systems have long been using a pretrained LM [2], whereas most end-to-end (E2E) ASR systems employ a single E2E model that includes a network component acting as an LM.14 For example, the prediction network of RNN- T and the decoder network of AED models take on the role of a LM covering label back-histories. Therefore, E2E ASR does not seem to require external LMs. Nevertheless, many studies have demonstrated that external LMs help improve the recognition accuracy in E2E ASR. There are presumably three reasons that E2E ASR still requires an external LM: a) Compensation for poor generalization: E2E models need to learn a more complicated mapping function than classical modular-based models such as acoustic models. Con- sequently, E2E models tend to face overfitting problems if the amount of training data is not sufficient. Pretrained LMs potentially compensate for the less generalized predictions made by E2E models. b) Use of external text data: E2E models need to be trained using paired speech and text data, while LMs can be trained with only text data. Generally, text data can be collected more easily than the paired data. The training speed of an LM is also faster than that of E2E models for the same number of sentences. Accordingly, the LM can be improved more effectively with external text data, providing additional performance gain to the ASR system. c) Domain adaptation: Domain adaptation helps im- prove recognition accuracy when the E2E model is applied to a specific domain. However, domain adaptation of the E2E model requires a certain amount of paired data in the target domain. Also, when multiple domains are assumed, it may be costly to maintain multiple E2E models for the domains the system supports. If a pretrained LM for the target domain is available, it may more easily improve recognition accuracy for domain-specific words and speaking styles without updating the E2E model. This section reviews various types of LMs used for E2E ASR and fusion"}