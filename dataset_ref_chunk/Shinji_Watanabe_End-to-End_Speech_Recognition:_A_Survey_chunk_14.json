{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_14.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is frame synchronous beam search?", "answer": " Frame synchronous beam search is an algorithm that performs pruning at every input frame during the search process.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " How does the frame synchronous beam search differ from the label synchronous beam search?", "answer": " Frame synchronous beam search depends on explicit alignment, while label synchronous beam search does not.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " What is LM shallow fusion?", "answer": " LM shallow fusion is a score combination method that linearly adds the language model score to the end-to-end ASR scores during beam search.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " What is the purpose of classical approaches to beam search for HMM, CTC, and RNN-T variants?", "answer": " Classical approaches to beam search for these variants are based on weighted finite state transducers and they are used for frame synchronous beam search.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " How does the asynchronous score fusion handle the mismatch between frame and label time indices?", "answer": " Asynchronous score fusion handles the mismatch by incorporating the language model score in the label transition state.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " What is lexical constraint during score fusion?", "answer": " Lexical constraint during score fusion is used to incorporate word-based lexical constraints for ASR, especially in end-to-end ASR using letter or token units.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " How can vectorization across both hypotheses and utterances accelerate the decoding process?", "answer": " Vectorization enables the replacement of score accumulation steps with vector-matrix operations, leveraging parallel computing capabilities for significant speedups.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " What is the TLG transducer used in classical approaches to ASR?", "answer": " The TLG transducer is composed of the token unit, word lexicon, and word-based language transducers, and it helps incorporate lexical constraints during beam search.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " What is the main advantage of using vectorization during beam search in RNN-T and attention-based models?", "answer": " Vectorization allows for parallel processing of multiple utterances, resulting in faster decoding and significant speedups.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}, {"question": " How does the frame synchronous algorithm handle additional output token transitions inside the beam search algorithm?", "answer": " The frame synchronous algorithm can easily extend to online and streaming decoding by using explicit alignment information with input frame and output token.", "ref_chunk": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}], "doc_text": "we com- bine various scores obtained from different modules, including the main end-to-end ASR and LM scores. D. Frame Synchronous Beam Search In contrast to the label synchronous case in Eq. (8), the frame synchronous beam search algorithm performs pruning at every input frame t, as follows: 1) Synchronous Score Fusion: The most simple score fu- sion is performed when the scores of multiple modules are synchronized. In this case, we can simply add the multiple scores at each frame t or label i. The most well-known score combination is LM shallow fusion. \u02dcC1:i(t) = NBESTC1;i(t) P (C1;i(t)|X), where | \u02dcC1:i(t)| = \u2206 where C1;i(t) is an i(t)-length label sequence obtained from the alignment A1:t, which is introduced in Sec. III-B. P (C1;i(t)|X) is obtained by summing up all possible align- ments A1:t \u2208 A(X,C1;i(t)). Unlike the label synchronous beam search, frame synchronous beam search depends on explicit alignment A; thus, it is often used for explicit alignment including CTC, RNN-T, and RNA. modeling approaches, C1:i(t) is an expanded partial hypotheses up to input frame t, similar to Eq. (7). LM shallow fusion: As discussed in Sec. VII, various neural LMs can be integrated with end-to-end ASR. The most simple integration is based on LM shallow fusion [255][256][257], as discussed in Sec. VII-B1, which (log-) linearly adds the LM score Plm(C1:i) to E2E ASR scores P (C1:i|X) during beam search in Eq. (8) as follows: log P (C1:i|X) \u2192 log P (C1:i|X) + \u03b3 log Plm(C1:i) where \u03b3 is a language model weight. Of course, we can combine other scores, such as the length penalty and coverage terms, as discussed in Sec. VI-C.u Compared with the label synchronous algorithm, the frame synchronous algorithm needs to handle additional output to- ken transitions inside the beam search algorithm. The frame synchronous algorithm can be easily extended in online and/or streaming decoding, thanks to the explicit alignment informa- tion with input frame and output token. Classical approaches to beam search for HMM, but also CTC and RNN-T variants, are based on weighted finite state transducers (WFST) [38], [74], [241] or lexical prefix trees [106], [242], [243]. They are categorized as frame synchronous beam search. These methods are often combined with an N- gram language model or a full-context neural language model [244], [245]. RNN-T [14], [246] and CTC prefix search [247] can deal with a neural language model by incorporating the language model score in the label transition state. Interestingly, triggered attention approaches [248], [249] allow us to use implicit alignment modeling approaches, including AED, in frame-synchronous beam search together with CTC and neural LM, which applies on-the-fly rescoring to the hypotheses given by CTC prefix search using the AED and LM scores. 2) Asynchronous Score Fusion: If we combine the frame- dependent score functions, P (at|\u00b7), used in explicit alignment modeling approaches, e.g., CTC, RNN-T, and label-dependent score functions, P (ci|\u00b7), used implicit alignment modeling approaches, e.g., AED, language model, we have to deal with the mismatch between the frame and label time indices t and i, respectively. In the time-synchronous beam search, this fusion is per- formed by incorporating the language model score in the label transition state [70], [22], [258]. [247] also combines a word-based language model and token-based CTC model by incorporating the language model score triggered by the word delimiter (space) symbol. In the label-synchronous beam search, we first compute the label-dependent scores from the frame-dependent score function by marginalizing all possible alignments given a hypothesis label sequence. CTC/attention joint decoding [86] is a typical example, where the CTC score is computed by marginalizing all possible alignments based on the CTC forward algorithm [229]. This approach eliminates the wrong This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 14 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 15 alignment issues and difficulties of finding the correct end of sentences in the label-synchronous beam search [86]. Note that the model fusion method during beam search can realize simple one-pass decoding, while it limits the time unit of the models to be the same or it requires additional dynamic programming to adjust the different time units, especially for the label-synchronous beam search. This dynamic program- ming computation becomes significantly large when the length of the utterance becomes larger and requires some heuristics to reduce the computational cost [259]. G. Lexical Constraint during Score Fusion Classically, we use a word-based language model to cap- ture the contextual information with the word unit, and also consider the word-based lexical constraint for ASR. However, end-to-end ASR often uses a letter or token unit and it causes further unit mismatch during beam search. As described in previous sections, the classical approach of incorporating the lexical constraint from the token unit to the word unit is based on a WFST. This method first makes a TLG transducer composed of the token (T), word lexicon (L), and word-based language transducers (G) [74]. This TLG transducer has been used for both CTC [74] and attention-based [53] models. HMM-based or CTC systems. To tackle this issue, there are several studies of modifying these models by limiting the output dependencies in the fixed length (i.e., finite-history) [47], [267], or keeping the original RNN-T structure but merging the similar hypotheses during beam search [107]. I. Vectorization across both Hypotheses and Utterances We can accelerate the decoding process by vectorizing multiple hypotheses during the beam search, where we replace the score accumulation steps for each hypothesis with vector- matrix operations for the vectorized hypotheses. This has been studied in RNN-T [22], [258], [268] and attention-based [259] models. This modification leverages the parallel computing capabilities of multi-core CPUs, GPUs and TPUs, resulting in significant speedups, while enabling multiple utterances to be processed simultaneously in a batch. Major deep neural net- work and end-to-end ASR"}