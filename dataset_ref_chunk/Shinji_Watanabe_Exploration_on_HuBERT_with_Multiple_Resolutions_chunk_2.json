{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Exploration_on_HuBERT_with_Multiple_Resolutions_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of controlling the stride of the conv. feature extractor?,answer: To obtain a range of resolutions and correspondingly, distinct HuBERT models.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " How many HuBERT models are considered in the discussion if K = 3?,answer: Three (H1, H2, H3).", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What shapes do the feature tensors X i 2 and X i 3 have?,answer: X i 2 has a shape of RT2\u00d7D and X i 3 has a shape of RT3\u00d7D.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What are the functions UP1, UP2, and UP3 used for in the HuBERT-MR-P model?,answer: To upsample the representations to the greatest common divisor of R1, R2, and R3 to ensure matching feature lengths.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " Describe the hierarchical approach in the HuBERT-MR-H model.,answer: It models multiple resolutions in a sequential manner and fuses the HuBERT representations from low to high resolution.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What architecture is adopted in the HuBERT-MR-H model for fusing representations?,answer: The decoder architecture inspired by U-net is adopted.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What dataset was used to pre-train all HuBERT models?,answer: The Librispeech dataset.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " How many iterations of training were conducted for each HuBERT model?,answer: Two iterations.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What benchmark was used to evaluate HuBERT-MR?,answer: The SUPERB benchmark.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}, {"question": " What were the main focus of the experiments related to HuBERT-MR-P in the SUPERB tasks?,answer: Mainly focused on HuBERT-MR-P without including additional trainable parameters except for the layerwise weights.", "ref_chunk": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}], "doc_text": "as the resolution of features. By controlling the stride of the conv. feature extractor, we can obtain a range of resolutions (R1, ..., RK ) and correspond- ingly, K distinct HuBERT models (H1, ..., HK ). In the next subsections, we discuss the application of the parallel and hier- archical approaches discussed in Sec. 1 to merge K HuBERT models for downstream tasks. For the easiness of discussion, we consider K = 3 as an example and all HuBERT models (H1, H2, H3) use the same model configuration for all encoder modules so that the feature dimension for both models is D. 2.1. Parallel HuBERT-MR (HuBERT-MR-P) As explained in Sec. 1, the parallel approach employs parallel encoders to process input signals at different resolutions. There- fore, we use three HuBERT models (H1, H2, and H3) with res- olutions R1, R2, and R3, respectively, to obtain layerwise fea- tures from the layer before the top encoder layer to the last en- coder layer: (X 0 2 , ..., X N 1 , ..., X N 3 ). These feature tensors have shapes X i 2 \u2208 RT2\u00d7D, and X i 3 \u2208 RT3\u00d7D, respectively. Noted that T1, T2, T3 are different. The illustration of HuBERT-MR-P is shown in Figure 1. We define multi-resolution features XMR-P as follows: 1 ), (X 0 2 ), and (X 0 1 \u2208 RT1\u00d7D, X i 3 , ..., X N XMR-P = N (cid:88) (w1,i\u00b7UP1(X i 1)+w2,i\u00b7UP2(X i 2)+w3,i\u00b7UP3(X i i=0 (1) where w1,i \u2208 [0, 1], w2,i \u2208 [0, 1], and w3,i \u2208 [0, 1] are learn- able weights that sum up to one (i.e., (cid:80)N i=0(w1,i + w2,i + w3,i) = 1). The functions UP1, UP2, and UP3 upsample the representations to the greatest common divisor of R1, R2, and 2In practical situations, it is necessary to incorporate rounding pro- cedures that take into account edge cases. 3)), Table 1: Configurations of the pre-trained HuBERT with multi- resolutions. The convolution (Conv.) module is represented in [(kernel-size, stride)* layer-number]. ID Res.(ms) Param. Conv. Module A B C 20 40 100 94.7 95.2 97.3 (10,5)*1 + (3,2)*4 + (2,2)*2 (10,5)*1 + (3,2)*4 + (2,2)*3 (10,5)*2 + (3,2)*4 + (2,2)*2 R3, denoted as R1,2,3, to ensure matching feature lengths. Fi- nally, we can use XMR-P \u2208 RTMR\u00d7D for various downstream tasks, where TMR = L//R1,2,3. The UP functions can be any upsampling functions, including simple methods such as repeat- ing the features along the time axis, as used in [27], or more complex methods such as transposed conv. networks. 2.2. Hierarchical HuBERT-MR (HuBERT-MR-H) As described in Sec. 1, the hierarchical approach models mul- tiple resolutions in a sequential manner. Unlike U-net-based methods [18, 21, 22], we do not perform additional feature en- coding as the HuBERT models with different resolutions are already pre-trained. Instead, as shown in Figure 1, we adopt the decoder architecture inspired by U-net and fuse the Hu- BERT representations from low to high resolution. Assuming R1 > R2 > R3, we first fuse the outputs from H1 and H2, and then we further fuse H3 for additional downstream models. The fusion module combines the representations from two different resolutions into a single stream. Specifically, we use a conv. module and a de-conv. module for each feature, respec- tively. Note that additional conv. modules improve the stability of the fusion as observed in our experiments. Given input fea- 2 \u2208 RT2\u00d7D, we first apply conv. tures X N modules with residual connections and then employ transposed conv. modules to align their resolutions. The resulting feature X 1:2 X 1:2 1 \u2208 RT1\u00d7D and X N MR-H is defined as: MR-H = DeConv1(Conv1(X N 1 )) + DeConv2(Conv2(X N 2 )). (2) 3 and use trans- Then, we further apply a conv. module to X N posed conv. modules to compute X 1:3 X 1:3 MR-H \u2208 RTMR\u00d7D as: MR-H) + DeConv3(Conv3(X N MR-H = DeConv1,2(X 1:2 We can then use the feature X 1:3 3 )). (3) MR-H for downstream tasks. 3. Experiments 3.1. Pre-trained HuBERT To evaluate the effectiveness of HuBERT models with differ- ent resolutions, we trained three HuBERT models by modifying their conv. feature extractor. The configurations of these models are presented in Table 1. We trained all HuBERT models fol- lowing the same procedure as HuBERT-base in [2], except for changes in label rates and corresponding conv. modules. We conducted two iterations of training for each HuBERT, where the first iteration was trained on Mel frequency cepstral coef- ficients (MFCC) clusters, and the second iteration was trained using the intermediate features\u2019 clusters. The final dimension of each HuBERT was set to D = 768. We pre-trained all Hu- BERT models using the Librispeech dataset [28]. 3.2. Experimental Setups SUPERB benchmark: In our experiments, we evaluate HuBERT-MR on the SUPERB benchmark [3\u20135]. According to Table 2: HuBERT-MR-P on SUPERB benchmark. Detailed tasks and evaluation metrics are discussed in Sec. 3.2. Proposed HuBERT- MR-P is introduced in Sec. 2.1. Model Res.(ms) PR(\u2193) ASR(\u2193) ER(\u2191) IC(\u2191) SID(\u2191) SD(\u2193) SV(\u2193) SE(\u2191) ST(\u2191) HuBERT wav2vec2 20 20 5.41 5.74 6.42 6.43 64.92 63.43 98.34 92.35 81.42 75.18 5.88 6.08 5.11 6.02 2.58 2.55 15.53 14.81 HuBERT-MR-P (100,40,20) 4.83 5.48 63.76 98.51 83.23 5.75 5.10 2.55 16.18 Table 3: The summation of layer weights of HuBERT with dif- ferent resolutions in the HuBERT-MR-P model, which was eval- uated in the SUPERB benchmark as shown in Table 2. HuBERT ASR SV ST Avg. Tasks Table 4: Fine-tuning results on Librispeech-100h (comparison with baselines). Results with language model rescoring are in brackets. HuBERT-MR-P is explained in Sec 2.1 and HuBERT- MR-H is discussed in Sec 2.2. 100ms 40ms 20ms 0.21 0.33 0.46 0.16 0.28 0.56 0.21 0.37 0.42 0.18 0.32 0.50 Model HuBERT HuBERT HuBERT Res.(ms) 20 40 100 WER(\u2193) 7.73( 3.81) 12.38( 4.90) 98.37(97.87) the SUPERB benchmark policy, we do not to include additional trainable parameters except for the layerwise weights. There- fore, we mainly focused on HuBERT-MR-P for the SUPERB tasks. We use the repeating"}