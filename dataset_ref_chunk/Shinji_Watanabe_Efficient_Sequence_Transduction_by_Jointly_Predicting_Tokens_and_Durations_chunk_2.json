{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Efficient_Sequence_Transduction_by_Jointly_Predicting_Tokens_and_Durations_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main difference between Token-and-Duration Transducers (TDT) and conventional transducers?", "answer": " TDT predicts the token duration of the current emission in addition to the output token.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " What does a Token-and-Duration Transducer (TDT) joint network generate as output?", "answer": " A TDT joint network emits two sets of output: one for the output token and the other for the duration of the token.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " How is the probability of observing the first u output labels in the first t frames represented in a TDT model?", "answer": " The probability of observing the first u output labels in the first t frames is represented by node (t, u) in the lattice.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " How is the TDT loss (LTDT) computed?", "answer": " The TDT loss (LTDT) is computed as -log PTDT(y|x), where PTDT(y|x) is the probability of the whole sequence.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " Why is the gradient computation for the TDT loss done analytically?", "answer": " The gradient computation for the TDT loss is done analytically because automatic differentiation for transducer loss is highly inefficient.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " What is the first part of the gradient of the TDT loss with respect to the token probabilities PT(v|t, u)?", "answer": " The first part of the gradient of the TDT loss with respect to the token probabilities PT(v|t, u) is -\u03b1(t, u)*b(v, t, u)/PTDT(y|x).", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " What are the base conditions for the backward variable (\u03b2) in the TDT model?", "answer": " The base condition for the backward variable (\u03b2) is \u03b2(T + 1, U) = 1.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " How are the forward variables \u03b1(t, u) computed in the TDT model?", "answer": " The forward variables \u03b1(t, u) are computed based on a recursive formula involving the duration probabilities and base conditions.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " What is the definition of the TDT loss (LTDT) in relation to the conventional Transducer loss?", "answer": " The TDT loss (LTDT) differs from the conventional Transducer loss in that it sums over durations in D for both non-blank and blank emissions.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}, {"question": " Why is the sum over durations in D for the blank emission in TDT important?", "answer": " The sum over durations in D for the blank emission in TDT is important to consider all possible contributions from states that can reach (t, u), weighted by the corresponding duration probabilities.", "ref_chunk": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}], "doc_text": "conventional RNN-Ts models, and they don\u2019t suffer from the performance degradation for speech corre- sponding to the text with repeated tokens. with recursion base conditions \u03b1(1, 0) = 1 and \u03b2(T, U ) = P (\u00d8|T, U ). In order to make this recursion well-defined, we require that both \u03b1(t, u) and \u03b2(t, u) are zero outside domain 1 \u2264 t \u2264 T and 0 \u2264 u \u2264 U . With those quantities defined, PRNNT(y|x) could be computed with either the \u03b1 or \u03b2 efficiently: PRNNT(y|x) = \u03b1(T, U )P (\u00d8|T, U ) = \u03b2(1, 0). Our TDT model implementation will be open-sourced with NVIDIA\u2019s NeMo 1 toolkit. Then we could compute the loss function as, 2. Background: Transducers LRNNT(y|x) = log PRNNT(y|x). An RNN-Transducer2 (Graves, 2012) consists of an encoder, a decoder (or a prediction network), and a joint network (or a joiner). The encoder and decoder extract higher-level rep- resentations of the acoustic and text and feed the output to the joint network, which generates a probability distribu- tion over the vocabulary. The vocabulary includes a special 3. Token-and-Duration Transducers A Token-and-Duration Transducer (TDT) differs from con- ventional transducers in that it predicts the token duration of the current emission. Namely, the TDT joiner generates two sets of output, one for the output token, and the other for the duration of the token (see Fig. 2). 3 Let us first 1https://github.com/NVIDIA/NeMo/. Pull request https://github.com/NVIDIA/NeMo/pull/6536 2When originally proposed, an RNN-Transducer uses a recur- rent network as the encoder hence the name RNN-T; nowadays Transducers usually adopt more sophisticated networks involving self-attention in their encoder. In this paper, we use the words RNN-T and Transducer interchangeably to represent any encoder- decoder-joiner model that uses the Transducer loss. 3In our implementation, the two outputs are disjoint sub-vectors of the joiner output. For example, let\u2019s take vocabulary size (voc) of 1024 (including \u00d8) that supports durations {0,1,2,3,4} (a total of 5 durations). The last layer of the joiner maps the hidden activation to a tensor joiner_out of size 1024 + 5 = 1029. Then joiner_out[:1024] and joiner_out[1024:] are independently normalized to generate the two sets of distributions. 2 (1) (2) (3) (4) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Figure 2. Architecture of a TDT model, which contains an encoder, a decoder, and a joint network. The TDT joint network emits two sets of output, one for the output token Z(t, u)[:voc], and the other for the duration of the token Z(t, u)[voc:]. The two distributions are jointly trained during model training. define a joint probability P (v, d|t, u) as the probability of generating token v (v could either be a text token or \u00d8), with duration d at location (t, u). We assume that token and durations are conditionally independent: Figure 3. Output probability lattice of TDT model with supported durations {0,1,2}. We follow the convention in (Graves, 2012) making t start with 1 and u with 0. The probability of observing the first u output labels in the first t frames is represented by node (t, u). Dotted arrows constitute a complete path in the lattice. PTDT(y|x) is computed through \u03b1 at the terminal node: 5 PTDT(y|x) = \u03b1(T + 1, U ) P (v, d|t, u) = PT (v|t, u)PD(d|t, u) (5) The backward variables (\u03b2) are computed as, \u03b2(t, u) = (cid:88) \u03b2(t + d, u)P (\u00d8, d|t, u) where PT (.) and PD(.) correspond to the token distribu- tion and duration distribution, respectively. Next, we can compute the forward variables \u03b1(t, u): + d\u2208D\\{0} (cid:88) \u03b2(t + d, u + 1)P (yu+1, d|t, u) d\u2208D \u03b1(t, u) = (cid:88) \u03b1(t \u2212 d, u)P (\u00d8, d|t \u2212 d, u) with the base condition \u03b2(T + 1, U ) = 1. The probability of the whole sequence is PTDT(y|x) = \u03b2(1, 0). + d\u2208D\\{0} (cid:88) \u03b1(t \u2212 d, u \u2212 1)P (yu, d|t \u2212 d, u \u2212 1) (6) With those quantities defined, we define TDT loss as d\u2208D LTDT = \u2212 log PTDT(y|x) with the same base condition \u03b1(1, 0) = 1 as that of the conventional Transducer. Note, this Equation differs from 2 in that, for both non-blank and blank emissions, we need to sum over durations in D to consider all possible contri- butions from states that can reach (t, u), weighted by the corresponding duration probabilities.4 Readers are encour- aged to compare those Equations with the transition arcs in Figure 3 to see the connections. The total output probability 3.1. TDT Gradient Computation We derive an analytical solution for the gradient of the TDT loss, since automatic differentiation for transducer loss is highly inefficient. 6 The gradient of the TDT loss L has two parts. The first part is the gradient with respect to the token probabilities PT (v|t, u): \u2202LTDT \u2202PT (v|t, u) = \u2212 \u03b1(t, u)b(v, t, u) PTDT(y|x) 4We disallow blank emission with duration 0, thus the sum is over D \\ {0} for the blank emission. This makes the model not strictly probabilistic unless we renormalize the duration proba- bilities excluding duration = 0 for blank emissions computation. Although in practice we find that this does not matter, since du- ration=0 is in general rarely predicted according to Figure 4, and this design makes the derivation of gradients much easier. 5This equation, and the base condition of \u03b2 are slightly different from the common definition used for conventional RNNT, although they are equivalent to the standard definition. For TDT though, this notation will make the boundary case much easier. In the recursion, we have \u03b2(T + 1, u) = \u03b1(T + 1, u) = 0, \u2200u \u0338= U . 6The detailed derivation for all gradients is in Appendix A. 3 (7) (8) (9) (10) Efficient Sequence Transduction by Jointly Predicting Tokens and Durations where \u03b1(t, u) are defined in Equation 6 and b(v, t, u) is define as: b(v, t, u) = \uf8f1 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f2 \uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 (cid:88) \u03b2(t + d, u + 1)PD(d|t, u), d\u2208D (cid:88) \u03b2(t + d,"}