{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Neural_Machine_Translation_for_the_Indigenous_Languages_of_the_Americas:_An_Introduction_chunk_3.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some challenges and open questions highlighted in the text regarding machine translation for Indigenous Latin American languages (ILA)?", "answer": " Some challenges and open questions highlighted include extreme low-resource parallel datasets, lack of monolingual data, low domain diversity, rich morphology, distant paired languages, noisy text environments, code-switching, lack of orthographic normalization, and dialectal variety.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " Why is it not possible to train a reliable pre-trained language model for ILA?", "answer": " It is not possible to train a reliable pre-trained language model for ILA because the amount of monolingual data available is not enough.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " Which language was mentioned as an exception with a large enough monolingual dataset to train a BERT-like model?", "answer": " Quechua was mentioned as an exception with a large enough monolingual dataset to train a BERT-like model.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is one of the major problems recognized during the AmericasNLP ST?", "answer": " Low domain diversity in the scarce parallel datasets is recognized as a major problem during the AmericasNLP ST.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is an example of a phenomenon strongly present in ILA related to the bilingualism among the communities?", "answer": " Code-switching is a phenomenon strongly present in ILA due to the bilingualism among their communities.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " How do monolingual texts, if they exist, tend to be found in relation to ILA?", "answer": " Monolingual texts, if they exist, are found in social media environments that often use a non-canonical writing.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is a challenge faced in the usage of ILA related to orthographic standards?", "answer": " One challenge faced in the usage of ILA is having a lack of unified orthographic standard, leading to difficulties in matching linguistic suggestions with day-by-day writing.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is notable about the linguistic richness of indigenous languages mentioned in the text?", "answer": " The linguistic richness of indigenous languages includes strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is mentioned as a resource that had important improvements in the AmericasNLP ST using orthographic normalizers?", "answer": " The winner of the AmericasNLP ST got important improvements using orthographic normalizers developed specifically for each American language.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}, {"question": " What is the most prominent dataset available for ILA according to the text?", "answer": " The most prominent dataset available for ILA is the Inuktitut\u2013English parallel data.", "ref_chunk": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}], "doc_text": "et al., 2020d), but these methods are limited to lan- guages for which such models are available. This is not possible for the ILA, as the amount of mono- lingual data is not enough to train a reliable pre- trained language model3. 3 Challenges and open questions In an overview of the datasets and recent studies of MT for the ILA, we found the following main issues to be handled. 2For a detailed overview of automatic metrics for MT we refer the interested reader to specialized reviews (Han, 2016; Celikyilmaz et al., 2020; Chatzikoumi, 2020). 3One exception to this is Quechua, that has a large enough monolingual dataset to train a BERT like model (Zevallos et al., 2022) Extreme low-resource parallel datasets Even with the recent advances, the resources available to train MT systems are extremely scarce, hav- ing training set between 4k and 20k sentences (see \u00a74), with notable exceptions for Inuktitut, Guarani and Quechua (Joanis et al., 2020; Ortega et al., 2020a). Lack of monolingual data Most of these lan- guages are mostly used in spoken form. In re- cent years, with the advancement and democra- tization of mobile technologies, indigenous lan- guages have seen a slight increase in massaging systems and private spheres (Rosales et al.). How- ever, the usage of these languages on the internet is rather limited. Even Wikipedia has a limited amount of these languages (Mager et al., 2018b). Low domain diversity . As most parallel datasets are scarce, they are restricted to a small number of domains, making it challenging to adapt it, or try to aim for general translation mod- els. This has been recognized as a major problem during the AmericasNLP ST (Mager et al., 2021). Rich morphology An important number of these languages are morphological highly rich. In many cases, we find polysynthetic, with or highly agglutinative languages (Kann et al., 2018) or even fusional phenomenon (Mager et al., 2020). Distant paired language The most common languages that we find that ILA is translated into are Spanish, English, and Portuguese. However, these languages are distantly related to the ILA, and have completely different linguistically phe- nomenons (Campbell, 2000; Romero et al., 2016). Noisy text environments Monolingual texts, if exist, are found in social media that often use a non-canonical witting (Rosales et al.). Code-Swithing This phenomenon is strongly present in ILA, as all of these languages are mi- nority languages in their own countries. The bilingualism among their communities is strong (and CS is a common phenomenon in this setup (\u00c7etino\u02d8glu, 2017)). The final result of this phe- nomenon is the inclusion of code-switching on a common base (Mager et al., 2019) in their lan- guage. Lack of orthographic normalization The us- age of ILA faces the problem of having a unified orthographic standard. This is not always possi- ble, as the suggestions of linguists and official en- tities do not always match the day-by-day writ- ing of the speakers. Moreover, in some cases, special symbols present in the orthographic stan- dards are not accessible in English or Spanish key- board and need to be replaced with other symbols. The winner of the AmericasNLP ST got important improvements using orthographic normalizers de- veloped specifically for each American language (V\u00e1zquez et al., 2021). Dialectal variety The indigenous languages have a strong dialectal variety, making it hard for native speakers to understand even speakers from neighboring villages. The linguistic richness of entire regions is so diverse that even a single state like the Mexican Oaxaca could correspond to the diversity in the whole Europe (McQuown, 1955). 4 Available MT datasets for ILA The parallel datasets available for MT have been increasing during the last years. At this moment, we can show in two folds the development of these resources: as shown in table 2 work on specific language has emerged; but also broader datasets have started to cover the ILA (see table 1). Language-specific corpus collection work has been done for many languages, where parallel corpus has been the main component. In re- cent time we have seen Cherokee\u2013English (OPUS) (Zhang et al., 2020c), Wixarika\u2013Spanish (Mager et al., 2018a), Shipio\u2013Konibo (Feldman and Coto- Solano, 2020), and others (see table 2). The most prominent of these datasets has been the Inuktitut\u2013 English parallel data. The last version of this dataset corpora (Joanis et al., 2020) is has medium size with 1,450,094 sentences. Previous versions of this corpus are (Martin et al., 2003). This data set was used for the WMT 2020 Shared Task on Unsupervised, and Low Resourced MT (Barrault et al., 2020). For wide-spoken languages like Guarani, it is even possible to collect a web crawled dataset, including news articles and social media parallel aligned data (Chiruzzo et al., 2020; G\u00f3ngora et al., 2021) This dataset also includes monolingual data. This is possible as Guaran\u00ed is one of the most spo- ken indigenous languages of the continent. In contrast to the language-specific datasets, we find broader approaches (see table 1). The broadest multilingual dataset, which contains the Dataset Paired-languages Authors Aymara, Ash\u00e1ninka, Bribri, Guaran\u00ed, Nahuatl, Otom\u00ed, Quechua, Rar\u00e1muri, Shipibo-Konibo, Wixarika Ch\u2019ol, Maya, Mazatec, Mixtec, Nahu- atl and Otomi OPUS * New testament Bible * AmericasNLI CPML (Ebrahimi et al., 2022) (Sierra Mart\u00ednez et al., 2020) (Tiedemann, 2016) (McCarthy et al., 2020) Table 1: Parallel dataset collections that contain one or more indigenous languages of the Americas Language Paried-language ISO Family Sentences Domain Authors Ash\u00e1ninka Bribri Spanish Spanish Guarani Spanish Guarani Spanish Guarani Spanish Guarani Nahuatl Spanish Spanish Otom\u00ed Spanish Rar\u00e1muri Spanish Shipibo-Konibo Spanish Wixarika Cherokee Inuktitut Ayuuk Spanish English English Spanish Mazatec Mixtec Spanish Spanish cni bzd Arawak Chibchan 3883 5923 gn Tupi-Guarani gn Tupi-Guarani 14,531 gn Tupi-Guarani 14,792 gn Tupi-Guarani nah Uto-Aztecan 30855 16145 oto Oto-Manguean 4889 tar Uto-Aztecan 14721 shp Panoan 14592 hch Uto-Aztecan Uto-Aztecan chr Eskimo\u2013Aleut 1,450,094 iku 7553 mir Mixe\u2013Zoque 8966 Many Oto-Manguean Many Oto-Manguean 9799 13235 News, Blogs News, Blogs News, So- cial Media 8 Domains Diverse Books Diverse Books Dictionary Examples Educational, Religious Literature OPUS Legislative"}