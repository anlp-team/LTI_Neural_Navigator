{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_Jais_and_Jais-chat:_Arabic-Centric_Foundation_and_Instruction-Tuned_Open_Generative_Large_Language_Models_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What models struggle to generate meaningful Arabic text according to the text?", "answer": " Models that have not undergone instruction-following fine-tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " Which models produce subpar Arabic text with average scores lower than 1 (out of 10) when evaluated against Jais-chat?", "answer": " BLOOMz and LLaMA2.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " How many models are focused on for comparison in the text?", "answer": " 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B).", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " What is the maximum possible total score a model can achieve in the evaluations discussed?", "answer": " 4,000.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " Which models outperform Jais-chat (13B) according to the text?", "answer": " ChatGPT and Claude.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " In a breakdown by question types, for which types of questions is Jais-chat competitive with ChatGPT and Claude?", "answer": " Common-sense, knowledge-based, writing-related, and generic questions.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " What measures were taken to ensure the safety of Jais-chat during interaction?", "answer": " Safety measures were incorporated during instruction-tuning and practical safety measures were implemented during application development.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " How many risk areas are identified during instruction-tuning to ensure the content generated by Jais-chat is safe?", "answer": " 5 risk areas.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " What are some of the principles imparted to Jais-chat during instruction-tuning to ensure safety?", "answer": " Refrain from generating language that promotes discrimination, uphold privacy standards, exercise caution in disseminating accurate information, reject engagement in any form of malicious use, and counteract emotional manipulation.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}, {"question": " What measure was taken to teach Jais-chat to avoid engaging in discussions on sensitive topics like religion and politics?", "answer": " Data was crawled from various Arabic websites and the DoNotAnswer dataset was integrated.", "ref_chunk": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}], "doc_text": "at random, and we prompt GPT-4 as follows: 41https://lmsys.org/blog/2023-03-30-vicuna/ 42https://www.anthropic.com/index/introducing-claude 18 You are a helpful and precise assistant for checking the quality of two Arabic assistants. Suppose the user only speaks Arabic, please evaluate both answers with your justification, and provide an integer score ranging from 0 to 10 after your justifications. When evaluating the answers, you should consider the helpfulness, relevance, accuracy, and level of detail of the answers. The score for answer 1 should be wrapped by <score1> and </score1>, and the score for answer 2 should be wrapped by <score2> and </score2>. Results First, we find that certain models struggle to generate meaningful Arabic text according to the given instructions. This observation applies particularly to models that have not undergone instruction-following fine- tuning, namely BLOOM, AraT5, AraT5-v2 and AraBART. Additionally, some models produce subpar Arabic text, with average scores lower than 1 (out of 10) when evaluated against Jais-chat (13B) \u2014 these models include BLOOMz and LLaMA2. While BLOOMz is competitive in downstream task evaluation (see Table 9), it is unable to follow Arabic instructions, despite being pretrained using 73G of Arabic text [SFA+23]. With these observations, we focus on comparing the top 6 models: ChatGPT, Claude, BXBLOOM, BXLLaMA, Jais-chat (6.7B), and Jais-chat (13B). As there are six models in total, each one is compared against the other five models, resulting in 400 scores (80 questions \u00d7 5 pairs) for every individual model. Since each score ranges from 0 to 10, summing up these scores for a model brings the maximum possible total score to 4,000. The overall comparative results are shown in Figure 5. While both ChatGPT (175B) and Claude (52B) outperform Jais-chat (13B), it is important to note that (i) they are 4\u201313 times larger, and (ii) the difference in scores between our Jais-chat (13B) and these larger models is relatively modest, at around 400 points. When focusing solely on certain types of tasks, including common-sense, knowledge-based, writing-related, and generic inquiries, the disparity between Jais-chat and ChatGPT/ Claude diminishes. Jais-chat is only 35 scores behind Claude and 114 scores behind ChatGPT, out of a total of 2,000, as illustrated in Figure 6. 500 1000 JAIS-chat (6.7B) 0 2000 ChatGPT 2500 3500 JAIS-chat (13B) 4000Total Score BXLLaMA (13B) 366035643167240219991488 BXBLOOM (7B) 3000 1500 Claude Figure 5: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions. The minimum and the maximum possible scores are 0 and 4,000, respectively. 500 JAIS-chat (13B) JAIS-chat (6.7B) Claude 250 1750 ChatGPT 1000 18551776174114201165892 2000Total Score 1500 0 BXLLaMA (13B) 750 BXBLOOM (7B) 1250 Figure 6: GPT-4 evaluation results for Jais-chat compared to open- and closed-source models on Arabic open- ended questions, with a focus on common-sense, knowledge-based, writing-related, and generic questions. The minimum and the maximum possible scores are 0 and 2,000, respectively. 19 JAIS-chat (13B) JAIS-chat (13B) Claude Claude math-and-coding JAIS-chat (6.7B) JAIS-chat (6.7B) generic 10Score 10Score 10Score 10Score 10 10 10 10 ChatGPT ChatGPT common-sense 0 0 0 0 0 0 0 0 BXLLaMA (13B) BXLLaMA (13B) counterfactual fermi roleplay knowledge BXBLOOM (7B) BXBLOOM (7B) writing 5 5 5 5 5 5 5 5 Figure 7: GPT-4 evaluation results breakdown by question types (the top-6 models only). Notably, Jais-chat (13B) is competitive to ChatGPT and Claude for common-sense, knowledge-based, writing-related, and generic questions (the left subfigures). However, it performs worse for counterfactual, roleplay, and Fermi questions, and is substantially worse at math and coding questions. Figure 7 shows a breakdown of the scores across various tasks. For the categories in Figure 6 including common-sense, knowledge-based, writing-related, and generic inquiries, Jais-chat performs generally better. This is particularly true for writing, where Jais-chat is almost on par with ChatGPT and Claude. In other task categories, including counterfactual, Fermi, roleplay, and math-and-coding, Jais-chat is worse than ChatGPT and Claude. This is expected, since these categories require a higher degree of reasoning, and the smaller size of the Jais-chat models puts them at a disadvantage. 6 Safety We used several strategies and precautionary measures to make Jais-chat safer to interact with and to minimize potential risks. These precautionary measures were incorporated at various stages of the model development. During the instruction-tuning process, we encoded safety measures into Jais-chat. Moreover, towards de- veloping an interactive application based on Jais-chat, we implemented several practical and simple safety measures, which we describe here with the aim of providing developers examples of guardrails to be considered during the application development for end-users. 20 6.1 Safety via Instruction-Tuning To ensure that Jais-chat has in-built safeguards on the content it generates, we have focused on this aspect during instruction-tuning. This involves avoiding the generation of content in the five risk areas identified by [WMR+21]. Through the process of instruction-tuning, we impart the following principles to Jais: (1) refrain from generating language that promotes discrimination, exclusion, or toxicity, regardless of user request or pref- erence; (2) uphold privacy standards by preventing the leakage of private or sensitive information; (3) exercise caution in disseminating accurate information and responding thoughtfully to queries that could potentially lead to material harm, such as those related to fields like medicine or law; (4) reject engagement in any form of ma- licious use, including inquiries about unethical or illegal activities; and (5) counteract emotional manipulation by transparently indicating that the model is a chatbot and not a human, particularly when there is a discernible overreliance on its responses. Furthermore, we also add some examples that aim to teach Jais-chat to avoid engaging in discussions on sensitive topics, particularly such concerning certain aspects of religion and politics. We crawled data from various Arabic websites, encompassing a wide spectrum of materials related to re- ligion and politics, and amassed approximately 1,000 instances in Arabic. Given the constraints of available Arabic resources, we expanded our dataset by incorporating content in English. To this end, we integrated the DoNotAnswer dataset [WLH+23], which comprises around 6,000 questions designed to potentially pro- voke harmful output from language models, along with corresponding harmless responses. Subsequently, we"}