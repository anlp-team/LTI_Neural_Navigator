{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_3D_Semantic_Segmentation_in_the_Wild:_Learning_Generalized_Models_for_Adverse-Condition_Point_Clouds_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of the ablation study mentioned in the text?,answer: To examine how different PointDR designs contribute to the overall generalization performance.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " What are the three models reported in Table 3 and how are they trained?,answer: 1) Baseline trained with Lce, 2) PointDR-CT trained with Lce and Lct without using memory bank B, 3) Complete PointDR trained with Lce, Lct, and memory bank B.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " Why does the PointDR-CT model achieve better performance than the Baseline model?,answer: Because learning perturbation-invariance helps for universal LiDAR segmentation of all-weather conditions.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " How does introducing the momentum-updated memory bank B improve segmentation performance?,answer: It serves as class prototypes that help optimize the segmentation network, leading to more robust representations for better performance over adverse weather point clouds.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " What is the focus of the Domain Adaptation study discussed in the text?,answer: To analyze the adaptability of UDA methods from normal to adverse weather conditions for 3D LiDAR segmentation.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " Which UDA method showed effectiveness in mitigating domain discrepancies under Dense-fog and Light-fog conditions?,answer: CoSMix.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " Why do the UDA methods achieve limited performance improvements under rain and snow conditions?,answer: Because rain and snow introduce large deformations on object surfaces or much noise, making adaptation from normal to adverse weather more challenging.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " What is the significance of the research findings regarding the UDA methods in the text?,answer: They indicate the large room for improvement in constructed benchmarks for 3D LiDAR segmentation in adverse weather conditions.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " What is the purpose of training separate models for each weather-specific subset of SemanticSTF in the study?,answer: To evaluate the trained model on the specific weather condition it has been trained for.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}, {"question": " How do different 3DSS network architectures generalize when trained with normal-weather point clouds and evaluated over SemanticSTF?,answer: The study shows how various 3DSS networks perform in 3D LiDAR segmentation when pre-trained with normal-weather data and tested on SemanticSTF.", "ref_chunk": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}], "doc_text": "tations, it works effectively across different adverse weather conditions. We also provide qualitative results, please refer to the appendix for details. Ablation study. We study different PointDR designs to examine how they contribute to the overall generalization performance. As Table 3 shows, we report three models over the benchmark \u201cSemanticKITTI \u2192 SemanticSTF\u201d: 1) Baseline that is trained with Lce. 2) PointDR-CT that is jointly trained with Lce and Lct without using the mem- ory bank B. 3) The complete PointDR that is trained with Lce, Lct and the memory bank B. We evaluate the three models over the validation set of SemanticSTF and Table 3 7 shows experimental results. We can see that the Base- line performs poorly at 24.4% due to clear domain dis- crepancy between point clouds of normal weather and ad- verse weather. Leveraging the proposed contrastive loss, Lct achieves clearly better performance at 27.4%, indicat- ing that learning perturbation-invariance is helpful for uni- versal LiDAR segmentation of all-weather conditions. On top of that, introducing the momentum-updated memory bank B further improves the segmentation performance at 28.6%. This is because the feature embeddings in B serve as the class prototypes which help the optimization of the segmentation network, finally leading to more robust repre- sentations of 3DSS that perform better over adverse weather point clouds. 5.2. Domain Adaptation We also study SemanticSTF over a domain adaptive point cloud segmentation benchmark SemanticKITTI \u2192 SemanticSTF. Specifically, we select four representative UDA methods including ADDA [46], entropy minimiza- tion (Ent-Min) [47], self-training [65], and CoSMix [38] for adaptation from the source SemanticKITTI [2] to- ward the target SemanticSTF. Following the state-of-the- art [38, 50, 51] on synthetic-to-real adaptation, we adopt MinkowskiNet [7] as the segmentation backbone for all compared methods. Table 4 shows experimental results over the validation set of SemanticSTF. We can see that all UDA methods outperform the Source-only consistently un- der the normal-to-adverse adaptation setup. At the other end, the performance gains are still quite limited, showing the great improvement space along domain adaptive 3DSS from normal to adverse weather conditions. In addition, we examined the adaptability of the four UDA methods in relation to each individual adverse weather condition. Specifically, we trained each of the four methods for adaptation from SemanticKITTI to SemanticSTF data for each adverse weather condition. Table 5 shows the ex- perimental results over the validation set of SemanticSTF. We can see all four methods outperform the Source-only method under Dense-fog and Light-fog, demonstrating their effectiveness in mitigating domain discrepancies. However, for rain and Snow, only CoSMix achieved marginal perfor- mance gains while the other three UDA methods achieved limited performance improvements. We conjecture that snow and rain introduce large deformations on object sur- faces or much noise, making adaptation from normal to ad- verse weather more challenging. CoSMix works in the in- put space by directly mixing source and target points, allow- ing it to perform better under heavy snow and rain which have larger domain gaps. However, all methods achieved relatively low segmentation performance, indicating the sig- nificance of our research and the large room for improve- ment in our constructed benchmarks. Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t e l o p . f a r t mIoU Oracle 89.4 42.1 0.0 59.9 61.2 69.6 39.0 0.0 82.2 21.5 58.2 45.6 86.1 63.6 80.2 52.0 77.6 50.1 61.7 54.7 64.8 Source-only 65.6 ADDA [46] Ent-Min [47] 69.2 Self-training [65] 71.5 65.0 CoSMix [38] 0.0 0.0 0.0 0.0 1.7 13.8 0.0 21.0 0.0 10.1 31.0 10.3 33.1 22.1 25.2 1.8 1.3 5.3 7.4 7.7 5.0 2.8 2.8 5.9 33.2 2.1 1.3 2.6 1.3 0.0 34.0 7.5 0.0 62.7 16.7 64.7 35.4 1.2 65.9 35.7 2.6 0.0 36.6 65.1 0.0 6.5 64.7 11.5 31.1 0.0 0.0 0.0 0.0 0.0 0.9 66.7 36.2 53.9 31.3 44.3 24.0 14.2 66.5 41.8 57.2 32.6 42.2 23.3 26.4 72.5 42.8 52.4 32.5 44.7 24.7 21.1 67.8 41.3 51.7 32.9 42.9 25.1 25.0 62.5 37.8 44.6 30.5 41.1 30.9 28.6 24.3 26.3 27.2 27.6 28.4 Table 4. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation. SemanticKITTI serves as the source domain and the entire SemanticSTF including all four weather conditions serves as the target domain. Method Dense-fog Light-fog Rain Snow 3DSS Model D-fog L-fog Rain Snow All Source-Only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 26.9 31.5 31.4 31.8 31.6 25.2 27.9 28.6 29.3 30.3 27.7 27.4 30.3 27.9 33.1 23.5 23.4 24.9 25.1 32.9 RandLA-Net [19] SalsaNext [9] SPVCNN [43] SPVNAS [43] Cylinder3D [64] 26.5 16.0 30.4 25.5 14.8 26.0 9.6 22.8 18.3 7.4 25.1 7.8 21.7 17.0 5.7 22.7 3.5 18.3 13.0 4.0 25.3 9.1 22.4 18.0 7.3 Table 5. Comparison of state-of-the-art domain adaptation meth- ods on SemanticKITTI\u2192SemanticSTF adaptation for individual adverse weather conditions. We train a separate model for each weather-specific subset of SemanticSTF and evaluate the trained model on the weather condition it has been trained for. Table 6. Performance of state-of-the-art 3DSS models that are pre-trained over SemanticKITTI and tested on validation set of SemanticSTF for individual weather conditions and jointly for all weather conditions. 5.3. Network Models vs All-Weather 3DSS We also study how different 3DSS network architec- tures generalize when they are trained with normal-weather point clouds and evaluated over SemanticSTF. Specifically, we select five representative 3DSS networks [9, 19, 43, 64] that have been widely adopted in 3D LiDAR segmen- tation studies. In the experiments, each selected net- work is first pre-trained with SemanticKITTI [2] and then"}