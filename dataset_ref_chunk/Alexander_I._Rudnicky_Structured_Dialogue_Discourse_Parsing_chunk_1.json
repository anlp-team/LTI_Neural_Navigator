{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Alexander_I._Rudnicky_Structured_Dialogue_Discourse_Parsing_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the goal of dialogue discourse parsing?", "answer": " To uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " How does previous work approach dialogue discourse parsing?", "answer": " Previous work either treats the task as a series of independent multiple-choice problems or restricts the encoding to only local interaction.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What are the two perspectives from which the proposed method improves upon previous work?", "answer": " The proposed method improves upon previous work from the perspectives of encoding and decoding.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What method is proposed for encoding in the dialogue discourse parsing?", "answer": " Structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What method is proposed for decoding in the dialogue discourse parsing?", "answer": " Structured inference using the modified Chiu-Liu-Edmonds algorithm.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What does the proposed method in the text not rely on to improve its robustness?", "answer": " The proposed method does not rely on hand-crafted features to improve its robustness.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What is the purpose of a dialogue discourse parser?", "answer": " The purpose of a dialogue discourse parser is to predict all the links and relations in a conversation accurately.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What key observation led to the development of the proposed dialogue discourse parsing method?", "answer": " Adding a dummy utterance at the beginning of the dialogue closely resembles a labeled multi-root non-projective spanning tree.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What are the essential elements of the proposed method for dialogue discourse parsing?", "answer": " The essential elements include the structured parameterization of the adjacency matrix, the directed version of matrix-tree theorem, and the modified directed spanning tree inference algorithm.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}, {"question": " What are the contributions of the proposed method for dialogue discourse parsing?", "answer": " The contributions include introducing structural inductive biases for encoding and decoding, jointly predicting discourse links and relations, and proposing a padding method for batchwise variable-length determinant calculation.", "ref_chunk": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}], "doc_text": "3 2 0 2 n u J 6 2 ] L C . s c [ 1 v 3 0 1 5 1 . 6 0 3 2 : v i X r a Structured Dialogue Discourse Parsing Ta-Chung Chi Language Technologies Institute Carnegie Mellon University tachungc@andrew.cmu.edu Alexander I. Rudnicky Language Technologies Institute Carnegie Mellon University air@cs.cmu.edu Abstract Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conver- sation by finding all the discourse links and corresponding relations. Previous work ei- ther treats this task as a series of independent multiple-choice problems, in which the link ex- istence and relations are decoded separately, or the encoding is restricted to only local in- teraction, ignoring the holistic structural in- formation. In contrast, we propose a princi- pled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we per- form structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of- the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores). 1 1 Introduction Discourse parsing is a series of tasks that consist of elementary discourse unit (EDU) segmentation, relation directionality classification (optional), and relation type classification between EDUs (Jurafsky and Martin, 2021). It serves as the first step of many downstream applications (Meyer and Popescu- Belis, 2012; Jansen et al., 2014; Narasimhan and Barzilay, 2015; Bhatia et al., 2015; Ji et al., 2016; Asher et al., 2016; Ji and Smith, 2017; Li et al., 2020a), and it can be categorized into three major 1Code released at https://github.com/ chijames/structured_dialogue_discourse_ parsing. mmatrtajova: and sheep for ore?ElaborationContinuationQ_Elab trtajova: okay Ash: yes for wood Dummy Root trtajova: anyone will trad wheat or sheep? Ash: okQA_pair J: nopes trtajova: wood for wheat? Figure 1: This is an example dialogue session. The ulti- mate goal of a dialogue discourse parser is to predict all the links (arrows) and relations (color of arrows) shown in this figure. Note that the Q_Elab arrow (dashed) can cross the QA_pair one, making it non-projective. discourse formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008) styles. Considering that SDRT-style formalism is used to label the STAC (Asher et al., 2016) and Molweni (Li et al., 2020a) dialogue corpora and the increasing im- portance of dialogue discourse parsers trained on them (Ouyang et al., 2021; Feng et al., 2021; Jia et al., 2020; Chen and Yang, 2021), we focus on de- signing an SDRT-style dialogue discourse parser us- ing the two corpora in this work. Figure 1 presents an example of a dialogue session in the STAC cor- pus (Asher et al., 2016) annotated with its discourse structure. The annotation is often encoded in two components: links and relations. The goal of a dia- logue discourse parser is to extract them accurately at the same time. One straightforward solution to this problem is to transform the parsing structure into a series of local pairwise link prediction problems. In other words, the model is expected to compute some local potentials between each pair of utterances, Models Encoding Decoding Link & Relation Prediction Use Feature MST (2015) ILP (2016) Deep-Seq. (2019) Struct-Aware (2021) Hierarchical (2021) This Work local, edge-wise local, edge-wise global, two-staged global, fully-connected hierarchical global, structured partial MST ILP indp. multiple choice indp. multiple choice indp. multiple choice full MST separate separate separate separate separate joint Y Y Y Y N N Table 1: This is the comparison between different dialogue discourse parsers. Our method is designed with structured encoding and decoding processes. Furthermore, the links and relations are learned and predicted jointly. Finally, our method does not rely on human-designed features, hence enjoys better robustness. and predict the relation type of that link if it ex- ists. However, this formulation does not take the global structural information into account, leading to inferior parsing performance. In contrast to previous work, our core obser- vation is that by adding a dummy utterance at the beginning of the dialogue, the overall struc- ture closely resembles a labeled multi-root non- projective spanning tree. In light of this observa- tion, we propose a principled dialogue discoursing parser that encodes structural inductive biases dur- ing training and inference. (2016). All the utterances, links, and relations con- stitute a graph G(V, E, R), where V represents the set of utterances, E represents the links connecting them, and R represents the edge labels. The goal of a discourse parser is to predict E and R given V . There are five existing dialogue discourse parsers to the best of our knowledge (Afantenos et al., 2015; Perret et al., 2016; Shi and Huang, 2019; Wang et al., 2021; Liu and Chen, 2021). We com- pare them against each other in detail in the follow- ing subsections and provide a summary in Table 1. The essential elements of our method are the novel structured parameterization of the adjacency matrix, the directed version of matrix-tree theo- rem (Tutte, 1984; Koo et al., 2007), and the mod- ified directed spanning tree inference algorithm. To the best of our knowledge, this is the first time that the labeled multi-root non-projective spanning tree is applied to the analysis of dialogue discourse structure. In summary, the contributions of this paper are: We propose a principled method for the dia- logue discourse parsing task, where structural inductive biases for both encoding and decod- ing processes are introduced. We jointly predict discourse links and rela- tions in a unified space. We propose a padding method that allows batchwise variable-length determinant calcu- lation. 2.1"}