{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_User-Centric_Evaluation_of_OCR_Systems_for_Kwak\u2019wala_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What role does the transcriber group play in how fast the user completes tasks?", "answer": " The transcriber group plays a role in how fast the user completes tasks.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " How does having some form of OCR help reduce transcription time?", "answer": " Having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50%.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " According to the results, does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool?", "answer": " Yes, using post-correction further reduces transcription time compared to using an off-the-shelf OCR tool.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " What is the utility of using post-correction in the transcription pipeline?", "answer": " Using post-correction reduces manual correction time by 21%.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " How does prior familiarity with Kwak\u2019wala affect transcription time?", "answer": " Having prior familiarity with Kwak\u2019wala language reduces transcription time.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " What percentage of participants perceived that correcting an OCR output was faster than typing the transcription from scratch?", "answer": " 100% of the participants perceived that correcting an OCR output was faster.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " What did the majority of transcribers in the user study prefer in terms of task setup?", "answer": " The majority of transcribers preferred correcting OCR outputs over typing from scratch.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " Why did the majority of transcribers prefer correcting OCR outputs?", "answer": " The majority preferred correcting OCR outputs because it was faster and required less mental effort.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " What is one challenge mentioned by a transcriber when annotating images?", "answer": " One transcriber mentioned that differentiating between l and \u0142 was difficult.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}, {"question": " What did some transcribers mention as easier than typing from scratch?", "answer": " Several transcribers described correction as easier than typing from scratch.", "ref_chunk": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}], "doc_text": "the transcriber group (i.e., whether the participant has prior knowl- edge of Kwak\u2019wala) plays a role in how fast the user completes tasks. Does having some form of OCR help reduce transcription time? In Table 1, we present tran- scription time estimates from the LME model com- paring two settings: (1) the baseline setup which does not use any OCR and the user types the tran- scription from scratch, and (2) having some form of OCR before the transcription process which the user can correct to produce error-free text (either Ocular or post-correction). As is evident from the results, having some form of OCR greatly improves transcription speed, reducing the time estimate by over 50% (from 61.65 to 28.21 minutes) and con- sequently, reducing the manual effort needed to produce an accurate machine-readable version of the documents. Does post-correction help reduce transcription time beyond using an off-the-shelf OCR tool? From the previous results, it is evident that using OCR is bene\ufb01cial in reducing manual transcrip- tion time. We also evaluate whether using the post-correction model is useful or just using an off-the-shelf tool like Ocular is suf\ufb01ciently useful for transcribers. The LME model estimates for this comparison are in Table 2. We see that using post- correction, as proposed in Rijhwani et al. (2021), Task Setup Time Est. (min.) p-value Ocular Post-correction 31.67 24.98 2.55e-05 * 0.0121 * Table 2: Per-page transcription time estimates in min- utes from the LME model comparing task setups us- ing an off-the-shelf OCR system (Ocular) with an OCR post-correction method. The time estimate is reduced by 6.69 minutes for a page, indicating the utility of post- correction to downstream users over using Ocular. The p-value is < 0.05, indicating statistical signi\ufb01cance (*). Group Time Est. (min.) p-value Not familiar Familiar 43.60 25.74 8.12e-05 * 0.228 Table 3: Per-page transcription time estimates in min- utes from the LME model comparing transcribers that had prior familiarity with Kwak\u2019wala with those that did not. The time estimate is reduced by 17.86 minutes for a page when the user is familiar with Kwak\u2019wala, indicating that target knowledge language might be use- ful to have in image transcription tasks. The p-value is > 0.05 for the estimate, which indicates that it is not statistically signi\ufb01cant, likely because we only had two users that were familiar with the language. in the transcription pipeline reduces manual cor- rection time by 21%, indicating its utility to the downstream task of manually correcting the text. Does prior familiarity with Kwak\u2019wala and the Boas script affect transcription time? Beyond our primary analysis of the effect of using OCR, we also try to evaluate the extent to which the user\u2019s knowledge of the Kwak\u2019wala language affects the speed of transcription. Table 3 demonstrates this comparison with results across all three task se- tups. The estimates show that this factor does play a role with the LME model estimate with a 40% reduction in transcription time for the group famil- iar with Kwak\u2019wala. However, the p-value of this estimate is > 0.05, indicating that the result is not statistically signi\ufb01cant \u2013 this is likely because only two transcribers in the user study had prior knowl- edge of the language and more data is needed to draw a statistically signi\ufb01cant conclusion. 3.7 Subjective Feedback After participants completed the transcription tasks, we asked them to \ufb01ll out a short survey to de- scribe their experience with the task. Note that, to avoid any bias, the participants were not told which OCR setup (Ocular or post-correction) was used for each task. Therefore, the survey focused on understanding whether users observed any dif- ferences between typing from scratch or correcting transcriptions, but the questions did not distinguish between the two OCR-based setups. The full list of questions contained in the survey is in Section A.2. We asked which of the setups led to faster com- pletion of the tasks, and 100% of the participants perceived that correcting an OCR output was faster than typing the transcription from scratch. Some participants also provided feedback: \u201cCorrecting is faster, as there is much less typing involved which requires most of the time\u201d (user7, from Upwork, not familiar with Kwak\u2019wala) \u201cCorrecting felt far more ef\ufb01cient!\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) However, even though it was slower, two out of the nine participants preferred typing out the text without the aid of an OCR output: \u201cI preferred typing the text from scratch, as searching for any editable text is dif\ufb01- cult. You need more effort for editing.\u201d (user8, from Upwork, not familiar with Kwak\u2019wala) However, the remaining seven transcribers pro- vided strong feedback that correcting OCR outputs was the preferable task setup, for various reasons: \u201cI vastly preferred correcting OCR out- puts. It was so much faster, and also required less investment of attention.\u201d (user2, linguistic researcher, familiar with Kwak\u2019wala) \u201cI preferred correcting text - it\u2019s much faster. I can spend more mental energy making sure the characters are correct rather than wasting time on transcribing trivially-easy letters.\u201d (user5, computer science student, not familiar with Kwak\u2019wala) \u201cI prefer correcting text because typing from scratch is somehow tricky to follow line by line.\u201d (user9, from Upwork, not familiar with Kwak\u2019wala) Overall, transcribers participating in the user study identi\ufb01ed a reduction in time spent when the OCR outputs were utilized and the majority preferred the task setup not only because of the speed improvement but also because the OCR out- puts allowed them to zoom in and \ufb01x speci\ufb01c errors rather than spending time on the entire image. Additionally, we asked participants if any tasks seemed to be easier or more dif\ufb01cult than others. While several described correction as easier than typing from scratch, some transcribers focused on interesting language-speci\ufb01c and document- speci\ufb01c challenges: \u201cA few alphabets were dif\ufb01cult to anno- tate from the images. For example, it was dif\ufb01cult to differentiate between l and \u0142.\u201d (user6, from Upwork, not familiar with Kwak\u2019wala) \u201cimage text was with small fonts.\u201d (user4, computer science student, not familiar with"}