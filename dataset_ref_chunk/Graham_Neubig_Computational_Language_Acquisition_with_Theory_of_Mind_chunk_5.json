{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Computational_Language_Acquisition_with_Theory_of_Mind_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What was the purpose of training a model without any Theory of Mind (ToM) component?", "answer": " For comparison.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " How were the hard distractors chosen for the study?", "answer": " By the hybrid similarity between visual and semantic (CLIP) features.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What did the study find in terms of performance improvements when speaker models were trained to rerank utterances solely by ToM listener score?", "answer": " Significant performance improvements in accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What did models that rerank utterances using a combined speaker-ToM score generally fail to outperform?", "answer": " Models that do not use their ToM listener in training.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " In what scenarios did the usage of a highly-weighted ToM listener lead to significant fluency gains?", "answer": " When training on both easy (15.6% relative increase) and hard (11.6%) distractors.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What was the effect of using normally or highly weighted ToM listeners on the length and complexity of utterances?", "answer": " Longer and more complex utterances were observed.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " How did the usage of a highly influential ToM listener during the training process impact performance and fluency gains?", "answer": " It led to significant performance and fluency gains.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What models represent the upper bound of how good a speaker\u2019s listener model can be?", "answer": " RSA models.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What role does the text suggest Theory of Mind (ToM) plays in simulated language acquisition?", "answer": " An important role, similarly to human language acquisition.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}, {"question": " What improvements were generally found in language quality in models trained on more difficult distractors?", "answer": " Significant improvements, particularly in fluency score where gains ranged between 25% to 46%.", "ref_chunk": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}], "doc_text": "model equipped with a ToM listener that it does not give any weight to. Additionally, we train a model without any ToM component for comparison. We do this for both easy and hard distractors, where the hard distractors were those that were chosen by the hybrid similarity between visual and semantic (CLIP) features outlined in 5. Finally, we give the listener the ground-truth captions over the test set to compute gold-standard metrics of accuracy and \ufb02uency. We \ufb01nd signi\ufb01cant performance improvements in Table 1 when speaker models are trained to rerank utterances solely by ToM listener score. Such \u201chigh-weight ToM\u201d speaker models achieve accuracy gains of 3.0% and 4.6% on easy and hard distractors, respectively. This suggests that the inclusion of a suf\ufb01ciently in\ufb02uential ToM reranker during the speaker training process improves speaker per- formance, although the relative gains appear to be much higher when training on easy distractors. 7 0.38 0.45 1.00 0.47 0.49 0.50 0.49 0.49 0.52 0.50 0.49 Published as a conference paper at ICLR 2023 Table 2: Performance and language features of speakers trained on various distractors. We only show the most performant variants of Caption and Hybrid similarity, with the others shown in A.1. Model Distractors Performance Acc POS F1 Fluency ADJ ADP NOUN VERB Average Length Base Gold Standard 0.81 0.92 1.50 2.52 0.16 1.00 0.52 1.00 0.41 1.00 0.38 1.00 8.97 10.79 Image Caption Hybrid 0.80 0.86 0.85 2.09 2.01 2.19 0.19 0.19 0.20 0.61 0.62 0.62 0.45 0.49 0.49 0.49 0.48 0.47 10.33 10.04 10.18 However, we \ufb01nd that speaker models that rerank utterances using a combined speaker-ToM score generally fail to outperform models that do not use their ToM listener in training. We also \ufb01nd that the usage of a highly-weighted ToM listener leads to signi\ufb01cant \ufb02uency gains when training on both easy (15.6% relative increase in \ufb02uency score) and hard (11.6%) distractors. We also see longer and more complex utterances when using normally or highly weighted ToM listeners. Additionally, we \ufb01nd limited gains in general captioning ability between baseline and high-weight models, as measured by BLEU score. However, these effects are more subtle, and do not always lead to signi\ufb01cant accuracy gains, suggesting that the main driver of ToM accuracy gains is increased pragmatic ability. We conclude that usage of a highly in\ufb02uential ToM listener during the training process leads to signi\ufb01cant performance and \ufb02uency gains. We are also able to qualitatively observe the improvement in model performance from ToM. As seen in one representative example in Fig. 3, our ToM Speaker is able to identify two elements that clearly distinguish the target image from the distractors (i.e. that there are multiple men who are playing baseball) in a \ufb02uent utterance. Finally, we \ufb01nd that the ToM listener successfully approximates the external listener. Models with learned listeners and RSA models with the pretrained listener perform comparably in accuracy and \ufb02uency. Because the RSA models represent the upper bound of how good a speaker\u2019s listener model can be, this suggests that our learned listeners are very bene\ufb01cial to the speakers. This is also shown through the high ToM accuracies reported, especially in the most performant models, those with high listener weight. These qualitative and quantitative results provide computational evidence that ToM can play an important role in simulated language acquisition, similarly to how it has been hypothesized to play a critical role in human language acquisition. 6.3 EFFECTS OF DISTRACTOR DIFFICULTY As shown in Table 2, we generally \ufb01nd signi\ufb01cant improvements in language quality in models trained on more dif\ufb01cult distractors. The largest gains are those seen in the \ufb02uency score, where dif\ufb01cult distractors achieve gains ranging between 25% to 46%. We also \ufb01nd that models trained on more dif\ufb01cult distractors use more similar vocabulary to the ground-truth captions, as measured by F1 score in the ground-truth captions and utterances produced. This is signi\ufb01cantly higher over adpositions, nouns, and verbs on models trained with more dif\ufb01cult distractors. Finally, all speakers trained on dif\ufb01cult distractors generate more complex utterances compared to the base speaker, with utterances that are at least one word longer on average. This supports our hypothesis that when confronted with increased environmental pressure, the speaker adapts by becoming more precise, \ufb02uent, and complex with its language. These can be seen qualitatively in one representative example in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more \ufb02uent utterances that more precisely describe the image (in this example, correctly identifying an object in the image as a baseball bat, as opposed to an umbrella). We \ufb01nd smaller differences between the language of models trained with various types of hard dis- tractors. Speaker models trained with visually similar distractors achieve the highest \ufb02uency, at 2.094, and form the longest utterances. They also have more precise verb selection, as measured by F1. Speakers trained on distractors that were selected with hybrid or caption similarity, achieved high noun F1 scores of 0.49 compared to 0.41 for the base speaker model, indicating that semanti- cally similar distractors in training may be better for identifying salient nouns. We \ufb01nd that training on more dif\ufb01cult distractors does not consistently improve model performance when evaluating on easier distractors. This suggests some disconnect between a language\u2019s \ufb02uency and its suitability to 8 Published as a conference paper at ICLR 2023 the image referential game environment. However, speakers that train on more semantically simi- lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some bene\ufb01ts to performance from training on certain harder distractors. 7 RELATED WORK Parallels in Human Language Acquisition. The concept of learning language through repeated exposure to referents is a popular model within the psychology community. Smith & Yu (2008) found that infants resolve the uncertainty of determining which referent in a scene a word refers to by statistical learning over word-scene pairings. Yu & Ballard (2007) incorporated a social element into models by considering \u201csocial-cognitive\u201d capacities, such as attention reading, that act as"}