{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/T._Mitamura_Hierarchical_Event_Grounding_chunk_8.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of selecting the threshold \u03c4c for emitting prediction at inference time?", "answer": " The purpose is to select the threshold based on the performance on the dev set.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " How is the performance measured in terms of evaluating the models?", "answer": " The performance is measured using the product of Strict Acc, Macro F1, and Micro F1.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " What does Recall@k (fraction) evaluate in addition to Recall@k?", "answer": " Recall@k (fraction) evaluates partial retrieval in addition to Recall@k.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " What is the distinction between the bi-encoder retrieval performance under Recall@k (fraction) and Recall@k?", "answer": " The bi-encoder retrieval performance under Recall@k (fraction) counts successful retrieval if some (not all) of the gold events are predicted within the top-k retrievals.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " How does the bi-encoder + cross-encoder system performance differ between multilingual and crosslingual tasks?", "answer": " The best-performing bi-encoder + cross-encoder system is reported based on Strict Acc, Macro F1, and Micro F1 for each task.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " What metrics are used to measure the performance of bi-encoder and cross-encoder in Table 5?", "answer": " Strict Acc, Macro F1, and Micro F1 are used to measure the performance in Table 5.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " In Table 6, what is the key difference in performance evaluation between multilingual and crosslingual event linking?", "answer": " Table 6 shows the performance in crosslingual event linking and includes metrics such as Strict Acc, Macro F1, and Micro F1 for each language.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " Based on the given performance numbers, which language has the highest bi-encoder Recall@min in multilingual event linking?", "answer": " English has the highest bi-encoder Recall@min in multilingual event linking.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " Which language has the lowest cross-encoder Macro F1 in crosslingual event linking according to the provided data?", "answer": " Bengali has the lowest cross-encoder Macro F1 in crosslingual event linking.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}, {"question": " How does the recall performance differ in crosslingual event linking for Afrikaans and Vietnamese based on the table data?", "answer": " Afrikaans has a higher recall performance compared to Vietnamese in crosslingual event linking.", "ref_chunk": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}], "doc_text": "k: # retrieved events Figure 6: Crosslingual bi-encoder Recall@k (fraction) on the dev set. Cross-encoder Inference At inference time, we select the threshold \u03c4c for emitting prediction from the set {0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9}, based on the perfor- mance on dev set. In terms of measuring the performance, we use the product of all three metrics, i.e. Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. D Additional Results D.1 Bi-encoder In addition to Recall@k, which counts the retrieval at k as successful if and only if all the gold events are predicted within the top-k retrieval, we propose to also evaluate bi- encoders that measures partial retrieval. In particular, we in- troduce Recall@k (fraction): for a given mention with p gold events, of which q are predicted in the top-k retrievals, its Recall@k (fraction) = q p . Figure 5 and \ufb01gure 6 depict the bi-encoder retrieval per- formance under Recall@k (fraction) on the dev split of multi- and crosslingual tasks, respectively. Compared with the corresponding performance on Recall@k in \ufb01gure 3 and \ufb01gure 4, every model attains a higher score under Recall@k (fraction) while the relative performance gap remains simi- lar. D.2 Per-language results Table 5 and Table 6 display the bi-encoder and cross-encoder performance on each of the languages, on both multi- and crosslingual tasks. We report the best-performing bi-encoder + cross-encoder systems ((c) in multilingual and (d) in crosslingual task) by measuring Strict Acc \u00d7 Macro F1 \u00d7 Micro F1. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Multilingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 86.9 59.5 65.2 73.5 48.4 52.5 55.2 63.0 75.0 44.5 41.2 53.9 48.3 50.6 39.8 64.4 81.3 59.4 57.4 44.6 54.0 56.1 74.7 70.0 43.8 70.2 65.3 44.8 58.8 60.9 48.8 45.2 60.8 66.7 56.2 100.0 71.0 83.3 87.6 43.2 63.8 61.2 71.1 38.2 51.3 77.2 45.5 40.2 51.1 54.8 60.2 35.7 30.7 46.1 30.3 39.7 43.0 49.7 73.6 40.9 50.4 29.7 46.3 59.5 63.7 73.3 62.5 62.5 56.9 34.3 45.2 45.5 34.8 39.7 57.6 57.0 40.8 66.7 53.6 66.7 75.3 41.4 53.1 41.8 80.1 61.2 75.8 84.4 75.1 61.5 75.9 73.6 77.1 50.8 55.7 58.0 46.3 56.1 68.3 66.0 79.3 56.9 73.8 47.3 62.3 78.2 81.5 78.3 66.6 75.5 68.7 49.3 69.5 69.4 58.5 68.5 72.0 67.2 54.7 66.7 66.8 80.9 84.3 66.6 73.5 63.9 78.1 56.1 73.0 81.9 69.5 59.0 69.6 71.4 75.1 50.9 53.2 58.3 45.3 52.1 65.4 64.0 77.9 56.3 70.4 46.2 57.6 73.0 77.5 77.4 68.3 72.9 66.6 49.5 66.0 65.7 56.1 64.5 68.4 67.0 53.8 66.7 65.4 76.5 82.0 61.1 70.6 62.5 Table 5: Bi-encoder and cross-encoder performance on multilingual event linking (test set performance) across all languages in the dataset. Languages # mentions Bi-encoder Recall@min Cross-encoder Strict Acc Macro F1 Micro F1 Crosslingual Afrikaans Arabic Belarusian Bengali Bulgarian Catalan Chinese Czech Danish Dutch English Finnish French German Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean Malay Malayalam Marathi Norwegian Persian Polish Portuguese Romanian Russian Serbian Slovak Slovenian Spanish Swahili Swedish Tamil Thai Turkish Ukrainian Vietnamese 360 1776 612 136 1918 1312 980 2051 575 2030 10065 2956 6760 8888 2841 1866 91 974 678 3842 2768 897 190 30 16 895 608 4749 1851 1329 13221 2770 561 456 3757 3 1135 36 275 1586 3551 533 67.2 24.3 36.4 5.9 42.3 41.8 23.1 39.3 48.9 32.7 41.8 33.9 34.8 38.7 36.4 32.1 13.2 38.5 44.0 39.0 21.2 31.5 44.2 16.7 12.5 44.6 35.0 32.6 44.4 45.6 41.9 39.3 46.0 47.1 43.3 0.0 48.3 16.7 44.4 36.1 53.6 41.7 34.2 6.2 9.5 0.7 9.1 11.8 7.5 11.4 23.8 14.0 18.2 16.2 13.5 13.9 10.2 8.4 5.5 10.2 15.9 12.9 8.3 19.1 12.6 6.7 0.0 21.7 7.6 8.6 17.7 14.2 12.1 8.3 10.0 14.2 15.3 0.0 18.1 0.0 20.4 10.1 12.2 12.8 40.6 20.7 31.5 4.2 32.6 37.5 22.9 28.7 44.7 33.7 49.5 33.1 33.9 33.5 27.0 20.5 8.2 22.4 41.6 34.5 20.9 36.0 34.1 12.5 3.1 40.5 22.3 27.0 44.2 36.2 36.7 28.9 26.8 29.9 35.9 11.1 35.4 14.0 42.9 25.9 34.0 37.5 39.1 19.5 30.6 5.4 32.2 36.7 21.0 28.6 40.6 33.2 45.7 32.3 32.9 31.3 26.8 20.6 7.4 23.3 40.8 33.5 19.8 31.8 33.4 13.0 4.9 38.6 21.6 26.4 40.8 34.8 35.3 29.2 26.3 30.2 35.0 15.4 34.6 15.4 40.0 26.0 33.4 33.9 Table 6: Bi-encoder and cross-encoder performance on crosslingual event linking (test set performance) across all languages in the dataset."}