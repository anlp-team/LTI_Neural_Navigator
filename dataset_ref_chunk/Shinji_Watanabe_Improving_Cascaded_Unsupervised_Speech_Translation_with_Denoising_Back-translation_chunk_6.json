{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Improving_Cascaded_Unsupervised_Speech_Translation_with_Denoising_Back-translation_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main focus of the work mentioned in the text?", "answer": " Building cascaded unsupervised speech-to-speech translation systems and proposing denoising back-translation to improve robustness.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " How does denoising back-translation (DBT) contribute to improving unsupervised speech translation performance?", "answer": " It generally improves the performance across different language pairs that were experimented on.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What is one of the key advantages of the speech translation results from this work?", "answer": " They are better than some previous supervised methods even without using any paired data.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What is a potential future direction mentioned in the text for further research?", "answer": " Investigating techniques to reduce error propagation between different unsupervised cascaded modules or conducting direct unsupervised speech-to-text translation.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What limitations are identified in the work discussed in the text?", "answer": " The unresolved error propagation between UTTS and other modules, and the limitation to written languages for the US2ST system.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What is the focus of the Ethics Statement mentioned in the text?", "answer": " Building effective unsupervised speech translation systems, reducing error propagation, and improving inference latency.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What are some references to related works cited in the text?", "answer": " Some references include Common Voice, Wikiextractor, XLS-R, wav2vec 2.0, and Unsupervised speech recognition.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What is the purpose of the proposed method TDN in the text?", "answer": " To be integrated into UNMT in order to reduce inference latency.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What is the potential impact of the unresolved error propagation between UTTS and other modules?", "answer": " It may lead to a lower score of the S2ST (speech-to-speech translation) result.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}, {"question": " What additional insight does the denoise back-translation method bring to unsupervised speech-to-speech translation?", "answer": " It brings new insights and can be extended to unwritten language setups.", "ref_chunk": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}], "doc_text": "be overestimated. The performance drop induced by pseudo-labeling is acceptable or at least reasonable. 6 Conclusion In this work, we build cascaded unsupervised speech-to-speech translation (US2ST) systems in several translation directions. To further improve the performance and mitigate the error propagation problems, we propose denoising back-translation (DBT), which is a novel method to improve the robustness of UNMT. DBT generally improves the performance of unsupervised speech translation (UST) across all the language pairs that we have experimented on. Without leveraging any paired data, our speech translation results are even better than some previous supervised methods. Addition- ally, we analyze the performance of each part in different settings individually; and we also attempt to integrate the TDN into the UNMT to reduce inference latency. In the future, we may inves- tigate more techniques that can reduce the error propagation problems between different unsuper- vised cascaded modules; or conduct direct UST or US2ST. Limitations In this work, we have handled the problem of error propagation among UASR, TDN, and UNMT. Nev- ertheless, we didn\u2019t resolve that between UTTS and other modules, which may lead to a lower score of the S2ST result. Our methodology works for most languages, however, our US2ST is based on UNMT for un- paired text data. Therefore, it is limited to writ- ten languages. We believe that our denoise back- translation brings new insights to US2ST and can extend to unwritten language setups. Ethics Statement Our works build an effective UST cascaded system and try to mitigate the error propagation and infer- ence latency. The communities might be interested in how to build a direct US2TT or even US2ST system or how to further improve the performance of the UST system. References Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor Weber. 2019. Common voice: A massively- arXiv preprint multilingual arXiv:1912.06670. speech corpus. Giusepppe Attardi. 2015. Wikiextractor. https:// github.com/attardi/wikiextractor. Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021. Xls-r: Self-supervised cross-lingual arXiv speech representation learning at scale. preprint arXiv:2111.09296. Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. 2021. Unsupervised speech recogni- tion. Advances in Neural Information Processing Systems, 34:27826\u201327839. Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A frame- work for self-supervised learning of speech represen- tations. Advances in Neural Information Processing Systems, 33:12449\u201312460. Yonatan Belinkov and Yonatan Bisk. 2017. Synthetic and natural noise both break neural machine transla- tion. arXiv preprint arXiv:1711.02173. 9 Luisa Bentivogli, Mauro Cettolo, Marco Gaido, Alina Karakanta, Alberto Martinelli, Matteo Negri, and Marco Turchi. 2021. Cascade versus direct speech translation: Do the differences still make a differ- ence? arXiv preprint arXiv:2106.01045. Alexandre B\u00e9rard, Olivier Pietquin, Christophe Servan, and Laurent Besacier. 2016. Listen and translate: A proof of concept for end-to-end speech-to-text trans- lation. arXiv preprint arXiv:1612.01744. Kuan-Yu Chen, Che-Ping Tsai, Da-Rong Liu, Hung-Yi Lee, and Lin-shan Lee. 2019. Completely unsuper- vised speech recognition by a generative adversarial network harmonized with iteratively re\ufb01ned hidden markov models. arXiv preprint arXiv:1904.04100. Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019a. Semi- supervised training for improving data ef\ufb01ciency In ICASSP 2019- in end-to-end speech synthesis. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6940\u20136944. IEEE. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2018. Unsupervised cross-modal alignment of speech and text embedding spaces. Ad- vances in neural information processing systems, 31. Yu-An Chung, Wei-Hung Weng, Schrasing Tong, and James Glass. 2019b. Towards unsupervised speech- to-text translation. In ICASSP 2019-2019 IEEE In- ternational Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7170\u20137174. IEEE. Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. representation learn- Unsupervised cross-lingual arXiv preprint ing for arXiv:2006.13979. speech recognition. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116. Mattia Antonino Di Gangi, Robert Enyedi, Alessandra Brusadin, and Marcello Federico. 2019. Robust neu- ral machine translation for clean and noisy speech transcripts. arXiv preprint arXiv:1910.10238. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative ad- versarial networks. Communications of the ACM, 63(11):139\u2013144. Tomoki Hayashi, Ryuichi Yamamoto, Takenori Yoshimura, Peter Wu, Jiatong Shi, Takaaki Saeki, Yooncheol Ju, Yusuke Yasuda, Shinnosuke Takamichi, and Shinji Watanabe. 2021. Espnet2-tts: Extending the edge of tts research. arXiv preprint arXiv:2110.07840. Keith Ito and Linda Johnson. 2017. The lj https://keithito.com/ speech LJ-Speech-Dataset/. dataset. Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, and Roi Pomerantz. 2021. Translatotron 2: Robust di- arXiv preprint rect speech-to-speech translation. arXiv:2107.08661. Ye Jia, Michelle Tadmor Ramanovich, Quan Wang, and Heiga Zen. 2022. CVSS corpus and mas- sively multilingual speech-to-speech translation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 6691\u20136703, Mar- seille, France. European Language Resources Asso- ciation. Ye Jia, Ron J Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson, Zhifeng Chen, and Yonghui Wu. 2019. Direct speech-to-speech translation with arXiv preprint a sequence-to-sequence model. arXiv:1904.06037. Jaehyeon Kim, Jungil Kong, and Juhee Son. 2021. Conditional variational autoencoder with adversar- ial learning for end-to-end text-to-speech. In Inter- national Conference on Machine Learning, pages 5530\u20135540. PMLR. Guillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291. Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. 2017. Unsupervised ma- chine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043. Alon Lavie, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppen- feld, and Puming Zhan. 1997. Janus-iii: Speech- In to-speech translation in multiple languages. 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 99\u2013 102. IEEE. Jiachen Lian, Chunlei Zhang, Gopala Krishna Anu- manchipalli, and Dong Yu. 2022. Utts: Un- supervised tts with conditional disentangled se- arXiv preprint quential variational auto-encoder. arXiv:2206.02512. Guan-Ting Lin, Chan-Jan Hsu, Da-Rong Liu, Hung- Yi Lee, and Yu Tsao. 2022."}