{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Crossing_the_Threshold:_Idiomatic_Machine_Translation_through_Retrieval_Augmentation_and_Loss_Weighting_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main focus of the study discussed in the text?,answer: The main focus is on improving machine translation of idiomatic expressions.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What is an idiom?,answer: An idiom is a conventionalized expression where the intended meaning differs from its literal translation.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " Why do idioms pose a challenge to translators?,answer: Idioms pose a challenge because their meanings do not follow from the meanings of their individual parts.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What is the tipping point mentioned in the text in relation to idiomatic translations?,answer: The tipping point is the point at which transformer-based machine translation models correctly default to idiomatic translations.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What dataset did the researchers compile to improve translation of idiomatic expressions?,answer: They compiled a dataset of natural sentences containing idiomatic expressions in French, Finnish, and Japanese.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What are two techniques introduced to improve translation of idioms?,answer: The strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What is the translation challenge posed by idiomatic expressions in literary texts?,answer: Failure to translate idiomatic expressions correctly may lead to incomprehensible translations, particularly in literary text.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What was the main improvement achieved by the proposed techniques in the study?,answer: The techniques improved the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What is the significance of the created dataset of sentences containing idiomatic expressions?,answer: The dataset contributes resources toward documenting idioms and improving their translation cross-linguistically.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}, {"question": " What is the average improvement in idiomatic translation abilities achieved by the proposed techniques?,answer: The techniques improved the idiomatic translation abilities of the model significantly, by an average of 10.4% in absolute accuracy.", "ref_chunk": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}], "doc_text": "3 2 0 2 t c O 0 2 ] L C . s c [ 2 v 1 8 0 7 0 . 0 1 3 2 : v i X r a Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting Emmy Liu Aditi Chaudhary \u2217 Graham Neubig Carnegie Mellon University emmy@cmu.edu, aditichaud@google.com, neubig@cs.cmu.edu Abstract Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the mean- ings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic trans- lation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based ma- chine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of \u223c 4k natu- ral sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on poten- tially idiomatic sentences, and using retrieval- augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.1 Although idiom translation has been recognized as a problem even before the advent of neural ma- chine translation (Bar-Hillel, 1952; Wehrli, 1998), most work has focused on identifying and evaluat- ing the problem cross-linguistically (Baziotis et al., 2022; Dankers et al., 2022b), or on interpreting the behaviour of transformer-based models in trans- lating or memorizing idioms (Haviv et al., 2022; Dankers et al., 2022b). Others pose idiom identifi- cation and paraphrasing as a separate task from ma- chine translation (Pershina et al., 2015). Compara- tively fewer recent works have attempted to remedy this problem. Early work made use of idiom dic- tionaries and direct substitution, or example-based machine translation (Salton et al., 2014; Nagao, 1984). However, we would ideally want to make use of the contextual translation abilities of neu- ral models. Data augmentation and the creation of new datasets have helped address this problem (Agrawal et al., 2018), but it may also be possi- ble to use existing data resources more effectively, especially for higher-resource languages. 1 Introduction An idiom is a conventionalized expression in which the intended meaning differs from its literal transla- tion. The translation of idioms has remained a prob- lem for state-of-the-art research and commercial translation systems, as idioms tend to be translated literally (Dankers et al., 2022b; Shao et al., 2017; Anastasiou, 2010). Failure to translate these expres- sions correctly may lead to incomprehensible trans- lations, particularly in literary text (Toral and Way, 2018). To illustrate the difficulty of understanding mistranslated idioms, we present mistranslations from commercial systems in Table 1.3 \u2217 Currently works at Google Research. 1Code and data available at https://github.com/n We first frame the general problem of non- compositional translation, which encompasses the translation of idioms and other multi-word expres- sions that cannot be translated word-for-word (\u00a72). We then perform synthetic experiments in a very simple case, finding that transformer-based ma- chine translation models generally translate word- for-word until a proportional threshold of sentences contain non-compositional expressions, at which point the translations flip to being correct (\u00a74.1). We evaluate translations by commercial models in three natural languages, and find a drop in perfor- mance on idiomatic sentences and stronger perfor- mance on more common idioms (\u00a74.2). We hypoth- esize that this may reflect similar trends as exist in processing other long-tail phenomena, and similar tactics to those used to deal with rare phenomena may work (Kandpal et al., 2022). ightingal3/idiom-translation/ 3Translations from commercial systems were collected at the end of 2022. With this intuition, we improve the idiomatic Source Target Translation Language System Vous devez avoir la dalle. You gotta be starving. You must have the slab. fr DeepL Il lui faut toujours chercher la petite b\u00eate. He has to dot all the i\u2019s, cross all the t\u2019s. He always has to look for the little beast. fr DeepL J\u2019ai la p\u00eache \u00e0 mort. Good as hell. I have the peach to death. fr Google \u5f31\u8089\u5f37\u98df The Weak are Meat, the Strong do Eat. The Weak are the Strong. ja DeepL \u305d\u306e\u624b\u306f\u98df\u308f\u306a\u3044\u308f Oh, no, I\u2019m not falling for that. I\u2019m not gonna eat that hand. ja DeepL \u77e5\u3089\u306c\u304c\u4ecf\u3063\u3066\u4e8b\u3082\u3042\u308b Well, sometimes what we don\u2019t know doesn\u2019t hurt us, right? I don\u2019t know, but sometimes Buddha ja Google Eukko el\u00e4\u00e4 kuin pellossa. Whoa. Homegirl clearly never met a trashcan. The hen lives like a field. fi DeepL Sinun olisi pit\u00e4nyt ottaa minut mukaan t\u00e4h\u00e4n isoon p\u00e4\u00e4t\u00f6kseesi - tavasta, jolla is\u00e4mme heitt\u00e4\u00e4 lusikan nurkkaan. You should have included me in this huge de- cision you made about how our father\u2019s gonna leave this Earth. You should have included me in this big decision of yours - the way our father throws the spoon in the corner. fi DeepL Roger voi tyk\u00e4t\u00e4 kyttyr\u00e4\u00e4. Roger may take a dim view of this... Roger may like a hunchback. fi Google Table 1: Examples of mistranslated sentences produced by commercial translation systems. Idioms and their corresponding translations are highlighted in red.2 translations generated by a strong pretrained ma- chine translation model, \u2206LM (Ma et al., 2021), without harming the translation quality of literal expressions. To contribute resources toward doc- umenting idioms and improving their translation cross-linguistically, we create a dataset of sentences containing idiomatic expressions in three languages (French (fr), Finnish (fi) and Japanese (ja) (\u00a73). We propose two simple but effective ways to im- prove translation of idioms, namely upweighting training loss on potentially idiomatic sentences and retrieval augmentation (\u00a75). We find that this can improve the idiomatic translation abilities of the model significantly, by an average of 10.4% in abso- lute accuracy (\u00a77.1). Moreover, this does not harm translation of sentences where the literal sense of the idiom is used, and it improves translation of out-of-distribution sentences in French and Finnish"}