{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Multi-Dimensional_Evaluation_of_Text_Summarization_with_In-Context_Learning.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What kind of evaluation is discussed in the text?", "answer": " Multi-dimensional evaluation of text summarization with in-context learning", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What are some dimensions in which generated text can be evaluated?", "answer": " Fluency, coherence, factuality, and any other dimensions of interest", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What is the advantage of using large language models for multi-dimensional evaluation?", "answer": " They can be used as evaluators without the need for large training datasets", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What is ICE in the context of text evaluation?", "answer": " In-Context learning-based Evaluator framework", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " How many in-context examples are used in the default prompt design for ICE?", "answer": " 4 in-context examples", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What are the four dimensions evaluated in the text?", "answer": " Consistency, relevance, fluency, and coherence", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What kind of datasets and baselines are used for evaluation in the text?", "answer": " SummEval dataset, CTC, BARTScore, UniEval", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What is observed about the performance of ICE with respect to UniEval?", "answer": " ICE with uniform sampling outperforms UniEval on consistency and relevance", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What is the main finding regarding the evaluation of GPT-3 summaries by ICE?", "answer": " ICE evaluations agree closely with human judgments on GPT-3 summaries", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}, {"question": " What is a limitation mentioned in the text regarding the use of powerful language models?", "answer": " Dependency on external models that may carry the risk of failure", "ref_chunk": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}], "doc_text": "Multi-DimensionalEvaluationofTextSummarizationwithIn-ContextLearningSameerJain1VaishakhKeshava1SwarnashreeMysoreSathyendra1PatrickFernandes1,2PengfeiLiu1GrahamNeubig1ChuntingZhou31CarnegieMellonUniversity2InstitutoSuperiorT\u00e9cnico3FacebookAIResearch{sameerj,vkeshava,smysores}@cs.cmu.eduAbstractEvaluationofnaturallanguagegeneration(NLG)iscomplexandmulti-dimensional.Gen-eratedtextcanbeevaluatedforfluency,co-herence,factuality,oranyotherdimensionsofinterest.Mostframeworksthatperformsuchmulti-dimensionalevaluationrequiretrainingonlargemanuallyorsyntheticallygenerateddatasets.Inthispaper,westudytheefficacyoflargelanguagemodelsasmulti-dimensionalevaluatorsusingin-contextlearning,obviatingtheneedforlargetrainingdatasets.Ourex-perimentsshowthatin-contextlearning-basedevaluatorsarecompetitivewithlearnedeval-uationframeworksforthetaskoftextsum-marization,establishingstate-of-the-artondi-mensionssuchasrelevanceandfactualcon-sistency.Wethenanalyzetheeffectsoffac-torssuchastheselectionandnumberofin-contextexamplesonperformance.Finally,westudytheefficacyofin-contextlearning-basedevaluatorsinevaluatingzero-shotsum-marieswrittenbylargelanguagemodelssuchasGPT-3.Ourcodeisavailableathttps://github.com/JainSameer06/ICE1IntroductionDevelopingcomprehensiveevaluationframe-works(Dengetal.,2021;Yuanetal.,2021;Zhongetal.,2022)thatcanevaluatemultiplehuman-interpretabledimensions,suchasfactualconsis-tency(Kryscinskietal.,2020;Wangetal.,2020)andcoherence(Dzirietal.,2019;Huangetal.,2020),isimportantfortheadvancementofNaturalLanguageGeneration(NLG).However,similarity-basedmetrics(Papinenietal.,2002;Lin,2004;Sellametal.,2020;Zhaoetal.,2019;Zhangetal.,2020)stilldominateNLGevaluationinpractice.Comparedtothem,desiredmulti-dimensionaleval-uatorsdonotrequirereferencetextsforevaluation;andtheycaneasilyextendtonewexplainableeval-uationdimensions.Recently,Zhongetal.(2022)developedaunifiedevaluationframeworkthatcan\nText: Cats and dogs have the advantage... Summary: roland girous keeps a blood parrot... Consistency: 1.0 Text: Jordan Henderson has provided Liverpool.. Summary: jordan henderson is set to sign a... Consistency: 0.67 Text: Arsenal playmaker Mesut Ozil seemed... Summary: mesut ozil impressed on international... Consistency: ___________ Figure1:Ourpromptdesigntoevaluatetheconsistencyofthesummaryinred,illustratedusingtwoin-contextexamples(inblue).Toevaluateotheraspects,were-movethesourcetextorreplaceitwithareference.generalizetomultipledimensionsandtextgener-ationtasks.However,itreliesontheconstructionofsyntheticandauxiliarydataforthefinetuningofapre-trainedlanguagemodel,requiringin-depthknowledgeandsignificantengineeringeffortforeachdimension.Furthermore,theinclusionofnewdimensionsrequires(continued)trainingofthemodel,andmightaffecttheperformanceonotherdimensionsinunforeseenways.Inthiswork,weproposetousein-contextlearn-ing(Brownetal.,2020)withlargelanguagemod-els(LLMs)\u2014acommonlyusedmethodtoperformmanytasksbyutilizingonlyafewinput-outputex-amples\u2014toperformmulti-dimensionaltextevalu-ationinaunifiedfashion.Comparedtopre-trainedevaluatorsthatneedspecializedsupervisedtrainingforeachdimension,ourIn-Contextlearning-basedEvaluator(ICE)frameworkis:\u2022Learning-free.Itdoesnotrequiresupervisedfine-tuningonlargeannotated(synthetic)train-ingdata,requiringonlyahandfulofsamplesatinferencetime.\u2022Extensible.Toevaluatenewdimensions,itdoesnotrelyonlargeamountsofhumanjudgmentsortheconstructionofnewsyntheticdata,usingonlyanaturallanguagepromptconsistingofasmallnumberofexamplepairstoascertainthepropertiesassociatedwithagivenqualityaspect.\n8487 Findings of the Association for Computational Linguistics: ACL 2023, pages 8487\u20138495 July 9-14, 2023 \u00a92023 Association for Computational Linguistics\n\n\nInthispaper,usingtextsummarizationasatestbed,weshowthatwithasimplepromptdesign,ICEiscompetitivewithstate-of-the-arttrainedevalu-atorsonmulti-dimensionalevaluationofmodel-producedsummaries,establishinganewstate-of-the-artondimensionssuchasrelevanceandfactualconsistency.Tostudytherobustnessoftheeval-uatortotheselectionofin-contextexamples,weanalyzethefactorsthataffecttheperformanceofICE,suchasthenumberofin-contextexamplesandsamplingprocedureswhenpickingin-contextexamplesfromasetofcandidates.WefindICEtoberobusttotheselectionofin-contextexamplesandobserveaslightimprovementinperformanceasthenumberofexamplesisincreased.Finally,inlightoftherecentwork(Goyaletal.,2022)thatpointstothemisalignmentofexistingevaluationmetricswithhumanpreferenceinevaluatingzero-shotsummariesgeneratedbyLLMssuchasGPT-3(Brownetal.,2020),westudytheeffectivenessofICEinevaluatingzero-shotsummariesgener-atedbyGPT-3.WefindthatICEevaluationsagreecloselywithhumanjudgmentsonsuchsummaries.2Methodology2.1ProblemStatementGivenasequencexthatisinputtoanNLGsys-temandasystem-generatedoutputsequencey,anevaluationframeworkoutputsascoresthatcap-turesthequalityofy,eitherwithorwithoutthehelpofahuman-generatedreferenceoutputr.1Incaseofmulti-dimensionalevaluationwhereweareinterestedinassessingyoverdqualitymetrics,weinsteadgetavectorS=(s1,s2,...,sd)overdiversedimensions(e.g.,coherence,fluency).De-pendingonthedimension,thereissometimesaneedtoconditionanevaluationonx(suchastoevaluateconsistencyinsummarization).Weevalu-ateourmethodoverfourdimensions:\u2022Consistency:Thefactualcorrectnessofasum-marygiventhesourcetext.\u2022Relevance:Thepropertyofcapturingsalientinformationfromthesource.\u2022Fluency:Ameasureofthequalityoftheindivid-ualsentencesinthesummary.\u2022Coherence:Ameasureofthequality,organiza-tion,andstructureofsentencesinthesummary.\n1Specificallyforsummarization,mostlearnedframeworksevaluaterelevancethroughreference-basedevaluation.2.2PromptDesign&ScoreExtractionICEreliesonanLLM(weusethetext-davinci-003modelofGPT-3)tomakepredictions.Ittakesinapromptthatconsistsofasmallnumberofin-contextexamples,eachofwhichconsistsofgeneratedtextanditscorrespondingqualityscoreasanumericstring.Thepromptendswithatestexample,forwhichthemodelpredictsascore(Figure1).Theinputcontainsthemodel-generatedtext(summary),inadditiontowhichitmightcon-tainadditionalinformationsuchasthesourcetextorreferences,dependingonthedimen-sion.Toevaluatefluencyandcoherence,ourpromptsusein-contextexamplesconsistingofgen-eratedsummariesandcorrespondingscores.Forconsistencyandrelevance,weusethesourcetextandareferencesummaryrespectively,inaddi-tiontothegeneratedsummary.WepassthisprompttoaGPT-3model,withsamplingtemperaturesetto0toelicitdeterministicresponses.Weparsethemodelresponse\u2013decodednumericstring\u2013asthedimensionscore.2.3SelectionofIn-contextExamplesBydefault,weuse4in-contextexamplesinourprompts,asthisisthelargestnumberthatfitswithinthecontextwindowofGPT-3.Weexperi-mentwithtwosamplingprocedures(AppendixB)toobtain4examplesfromapoolofexamples:1.UniformRandomSampling.Werandomlyselect4summariesfromthepoolofexamples.Thiscausestheexamplestofollowthesamedistributionastheexamplepool.2.StratifiedSampling.Webuckettherangeofscores,i.e.[0,1],into4equalpartitionsandrandomlysampleonesummaryfromeachone.Thiscausesexamplestoberepresentativeoftherangeofscoresintheexamplepool.Weavoidusingsyntheticallygenerateddata(Kryscinskietal.,2020;Zhongetal.,2022)sincethekindoferrorsmadebygenerationmodelsisoftendifferentfromtheerrorspresentinthenegativeexamplesinthesedatasets(GoyalandDurrett,2021).Weinsteadelecttouse(afew)humanevaluationsofmodel-generatedtextinordertomakethein-contextexamplesasrepresentativeofrealerrorsaspossible.Wedothisbysplittingthemeta-evaluationdatasetandusingapartitionasanin-contextexamplepool,asdescribedinSection3.1.\n8488\n\n\n2https://github.com/Yale-LILY/SummEvalBARTScore(whichalsodoesnotrequirefine-tuning)acrossdimensions.BetweenthetwosamplingproceduresforICE,weobservethatstratifiedsamplingworksmarginallybetterforalldimensionsotherthanconsistency.SincesummariesintheSummEvaldatasethaveperfectornear-perfecthumanscoresforconsistency(Figure2),uniformsamplingcausesin-contextexamplestoalsohavenear-perfectscores.Thisappearsusefulforthemodeltocalibrateitsscoringwhenevaluatingconsistency,leadingtobetterperformance.Weexplorethisingreaterdetailin\u00a74.1.Whilethesamereasoningcouldholdforfluency,weobservebothhereandin\u00a74.3thatfluencyscoresarequitestable.Giventhatfluencyisaneasieraspecttoevaluate,thisstabilitycouldbearesultofthemodelpossessingastrongnotionaboutfluencyfrompre-trainingtimethatisnotmodifiedsignificantlyasthedistri-butionofin-contextexampleschanges(ReynoldsandMcDonell,2021).Finally,weobservethattheperformanceforcoherenceandrelevancearesimilarregardlessofthesamplingprocedure.Thisisbecausescoresfortheseaspectsarespreadoutinthedataset,whichmakesuniformandstratifiedsamplingreturnsimilarin-contextexamples.4AnalysisInthissection,weanalysetheeffectsofourpromptengineeringchoices.Thecomparisonbetweensam-plingproceduresinSection4.1isperformedontheentiretestsetbuttheexperimentsinSections4.2and4.3areperformedonatestsetsampleofsize200tocontrolcosts.TheanalysesinSections4.1and4.2usefourin-contextexamples.4.1AnalyzingtheSamplingProceduresFigure2illustratesthatthepredictiondistributionsfromuniformandstratifiedsamplingdifferthemostwhenthetruedistributionisskewed,suchasforconsistency.Insuchacase,stratifiedsam-plingselectsin-contextexamplesfromtheentire\nCTC--0.4250.340--0.4950.364BARTScore0.4450.3400.3800.3140.3450.2830.3570.274UniEval0.5910.4240.4330.3480.4450.3490.4730.343\nTable1:Summary-levelSpearmanandKendall-TaucorrelationsofdifferentmetricsontheSummEvalbenchmark3Experiments3.1Datasets&BaselinesWeusetheSummEvaldataset(Fabbrietal.,2020)2tometa-evaluateourevaluationframework.Sum-mEvalcollectshumanevaluationannotationsfor16summarizationsystemson100articlessampledfromtheCNN/DailyMailcorpus,foratotalof1600summary-levelannotations.Eachsummaryiseval-uatedonfourdimensionsdescribedinSection2.2.Togetapoolofin-contextexamples,wekeepasideasmallsubset(64examples)oftheSum-mEvaldatasettopickin-contextexamplesfrom,andusetherest(1536examples)asthetestsetformeta-evaluation(evaluatingthebaselinesonthissametestset).FurtherdetailsareinAppendixA.WecompareICEtothefollowingstate-of-the-artmulti-dimensionalevaluators:(1)CTC(Dengetal.,2021)usesinformationalignmentbetweengeneratedoutputsandreferencesorinputs;(2)BARTScore(Yuanetal.,2021)usesthecondi-tionalprobabilityofasequencegiveninputsorreferences;and(3)UniEval(Zhongetal.,2022)usesaquestion-answeringframework(e.g.\"Isthisacoherentsummary?\")tocalculatemetrics.FollowingLiuetal.(2021);Zhongetal.(2022),weassessperformancebycomputingsummary-levelSpearmanandKendall-Taucorrelationsbe-tweenpredictedscoresandhumanjudgements.3.2ResultsAsillustratedinTable1,ICEiscompetitivewithfine-tunedbaselinesdespitenotrequiringanyfinetuning.Itachievesstate-of-the-artcor-relationwithhumanjudgmentsforrelevanceandconsistency.Weperformpairwisesignif-icancetestsandobservethatICE(uniformsam-pling)doesbetterthanUniEvalonconsistencyandrelevanceonKendall\u2019sTauwithasignifi-cancelevelof0.05(AppendixE).Additionally,theuniformsamplingvariantofICEoutperforms\nMetricCoherenceConsistencyFluencyRelevance\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\u03c1\u03c4\nICE(UniformSampling)0.4760.3880.4860.4660.3660.3280.4670.384ICE(StratifiedSampling)0.4970.3870.2980.2630.3970.3480.4850.396\n8489\n\n\n500\n500\n500\n500\nConsistency\nConsistency\nCoherence Stratified SamplingScoresNumber of ExamplesFigure2:DistributionsofhumanscoresandpredictedscoresusingICEwithuniformandstratifiedsamplingontheSummEvalbenchmarkdomainregardlessofthetruedistribution.Thisforcespredictionstowardsacentereddistribution,whichcancausetheperformancedropweobserveinTable1whenevaluatingconsistencyusingstratifiedsampling.Uniformsampling,ontheotherhand,selectsexamplesthatrepresentthetruedis-tribution,makingmodelpredictionsmorecloselyreflectthetruedistribution.Adrawbackofuniformsamplingissub-optimalcalibrationinlow-probabilityregionsofthetruedistribution.Forinstance,ifuniformsamplingisusedtoevaluateconsistency,themodelmightnotseein-contextexampleswith(say)scoreslessthan0.3(Figure2).Thiscanaffectoutputcali-brationinthatregion.Nonetheless,wesuggestusinguniformsamplingingeneral.Itismoresta-bleanditspredictiondistributioncloselyfollowsthetruedistribution.Fordimensionswhereitun-derperformsstratifiedsampling,themarginsarelesssignificant.Finally,evenwhenICE(uniformsampling)scoresarecalibrateddifferentlyfromhumanscores,theystillranksummary-qualitycor-rectly,insofarasourmainresults(Table1)show\n1000\n1000\n1000\n1000\n0.2\nCoherence Uniform Sampling\nRelevance Stratified Sampling\n0\n0\n0\n0\nCoherence\nCoherence\nRelevanceAspect\n3.5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nRelevanceFigure4:Effectofvaryingthenumberofin-contextexamples.thattheycompetewithstate-of-the-artonranking-basedmetricslikeKendall-TauandSpearmancor-relation.Weuseuniformsamplingtoselectin-contextexamplesinSections4.2and4.3.4.2EffectofSelectionofIn-contextExamplesInordertodeterminewhetherperformanceisro-busttothechoiceofin-contextexamples,weeval-uateourtestsetusingthreedifferentrandomsetsofin-contextexamples.WeobserveinFigure3thatforagivendimension,themaximumvariationacrossthreeseedsisabout7points,suggestingrea-sonablystableperformanceacrossthechoiceofin-contextexamples.4.3EffectofNumberofIn-contextExamplesWeevaluateourtestsetusingdifferentnumbersofin-contextexamples(Figure4).Weobservethatonlyforrelevanceandcoherencedoesperfor-manceshowimprovementasweincreasethenum-berofexamples.Onereasonforthiscouldbethedistributionofscoresforagivendimensioninthetestset(Figure2).Concretely,consistencyandfluencymostlyhavenear-perfectscoresandthere-foredonotbenefitfrommoresampleswhilethe\nConsistency Stratified Sampling\nSeed 3Figure3:Effectofsamplingdifferentin-contextexam-ples.Theperformanceoverthesametestsetisobservedtoberobusttothechoiceofin-contextexamples.\n1.5\n1500\n1500\n1500\n1500\n3.0\nConsistency Uniform Sampling\nCoherence Human\nFluency Uniform Sampling\n2.5\nFluency Stratified Sampling\n4.0Number of In-context Examples\nRelevance Human\nFluency\nFluency\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\nSeed 2\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nFluency Human\n2.0\nSeed 1\n0.4\n0.4\n0.6Spearman Correlation\n0.6Spearman Correlation\nConsistency Human\nRelevance Uniform Sampling\n8490\n\n\n1.25\n1.25\n1.25\n1.25\n1.25\n0.981\n26.63\n0.849\n4.85\n0.929\n0.761\n4.47\nMetric\n0.96-0.96-0.96-0.96\n4.78\nBRIO\nBRIO\nBRIO\nBRIO\n3SummEvalannotationsareallbasedonthesource,andthesrc-to-hypversionofBARTScoreperformsbestacrossdimensionsforthisbenchmark.Weusethisversionforalldi-mensions,leadingtoidenticalscores.WeformatBARTScoreresultsunlikeROUGE-LbecauseintheoryBARTScorescandifferacrossdimensionsforanarbitrarybenchmark.\nModel\n0.996\n4.15\n22.09\n0.890\nOverall\n4.97\n0.908\nTable2:System-levelscoresfromhumanannotationsandautomaticmetrics.Foreachaspect,wecoloragivenmetric\u2019shighest/lowestratedsystemwithorange/purple.scoresforcoherenceandrelevancearespreadoutandthereforemoresamplesallowrepresenta-tionoverthewholerangeofscores.Anotherobservationisthatevenforcoherenceandrelevance,performancewithasinglein-contextexamplereachesnearthatachievedbysomeoftheweakerfine-tunedbaselinesinTable1.Thissuggeststhatthemodelpossessestheno-tionoftheevaluationtaskfrompre-trainingitself,whichisinlinewithrecentwork(ReynoldsandMcDonell,2021;Minetal.,2022)thatsuggeststhatdemonstrationshelpextractthisknowledge.Finally,wenotethatcalibrationcanpotentiallybeimprovedbyincreasingthenumberofexam-ples.Forinstance,weobservedthatthefourin-contextexamplesthattheuniformsamplingpro-cedurechoseforcoherenceinFigure2hadscoresthatfallbetween0.7and1.0.Thisconcentratesthepredictiondistributioninthatrange.Theprobabil-ityofsuchaneventwillreduceasthenumberofexamplesisincreasedfurther.5UsingICEtoEvaluateZero-ShotPromptingModelsRecentworkbyGoyaletal.(2022)showedthatstandardreference-basedandreference-freemet-ricsarenotreliableinevaluatingzero-shotsum-marieswrittenbymodelssuchasGPT-3.Throughahumanstudycomparingsummariesfromthreesystems\u2013GPT-3,BRIO,andT0\u2013theyobservedthatwhilehumanspreferGPT-3summaries,automaticevaluatorsconsistentlyscoreGPT-3summarieslowerthansummariesfromothermodels.WestudytheefficacyofICEinevaluatingzero-shotsummarieswrittenbyGPT-3atadimensionlevel.Weusethesetof500CNNarticlesfromGoyaletal.(2022),withsummariesfromGPT-3,BRIO,andT0foreacharticle.Wesample100ofthesearticlesandhavethreeannotatorsratesummariesforeachofthedimensionsdefinedinSection2.2onascaleof{1,2,3,4,5}.WeuseICE,ROUGE,andBARTScore(allofwhichdonotrequiretrainingdata)toevaluatethesummariesandpresentsystem-levelresultsinTable2.WeobservethatICEagreeswithhumanjudg-mentsforeachdimensionandoverallpreferenceswhileexistingreference-basedandreference-freemetricssuchasROUGEandBARTScore3con-sistentlyrateGPT-3summarieslow.Goyaletal.(2022)suggestthatmostexistingevalua-tionmetricsrewardsummariesthatimitaterefer-ences,whileGPT-3summariesarezero-shotandnottrainedtoimitatehuman-writtenreferences,whichislikelywhytheyarepenalizedbymostex-istingevaluators.However,sinceICEisnotbasedonreferencesimilarity(exceptwhenevaluatingrelevance)andisalsonottrainedwithreferencesummaries,itisabletobetterevaluateGPT-3sum-mariesandagreeswithhumanpreferences.6ConclusionWeshowthatin-contextlearningcanbeusedforNLGevaluationasanalternativetofine-tunedeval-uationmetrics.Usingasmallnumberofexamples,in-contextlearningevaluatorscanreachorexceedthestate-of-the-artonmulti-dimensionalevaluationandthatthisisrobusttothechoiceofin-contextexamples.Finally,weshowthatin-contextlearn-ingevaluatorsalignwellwithhumanjudgementswhenevaluatingsummarieswrittenbyGPT-3.LimitationsWhileICEdoesnotrequirefine-tuningonlargeamountsofdata,itrequiresqueryingapowerfulLLMatinferencetime(weuseGPT-3forourexper-imentswhichhas175billionparameters).Thiscanbeapay-per-usemodeloranopen-sourcemodelsuchasBLOOM.Thismakesadownstreamsys-temthatusesICEreliantonanexternaldependency,whichcarriestheriskoftheexternaldependencyfailing.\n4.80\n28.20\nCoh.Con.Flu.Rel.\nHuman\n3.68\n4.73\nBARTSc.\n0.985\n0.96\n4.27\n0.71\n0.71\n0.71\n0.71\n0.71\n4.65\n4.65\nT0\nT0\nT0\nT0\n0.904\nROUGE-L\nICE\n0.994\nGPT-3\nGPT-3\nGPT-3\nGPT-3\n0.937\n\n0.8960.9930.9930.834\n4.574.654.884.48\n8491\n\n\nRelatedly,inthispaper,wearelimitedduetomonetaryconstraintsinavarietyofexperimentsweperform.Forinstance,werestrictourselvestotextsummarizationandusesamplesofbenchmarkmeta-evaluationsuitesduringsomeofourexperi-ments.WeleavetheinvestigationofusingICEforotherdimensionsanddownstreamtasksforfuturework.ReferencesTomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.MingkaiDeng,BowenTan,ZhengzhongLiu,EricXing,andZhitingHu.2021.Compression,transduction,andcreation:Aunifiedframeworkforevaluatingnaturallanguagegeneration.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7580\u20137605,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.NouhaDziri,EhsanKamalloo,KoryMathewson,andOsmarZaiane.2019.Evaluatingcoherenceindia-loguesystemsusingentailment.InProceedingsofthe2019ConferenceoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages3806\u20133812,Minneapolis,Min-nesota.AssociationforComputationalLinguistics.AlexanderRFabbri,WojciechKry\u00b4sci\u00b4nski,BryanMc-Cann,CaimingXiong,RichardSocher,andDragomirRadev.2020.Summeval:Re-evaluatingsummariza-tionevaluation.arXivpreprintarXiv:2007.12626.TanyaGoyalandGregDurrett.2021.Annotatingandmodelingfine-grainedfactualityinsummarization.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages1449\u20131462,Online.AssociationforComputa-tionalLinguistics.TanyaGoyal,JunyiJessyLi,andGregDurrett.2022.Newssummarizationandevaluationintheeraofgpt-3.LishanHuang,ZhengYe,JinghuiQin,LiangLin,andXiaodanLiang.2020.GRADE:Automaticgraph-enhancedcoherencemetricforevaluatingopen-domaindialoguesystems.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9230\u20139240,Online.AssociationforComputationalLinguistics.WojciechKryscinski,BryanMcCann,CaimingXiong,andRichardSocher.2020.Evaluatingthefactualconsistencyofabstractivetextsummarization.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages9332\u20139346,Online.AssociationforComputa-tionalLinguistics.Chin-YewLin.2004.ROUGE:Apackageforauto-maticevaluationofsummaries.InTextSummariza-tionBranchesOut,pages74\u201381,Barcelona,Spain.AssociationforComputationalLinguistics.PengfeiLiu,JinlanFu,YangXiao,WeizheYuan,ShuaichenChang,JunqiDai,YixinLiu,ZihuiwenYe,andGrahamNeubig.2021.ExplainaBoard:Anex-plainableleaderboardforNLP.InProceedingsofthe59thAnnualMeetingoftheAssociationforCompu-tationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing:SystemDemonstrations,pages280\u2013289,Online.AssociationforComputationalLinguistics.SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLukeZettle-moyer.2022.Rethinkingtheroleofdemonstrations:Whatmakesin-contextlearningwork?KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:Amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingonAssociationforComputa-tionalLinguistics,ACL\u201902,page311\u2013318,USA.AssociationforComputationalLinguistics.LariaReynoldsandKyleMcDonell.2021.Promptprogrammingforlargelanguagemodels:Beyondthefew-shotparadigm.ThibaultSellam,DipanjanDas,andAnkurParikh.2020.BLEURT:Learningrobustmetricsfortextgenera-tion.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages7881\u20137892,Online.AssociationforComputationalLinguistics.AlexWang,KyunghyunCho,andMikeLewis.2020.Askingandansweringquestionstoevaluatethefac-tualconsistencyofsummaries.InProceedingsofthe58thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages5008\u20135020,Online.Asso-ciationforComputationalLinguistics.WeizheYuan,GrahamNeubig,andPengfeiLiu.2021.Bartscore:Evaluatinggeneratedtextastextgenera-tion.InAdvancesinNeuralInformationProcessingSystems,volume34,pages27263\u201327277.CurranAs-sociates,Inc.TianyiZhang,VarshaKishore,FelixWu*,KilianQ.Weinberger,andYoavArtzi.2020.Bertscore:Eval-uatingtextgenerationwithbert.InInternationalConferenceonLearningRepresentations.\n8492\n\n\nWeiZhao,MaximePeyrard,FeiLiu,YangGao,Chris-tianM.Meyer,andSteffenEger.2019.MoverScore:Textgenerationevaluatingwithcontextualizedem-beddingsandearthmoverdistance.InProceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9thInterna-tionalJointConferenceonNaturalLanguagePro-cessing(EMNLP-IJCNLP),pages563\u2013578,HongKong,China.AssociationforComputationalLin-guistics.MingZhong,YangLiu,DaYin,YuningMao,YizhuJiao,PengfeiLiu,ChenguangZhu,HengJi,andJiaweiHan.2022.Towardsaunifiedmulti-dimensionalevaluatorfortextgeneration.ASplittingSummEvalandtheSelectionofIn-contextExamplesWerandomlyselect4articlesfromtheSummEvaldatasetandpickonesystem-generatedsummaryfromeacharticleasanin-contextexampleusingtheproceduresoutlinedinSection2.3.Inotherwords,wepickn=4inFigure1.Foragivenvalueofn,promptsforevaluatingconsistencyarethelongestsincetheycontainentiresourcearticles.Wepicknsuchthatconsistencypromptsfitwithinthecontextwindowofthemodel.WestudytheeffectofthechoiceofninSection4.3.Toensurethatthereisnooverlapinthesourcearticleofanyin-contextexamplewiththesourcear-ticleofanytestexample,weremoveallsummariescorrespondingtothe4selectedsourcetextsandusetheremaining1536examplesfromSummEvalasourtestset.WeensuretheabsenceofoverlapthroughoutallexperimentsinSections3,4,and5.BSamplingProceduresB.0.1UniformRandomSamplingOnesummaryispickeduniformlyatrandomfromthesetof16summariesforagivensourcetext.Wedothisforeachofthe4sourcetextsselectedtopickin-contextexamplesfrom.Eachofthe4sampledin-contextexamplesthenconsistsoftheselectedsummary,itshumanevaluationscoreonthecurrentaspectofinterest,and(optionally)thesourcetextorthereferencetext.B.0.2StratifiedSamplingLetAdenotethescoreofasummaryontheaspectweareevaluatingfor;thenA\u2208[0,1].Instrati-fiedsampling,wedefine4bucketsbytheranges{[0,0.25],(0.25,0.5],(0.5,0.75],(0.75,1.0]}.Weassignsummarystooneofthebucketsdepend-ingonthevalueofAs.Wedothisforeachofthe64in-contextexamplecandidatesummaries.Fi-nally,wepick4summariesfromthe64candidatessuchthateachsummaryfallsintoadifferentbucketandalsocomesfromadifferentsourcetext.Weperformanexhaustivesearchforsuchanassign-ment,andincasenosuchassignmentispossible(thiscanhappenifnoneofthe64summariesfallinagivenbucket),wepickanarbitrarysummaryfromarandomlyselectedbucket,ensuringthatall4summariescomefromdifferentsourcearticles.Forbothuniformandrandomsampling,ween-surethateachsummarycorrespondstoadifferentsourcearticle.CAnnotationProcedureforRatingGPT-3,BRIO,andT0SummariesSummariesareannotatedonascaleof{1,2,3,4,5}forcoherence,consistency,fluency,andrelevanceusingtheannotationinstructionsfromFabbrietal.(2020).DUseofExistingEvaluationPackagesWeuseexistingpackagesforallourbaselines\u2013ROUGE,BARTScore,CTC,andUniEval.ForROUGE,weusethenativepythonimplementationandreportROUGE-LscoresforourexperimentinSection5.ForBARTScore,weusetheimplemen-tationaccompanyingthepaperwiththesourcetohypothesissettingacrossalldimensions,asthatgivesthebestcorrelationswithhumanjudgmentsacrossdimensions.ForUniEval,weusepre-trainedmodelreleasedbytheauthorstoobtainresultsinTable1onthetestsetofsize1536.ESignificanceTestsSinceICEscoresforsomedimensionsareclosetoUniEvalscores,weperformpairwiseteststodeterminewhenonemethodisbetterthantheother.Concretely,wecompareperformanceon1000boot-strapsamplesbyrandomlyselecting80%ofthetestsetforeachsample.WeobservethatwhenusingKendall\u2019sTau,ICEwithuniformsamplingoutper-formsUniEvalwithasignificancelevelof0.05onbothconsistencyandrelevance.WhenusingSpearman\u2019srankcorrelation,IceagainoutperformsUniEvalonconsistency,butthetestisinconclu-siveatthatsignificancelevelforrelevance.\n8493\n\n\nACL2023ResponsibleNLPChecklist\nTheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.\nAForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Limitationssectionattheend(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Inthelimitationssection,wediscusstherisksassociatedwithrelyingonexternaldependenciesindeployingaframeworksuchastheonestudiedinourwork,ifoneintendstobuildareal-worldapplicationaroundit.(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper\u2019smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescienti\ufb01cartifacts?Wegenerateratingsofsystem-generatedsummariesonthebasisofquality(cid:3)B1.Didyoucitethecreatorsofartifactsyouused?Notapplicable.Wecreatedtheartifacts(cid:3)B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Notapplicable.Wehavenot,atthemoment,decidedonthetermofdistributionofourhuman-annotateddata(cid:3)B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeci\ufb01ed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Notapplicable.Theartifactswecreatearebuiltontopofpubliclyavailabledatasetsofpubliclyavailablenewsarticles,whichdonotconstitutedataaccessedsolelyforresearchpurposes(cid:3)B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidenti\ufb01esindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Notapplicable.Wedonotcollectanynewdata.ThedataweuseconsistsofCNNarticles.(cid:3)B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?Notapplicable.Ourartifactsareratingsofsystemgeneratedsummariesfromnewsarticles.Wementionthisintherelevantsection\u2013Section5.(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigni\ufb01cant,whileonsmalltestsetstheymaynotbe.WementionthesestatisticsforallourexperimentsinSections3,4,and5.\n8494\n\n\nC(cid:3)3Didyouruncomputationalexperiments?AlmostallsectionsotherthanIntroductiondescribecomputationalexperiments(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?WementioninthepaperthatourbackboneisGPT-3.Wementionitsnumberofparametersinthelimitationssection.(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Mostofthe\"hyperparamters\"forourframeworkarepromptengineeringchoices,whichwediscussextensivelyinSections4and5.WementionrelevantparametersofourGPTbackbone(suchassamplingtemperature)inSection3(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Anumberofouranalysesaredoneonsamplesofthebenchmarkdatasets,andwehavedescribedwhereandhowwearesettingupandreportingmultipleruns.Wehaveaddedsigni\ufb01canceteststovalidateresults,wherenecessary.(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?AppendixDD(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section5(cid:3)D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Notapplicable.WeusepreciselythesameinstructionsasusedtoannotateSummEval,ourbenchmarkmeta-evaluationdataset.Wehighlightthemainpointsoftheinstructionsinourpaperbutredirectreaderstotheoriginalpaperforthefulltext(cid:3)D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants\u2019demographic(e.g.,countryofresidence)?Notapplicable.Weperformedtherelevantannotations(cid:3)D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou\u2019reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Notapplicable.Weannotatesystem-generatedsummariesofpublicallyavailablenews(CNN)articlesforquality.Wedonotuse/curateanyindividual\u2019spersonaldata.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Leftblank.(cid:3)D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Notapplicable.Thesourceofthedataisnewsarticles.Forourstudy,weannotatesystem-generatedsummariesofsucharticlesforquality\n8495"}