{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Exploration_on_HuBERT_with_Multiple_Resolutions_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the name of the widely-used self-supervised learning model in speech processing mentioned in the text?,        answer: Hidden-unit BERT (HuBERT)    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " Why do the authors argue that the fixed 20ms resolution of hidden representations in HuBERT may not be optimal for various speech-processing tasks?,        answer: Different speech-processing tasks may have attributes based on different time scales such as speaker characteristics and semantics.    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What are the two approaches explored for integrating HuBERT features with multiple resolutions?,        answer: The parallel approach and the hierarchical approach    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What is the purpose of HuBERT with multiple resolutions as highlighted in the text?,        answer: To capture diverse information from speech signals    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What are the two mainstream approaches that have emerged in speech recognition according to the text?,        answer: The parallel processing approach and the hierarchical approach    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " How does the second hierarchical approach differ from the parallel approach in the text?,        answer: It serializes the aggregation of multi-resolution information    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What is the purpose of using HuBERT representations at different resolutions for downstream speech tasks as proposed in the text?,        answer: To efficiently utilize HuBERT of different resolutions    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " In the feature extraction approach mentioned in the text, how is the pre-trained HuBERT model used?,        answer: To extract high-level features from speech signals    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What is the role of the conv. feature extractor in the HuBERT model mentioned in the text?,        answer: It converts the raw waveform into hidden states    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}, {"question": " What do the authors demonstrate through experiments regarding HuBERT with multiple resolutions?,        answer: It outperforms the original model    ", "ref_chunk": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}], "doc_text": "3 2 0 2 n u J 2 2 ] D S . s c [ 2 v 4 8 0 1 0 . 6 0 3 2 : v i X r a Exploration on HuBERT with Multiple Resolutions Jiatong Shi1, Yun Tang2, Hirofumi Inaguma2, Hongyu Gong2, Juan Pino2, Shinji Watanabe1 1Language Technologies Institute, Carnegie Mellon University 2Meta AI {jiatongs, swatanab}@cs.cmu.edu Abstract Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we pro- pose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outper- forms the original model. This highlights the potential of utiliz- ing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals. Index Terms: speech self-supervised learning, multi-resolution HuBERT, Hidden-unit BERT. tion raises concerns regarding its optimality for diverse speech- related tasks.1 In contrast, the literature also suggests that mod- eling speech at multiple resolutions is preferable for speech recognition [8\u201316], speaker verification [17\u201319], speech en- hancement [20, 21], and voice conversion [22]. Two main- stream approaches have emerged: one that focuses on parallel processing [8\u201314, 17], and the other that utilizes hierarchical frameworks such as U-net [18, 21\u201326]. The parallel paradigm is based on observations of multi- ple parallel processing streams in the human speech cognitive system [8, 9]. To formalize multi-stream signals, a common method is to use parallel encoders that consider multi-resolution signals. For example, [13] employs two encoders based on re- current neural network (RNN) and convolution neural network (CNN)-RNN, respectively. Both encoders use the same input features, while the second applies CNN to transform features into a different temporal resolution. 1. Introduction In recent years, self-supervised learning (SSL) models for speech processing have demonstrated impressive performance on a range of tasks [1]. These models can leverage unlabeled speech data to learn general-purpose knowledge, rather than re- lying solely on supervised training with paired labels. As a re- sult, speech SSLs have emerged as a powerful tool for speech processing, offering a promising alternative to traditional super- vised learning approaches. HuBERT [2] is one of the most prominent speech self- supervised learning (SSL) models, according to the SUPERB benchmark [3\u20135]. During training, HuBERT employs an offline clustering step to generate pseudo labels and uses a masked lan- guage model (MLM) objective. Like many speech processing systems, HuBERT begins by converting the raw waveform into hidden states using convolutional (conv.) layers, resulting in a fixed 20ms resolution for its representation. The second hierarchical approach, in contrast, serializes the aggregation of multi-resolution information. An example of this approach is the U-net-like architecture, which is based on an encoder-decoder structure [15, 16, 18, 21, 22]. The en- coder processes high-resolution features initially and downsam- ples them to prioritize low-resolution features. Conversely, the decoder starts from low-resolution features and upsamples them to refine information in high resolution. To ensure stability, cor- responding blocks with the same resolution in the encoder and decoder are connected with residual connections. In this work, we propose using HuBERT representations at different resolutions (HuBERT-MR) for downstream speech tasks. In our experiments, we evaluate both the parallel and the hierarchical approaches to efficiently utilize HuBERT of different resolutions. Experiments show that our proposed method could get significantly better performances over the original HuBERT at 20ms resolution. In some tasks, the Hu- BERT with multi-resolution can even achieve reasonable per- formances compared to large models, even with less training data and fewer parameters. HuBERT can be used as a feature extractor or directly fine- tuned as an encoder. In the feature extraction approach, the pre-trained model is used to extract high-level features from speech signals, which are then fed into a downstream task- specific model such as a classifier or a regression model. This approach reduces the computational cost during training [6, 7]. On the other hand, fine-tuning the pre-trained HuBERT model as an encoder is a popular approach, which further improves the performance at the cost of training massive encoder param- eters. In this approach, the pre-trained model is further trained on the downstream task data, either by updating all the model parameters or just the last few layers. 2. HuBERT with Multiple Resolutions Let S \u2208 R1\u00d7L be a speech signal with length L. The HuBERT model H consists of two modules: a conv. feature extractor and an N -layer transformer encoder. The conv. block first con- T ] \u2208 RT \u00d7D, verts S into a sequence of vectors X 0 = [x0 where T is the number of frames and D is the dimension of each frame. The resulting feature sequence X 0 is then passed to the transformer encoder, which produces a sequence of feature rep- 1, ..., x0 Although the HuBERT representation has demonstrated strong performance, the empirical selection of a 20ms resolu- 1It\u2019s worth noting that this choice of resolution is derived from an ASR conversion involving downsampling, which is specific to that par- ticular task. ParallelHuBERT-MR Fusion SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HierarchicalHuBERT-MR Fusion Fusion HuBERT HuBERT HuBERT SpeechSignalsH1<latexit sha1_base64=\"SJ5pfPHjmpDnUQ6ZcoW/1R7XTXE=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRY0dZCG8pmu2mXbjZhdyKU0J/gxYMiXv1F3vw3btsctPXBwOO9GWbmBYkUBl332ylsbG5t7xR3S3v7B4dH5eOTjolTzXibxTLW3YAaLoXibRQoeTfRnEaB5I/B5HbuPz5xbUSsHnCacD+iIyVCwSha6b458Ablilt1FyDrxMtJBXK0BuWv/jBmacQVMkmN6Xlugn5GNQom+azUTw1PKJvQEe9ZqmjEjZ8tTp2RC6sMSRhrWwrJQv09kdHImGkU2M6I4tisenPxP6+XYnjtZ0IlKXLFlovCVBKMyfxvMhSaM5RTSyjTwt5K2JhqytCmU7IheKsvr5NOrerVqzd39UqjlsdRhDM4h0vw4Aoa0IQWtIHBCJ7hFd4c6bw4787HsrXg5DOn8AfO5w/BkY1s</latexit> HuBERT HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> HuBERT DownstreamModelH2<latexit sha1_base64=\"o7oRonGwcNoBP8OJg5qhPQN/4w0=\">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lKQb0VvPRYwX5AG8pmu22X7m7C7kQooX/BiwdFvPqHvPlvTNoctPXBwOO9GWbmBZEUFl332ylsbe/s7hX3SweHR8cn5dOzjg1jw3ibhTI0vYBaLoXmbRQoeS8ynKpA8m4wu8/87hM3VoT6EecR9xWdaDEWjGImNYe10rBccavuEmSTeDmpQI7WsPw1GIUsVlwjk9TavudG6CfUoGCSL0qD2PKIshmd8H5KNVXc+sny1gW5SpURGYcmLY1kqf6eSKiydq6CtFNRnNp1LxP/8/oxjm/9ROgoRq7ZatE4lgRDkj1ORsJwhnKeEsqMSG8lbEoNZZjGk4Xgrb+8STq1qlev3j3UK41aHkcRLuASrsGDG2hAE1rQBgZTeIZXeHOU8+K8Ox+r1oKTz5zDHzifP/f+jYE=</latexit>H3<latexit sha1_base64=\"7740bN0fxfI+/KsB8Magnc8ZB7E=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKezGgHoLeMkxonlAsoTZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5Pb2Nza3snvFvb2Dw6PiscnLR0limGTRSJSnYBqFFxi03AjsBMrpGEgsB1M7uZ++wmV5pF8NNMY/ZCOJB9yRo2VHur9q36x5JbdBcg68TJSggyNfvGrN4hYEqI0TFCtu54bGz+lynAmcFboJRpjyiZ0hF1LJQ1R++ni1Bm5sMqADCNlSxqyUH9PpDTUehoGtjOkZqxXvbn4n9dNzPDGT7mME4OSLRcNE0FMROZ/kwFXyIyYWkKZ4vZWwsZUUWZsOgUbgrf68jppVcpetXx7Xy3VKlkceTiDc7gED66hBnVoQBMYjOAZXuHNEc6L8+58LFtzTjZzCn/gfP4AxJmNbg==</latexit> Figure 1: HuBERT-MR-P and HuBERT-MR-H. In HuBERT- MR-P (shown in the upper figure), three HuBERT models are fused in parallel. In contrast, HuBERT-MR-H (shown in the lower figure) fuses HuBERT models hierarchically, with fea- tures of low resolutions being fused earlier. Details about the framework design and Fusion modules can be found in Sec- tion 2.1 and Section 2.2, respectively. T ] \u2208 RT \u00d7D at the i-th transformer 1, ..., xi resentations X i = [xi layer. Each frame xi t corresponds to a fixed time interval R, where R \u00b7 T = L.2 We refer to R"}