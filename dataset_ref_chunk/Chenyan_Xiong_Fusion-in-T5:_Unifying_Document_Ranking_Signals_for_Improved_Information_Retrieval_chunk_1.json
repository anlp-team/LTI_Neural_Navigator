{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Chenyan_Xiong_Fusion-in-T5:_Unifying_Document_Ranking_Signals_for_Improved_Information_Retrieval_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the name of the re-ranker proposed in the paper?", "answer": " Fusion-in-T5 (FiT5)", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " Which institutions are the authors affiliated with in China?", "answer": " Tsinghua University and Beijing National Research Center for Information Science and Technology", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " What is the main task of Information Retrieval (IR)?", "answer": " To retrieve a relevant set of documents from a large collection given a user query", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " What techniques are mentioned in the text to improve the ranking process?", "answer": " Using an extra pair/list-wise re-ranker or pseudo relevance feedback (PRF)", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " How does FiT5 integrate document text, retrieval features, and global document information?", "answer": " By using templated-based input and global attention", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " Why is Fusion-in-T5 (FiT5) designed to consolidate multiple IR features into a single learnable model?", "answer": " To rank documents within a unified framework", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " What type of models often serve as the foundation in cascade systems for information retrieval?", "answer": " Neural IR models", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " What does the global attention architecture in FiT5 enable the model to do?", "answer": " Better differentiate between similar documents and produce better ranking results", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " Which widely-used IR benchmarks were used to evaluate FiT5 in the experimental results?", "answer": " MS MARCO and TREC DL", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}, {"question": " What does FiT5 outperform on the MS MARCO dataset?", "answer": " Systems with more re-ranking stages and/or larger models", "ref_chunk": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}], "doc_text": "3 2 0 2 y a M 4 2 ] R I . s c [ 1 v 5 8 6 4 1 . 5 0 3 2 : v i X r a Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval Shi Yu1\u2217, Chenghao Fan2\u2217, Chenyan Xiong3, David Jin4, Zhiyuan Liu15, and Zhenghao Liu6 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China 2School of Comp. Sci., Huazhong University of Science and Technology, Wuhan, China 3Microsoft Research, Redmond, USA 4MIT, Cambridge, USA 5Beijing National Research Center for Information Science and Technology, Beijing, China 6Dept. of Comp. Sci. & Tech., Northeastern University, Shenyang, China Abstract Common IR pipelines are typically cascade sys- tems that may involve multiple rankers and/or fusion models to integrate different informa- tion step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document in- formation into a single unified model using templated-based input and global attention. Ex- periments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 sig- nificantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detec- tion of subtle nuances between them. Our code will be open-sourced. 1 Introduction Information retrieval (IR) aims to retrieve a relevant set of documents from a large collection, given a user query (Croft et al., 2010). The task poses chal- lenges for researchers to build models that are able to process vast amounts of information in response to a single input query. an extra pair/list-wise re-ranker (Nogueira et al., 2019; Zhang et al., 2022), or using pseudo rele- vance feedback (PRF) to expand the query with potentially relevant document information (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023). These techniques ultimately transform the ranking pro- cess into a task that demands careful engineering in order to achieve optimal performance. In this paper, we introduce Fusion-in-T5 (FiT5), a T5-based (Raffel et al., 2020) re-ranking model that collects ranking signals and ranks documents within a unified framework. FiT5 is designed to consolidate multiple IR features, including doc- ument texts, ranking features, and global docu- ment information, into a single learnable model. Specifically, the input to FiT5 is formulated us- ing a template that incorporates the document text with the ranking feature, which is represented as discretized integers. Additionally, to leverage infor- mation from other documents, we introduce global attention on the representation token from the late layers of FiT5 encoders, enabling document-wise information flow during encoding while mitigating the increase in computational cost. FiT5 functions as a re-ranking model within a typical two-stage retrieve-and-rerank pipeline, without the need for additional stages or hyperparameters. The information-rich nature of IR motivates researchers to construct intricate, cascade sys- tems (Yates et al., 2021; Zhang et al., 2021; Dai et al., 2018). Neural IR models often serve as the foundation of such systems, directly capturing text relevance in a coarse-to-fine approach (Yates et al., 2021; Nogueira et al., 2019; Pradeep et al., 2021). To capture ranking features observed from the data or the rankers, a learning-to-rank (LeToR) mod- ule is often applied (Zhang et al., 2020; Sun et al., 2021; Zhang et al., 2021, 2022; Dai et al., 2018). Further approaches are introduced to incorporate global information from the documents at the cost of an additional ranking stage, such as designing Experimental results on widely-used IR bench- marks, namely MS MARCO (Nguyen et al., 2016) and TREC DL 2019 (Craswell et al., 2020) & 2020 (Craswell et al., 2021), demonstrate that FiT5 exhibits substantial improvements over traditional retrieve-and-rerank pipelines. Furthermore, FiT5 outperforms systems with more re-ranking stages and/or larger models on the MS MARCO dataset. Further analysis reveals that FiT5 effectively lever- ages ranking features through its global attention architecture, enabling the model to better differ- entiate between similar documents and ultimately produce better ranking results. \u2217Equal contribution. Figure 1: Architecture of Fusion-in-T5. The query, document, and ranking feature are filled in the input template to form the input. We use retrieval score as the ranking feature. 2 Related Work IR Pipelines Recent IR pipelines are often cascade systems consisting of a retriever and one/multiple re-ranker(s) (Yates et al., 2021). The simplest form of a re-ranker is a pre-trained lan- guage model (PLM)-based model, which takes a pair of (query, document) texts as input and outputs a relevance score, e.g. BERT Re-ranker (Nogueira and Cho, 2019) and monoT5 (Nogueira et al., 2020). Learning-to-rank (LeToR) models (Liu et al., 2009) are often used to learn a final rank- ing score based on a set of data or ranker fea- tures, such as linear models (Vogt and Cottrell, 1999; Metzler and Bruce Croft, 2007) and neural networks (Han et al., 2020; Burges et al., 2005; Zhang et al., 2022). To leverage features from other candidate documents, researchers have pro- posed pseudo relevance feedback (PRF) to expand the query (Zheng et al., 2020; Yu et al., 2021; Li et al., 2023), and pair/list-wise re-ranking models duoT5 (Pradeep et al., 2021) and HLATR (Zhang et al., 2022). Despite their effectiveness, these methods introduce an extra stage in ranking, which may bring an additional efficiency burden. Attention over Multiple Texts Our work leverages similar ideas from Fusion-in-Decoder (FiD) (Izacard and Grave, 2021) and Transformer- XH (Zhao et al., 2020) to incorporate global infor- mation. FiD adds a T5 decoder model on top of the independent T5 document encoders to fuse all the text evidences through the decoder-encoder atten- tion and generate the answer for open-domain QA. Transformer-XH builds eXtra Hop attention across the text evidences inside the BERT layers to model the structure of texts for multi-hop QA. In this pa- per, we integrate the similar attention mechanism into the T5 encoder and build a fully-connected at- tention graph to model all the mutual relationships between candidate documents. 3 Methodology 3.1 Overview FiT5"}