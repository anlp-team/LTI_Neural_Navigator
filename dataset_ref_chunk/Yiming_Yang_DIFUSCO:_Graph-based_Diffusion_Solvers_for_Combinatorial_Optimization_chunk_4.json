{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Yiming_Yang_DIFUSCO:_Graph-based_Diffusion_Solvers_for_Combinatorial_Optimization_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are the initial values for ij and h0 in the text?", "answer": " ij are initialized as zeros, and h0 features of the nodes.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What does the 2-neuron and 1-neuron classification/regression head do to the final embeddings of xt?", "answer": " A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt for discrete and continuous diffusion models, respectively.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What hyper-parameters are used for all TSP and MIS benchmarks?", "answer": " For all TSP and MIS benchmarks, a 12-layer Anisotropic GNN with a width of 256 is used.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What specialized decoding strategies are designed for the two CO problems studied in the paper?", "answer": " Specialized decoding strategies are designed for the two CO problems studied in the paper to ensure feasible solutions.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " How are heatmaps generated in the text?", "answer": " The diffusion models are adapted to generate heatmaps by making appropriate modifications.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What method is used to evaluate the heatmap scores for TSP decoding according to the text?", "answer": " Greedy decoding and Monte Carlo Tree Search (MCTS) are used to evaluate the heatmap scores for TSP decoding.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What decoding strategy is used for the MIS problem?", "answer": " A greedy decoding strategy is used for the MIS problem.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What is the common practice for probabilistic CO solvers mentioned in the text?", "answer": " A common practice for probabilistic CO solvers is to sample multiple solutions and report the best one.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What is the main benchmark used to compare different model configurations in the text?", "answer": " TSP-50 instances are used as the main benchmark to compare different model configurations.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}, {"question": " What are the three evaluation metrics presented in the text to compare the performance of different models?", "answer": " The three evaluation metrics presented are average tour length, average relative performance gap, and total run time.", "ref_chunk": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}], "doc_text": "ij are initialized as zeros, and h0 features of the nodes. For MIS, e0 i are initialized as the corresponding values in xt. A 2-neuron and 1-neuron classification/regression head is applied to the final embeddings of xt ({eij} for edges and {hi} for nodes) for discrete and continuous diffusion models, respectively. Hyper-parameters For all TSP and MIS benchmarks, we use a 12-layer Anisotropic GNN with a width of 256 as described above. 3.5 Decoding Strategies for Diffusion-based Solvers After the training of the parameterized denoising network according to Eq. 4, the solutions are sampled from the diffusion models p\u03b8(x0|s) for final evaluation. However, probabilistic generative models such as DIFUSCO cannot guarantee that the sampled solutions are feasible according to the definition of CO problems. Therefore, specialized decoding strategies are designed for the two CO problems studied in this paper. 5 Heatmap Generation The diffusion models p\u03b8(\u00b7|s) produce discrete variables x as the final pre- dictions by applying Bernoulli sampling (Eq. 6) for discrete diffusion or quantization for continuous diffusion. However, this process discards the comparative information that reflects the confidence of the predicted variables, which is crucial for resolving conflicts in the decoding process. To preserve this information, we adapt the diffusion models to generate heatmaps [53, 92] by making the following appropriate modifications: 1) For discrete diffusion, the final score of p\u03b8(x0 = 1|s) is preserved as the heatmap scores; 2) For continuous diffusion, we remove the final quantization and use 0.5(\u02c6x0 + 1) as the heatmap scores. Note that different from previous heatmap approaches [53, 92] that produce a single conditionally independent distribution for all variables, DIFUSCO can produce diverse multimodal output distribution by using different random seeds. TSP Decoding Let {Aij} be the heatmap scores generated by DIFUSCO denoting the confidence of each edge. We evaluate two approaches as the decoding method following previous work [32, 92]: 1) Greedy decoding [32], where all the edges are ranked by (Aij + Aji)/\u2225ci \u2212 cj\u2225, and are inserted into the partial solution if there are no conflicts. 2-opt heuristics [71] are optionally applied. 2) Monte Carlo Tree Search (MCTS) [27], where k-opt transformation actions are sampled guided by the heatmap scores to improve the current solutions. Due to the space limit, a detailed description of two decoding strategies can be found in the appendix. MIS Decoding Let {ai} be the heatmap scores generated by DIFUSCO denoting the confidence of each node. A greedy decoding strategy is used for the MIS problem, where the nodes are ranked by ai and inserted into the partial solution if there are no conflicts. Recent research [8] pointed out that the graph reduction and 2-opt search [2] can find near-optimal solutions even starting from a randomly generated solution, so we do not use any post-processing for the greedy-decoded solutions. Solution Sampling A common practice for probabilistic CO solvers [64] is to sample multiple solutions and report the best one. For DIFUSCO, we follow this practice by sampling multiple heatmaps from p\u03b8(x0|s) with different random seeds and then applying the greedy decoding algorithm described above to each heatmap. 4 Experiments with TSP We use 2-D Euclidean TSP instances to test our models. We generate these instances by randomly sampling nodes from a uniform distribution over the unit square. We use TSP-50 (with 50 nodes) as the main benchmark to compare different model configurations. We also evaluate our method on larger TSP instances with 100, 500, 1000, and 10000 nodes to demonstrate its scalability and performance against other state-of-the-art methods. 4.1 Experimental Settings Datasets We generate and label the training instances using the Concorde exact solver [3] for TSP-50/100 and the LKH-3 heuristic solver [39] for TSP-500/1000/10000. We use the same test instances as [54, 64] for TSP-50/100 and [27] for TSP-500/1000/10000. Graph Sparsification We use sparse graphs for large-scale TSP problems to reduce the computa- tional complexity. We sparsify the graphs by limiting each node to have only k edges to its nearest neighbors based on the Euclidean distances. We set k to 50 for TSP-500 and 100 for TSP-1000/10000. This way, we avoid the quadratic growth of edges in dense graphs as the number of nodes increases. Model Settings T = 1000 denoising steps are used for the training of DIFUSCO on all datasets. Following Ho et al. [40], Graikos et al. [32], we use a simple linear noise schedule for {\u03b2t}T t=1, where \u03b21 = 10\u22124 and \u03b2T = 0.02. We follow Graikos et al. [32] and use the Greedy decoding + 2-opt scheme (Sec. 3.5) as the default decoding scheme for experiments. Evaluation Metrics In order to compare the performance of different models, we present three metrics: average tour length (Length), average relative performance gap (Gap), and total run time (Time). The detailed description can be found in the appendix. 6 Table 1: Comparing results on TSP-50 and TSP-100. \u2217 denotes the baseline for computing the performance gap. \u2020 indicates that the diffusion model samples a single solution as its greedy decoding scheme. Please refer to Sec. 4 for details. ALGORITHM TYPE TSP-50 TSP-100 LENGTH\u2193 GAP(%)\u2193 LENGTH \u2193 GAP(%)\u2193 CONCORDE 2-OPT \u2217 EXACT HEURISTICS 5.69 5.86 0.00 2.95 7.76 8.03 0.00 3.54 AM GCN TRANSFORMER POMO SYM-NCO DPDP IMAGE DIFFUSION OURS GREEDY GREEDY GREEDY GREEDY GREEDY 1k-IMPROVEMENTS GREEDY GREEDY \u2020 \u2020 5.80 5.87 5.71 5.73 - 5.70 5.76 5.70 1.76 3.10 0.31 0.64 - 0.14 1.23 0.10 8.12 8.41 7.88 7.84 7.84 7.89 7.92 7.78 4.53 8.38 1.42 1.07 0.94 1.62 2.11 0.24 Figure 1: Comparison of continu- ous (Gaussian noise) and discrete (Bernoulli noise) diffusion models with different inference diffusion steps and inference schedule (linear v.s. cosine). AM GCN TRANSFORMER POMO SYM-NCO MDAM DPDP OURS 1k\u00d7SAMPLING 2k\u00d7SAMPLING 2k\u00d7SAMPLING 8\u00d7AUGMENT 100\u00d7SAMPLING 50\u00d7SAMPLING 100k-IMPROVEMENTS 16\u00d7SAMPLING 5.73 5.70 5.69 5.69 - 5.70 5.70 5.69 0.52 0.01 0.00 0.03 - 0.03 0.00 -0.01 7.94 7.87 7.76 7.77 7.79 7.79 7.77 7.76 2.26 1.39 0.39 0.14 0.39 0.38 0.00 -0.01 (b) Discrete diffusion Figure 2: The performance Gap (%) are shown for continuous diffusion (a) and"}