{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Daniel_Fried_Grounding_Language_Models_to_Images_for_Multimodal_Generation_chunk_7.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What limitation did the authors find in the FROMAGe model in terms of generating relevant images?", "answer": " The ability of FROMAGe to produce relevant images was sometimes limited by its candidate retrieval set.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " Why do retrieval models like FROMAGe and CLIP struggle to produce relevant images for prompts that are less likely to occur in natural images?", "answer": " They struggle for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " What is a current limitation of the FROMAGe model during inference?", "answer": " It does not always generate [RET] during inference and has a stronger bias to produce regular text tokens.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " How can the issue of FROMAGe not generating [RET] during inference be somewhat alleviated?", "answer": " It can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifically prompting the model to show images.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " What is suggested as a promising direction for future work to enable FROMAGe to generate [RET] more naturally?", "answer": " Instruction finetuning on multimodal dialogue examples or training on explicitly interleaved image-text examples.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " What institutions partially supported the work described in the text?", "answer": " Google on Action, Task, and User Journey Modeling; ONR N000142312368; DARPA/AFRL FA87502321015.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " Who was acknowledged for their help with the figures in the text?", "answer": " Wendy Kua.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " What did the authors thank Felix Hill for in the text?", "answer": " Insightful discussions about Frozen.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " Which paper discusses the dangers of language models being too big?", "answer": " Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}, {"question": " What is the title of the paper by Banerjee and Lavie discussing an automatic metric for MT evaluation?", "answer": " METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.", "ref_chunk": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}], "doc_text": "to perform novel image generation in addition to image re- trieval is a natural way to improve its practical capabilities. In our qualitative experiments, we found that the ability of FROMAGe to produce relevant images was sometimes lim- ited by its candidate retrieval set. This is often the case for prompts that are less likely to occur in natural images, such as fantastical prompts used for benchmarking text-to-image generation models (Yu et al., 2022a). On such examples, we find that FROMAGe (and other retrieval models, such as CLIP) often do not produce relevant images. Developing a model that can both generate text and novel images is an open direction which will likely require further architectural improvements. Another current limitation of FROMAGe is that it does not always generate [RET] during inference, and generally has a stronger bias to produce regular text tokens. This is likely due to its extensive pretraining on text-only data. During inference, we find that this can be somewhat alleviated by scaling the [RET] logits by a factor 1.3 \u2212 1.5, prompting with in-context examples, or specifi- cally prompting the model to ask it to show images, which we found helpful in producing good qualitative results. In- vestigating ways to enable FROMAGe to generate [RET] more naturally is also a promising direction for future work. This may entail instruction finetuning (Wei et al., 2021) on multimodal dialogue examples, or training on explicitly interleaved image-text examples (Alayrac et al., 2022). This work was partially supported by a gift from Google on Action, Task, and User Journey Modeling, and sup- ported in part by ONR N000142312368 and DARPA/AFRL FA87502321015. We thank Wendy Kua for help with the figures, and Santiago Cort\u00b4es, Paul Liang, Martin Ma, So Yeon Min, Brandon Trabucco, Saujas Vaduguru, and others for feedback on previous versions of this paper. We thank Felix Hill for insightful discussions about Frozen. 9 Grounding Language Models to Images for Multimodal Inputs and Outputs References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond a fixed-length context. ACL, 2019. Aghajanyan, A., Huang, B., Ross, C., Karpukhin, V., Xu, H., Goyal, N., Okhonko, D., Joshi, M., Ghosh, G., Lewis, M., et al. Cm3: A causal masked multimodal model of the internet. arXiv preprint arXiv:2201.07520, 2022. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D. Visual dialog. In CVPR, 2017. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., et al. Flamingo: a visual language model for few-shot learning. NeurIPS, 2022. Banerjee, S. and Lavie, A. METEOR: An automatic metric for MT evaluation with improved correlation with human In Proceedings of the ACL Workshop on judgments. Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005. Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, pp. 610\u2013623, 2021. Birhane, A., Prabhu, V. U., and Kahembwe, E. Multimodal datasets: misogyny, pornography, and malignant stereo- types. arXiv preprint arXiv:2110.01963, 2021. Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosse- lut, A., Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. NeurIPS, 2020. Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. NeurIPS, 2022. Ding, M., Zheng, W., Hong, W., and Tang, J. Cogview2: Faster and better text-to-image generation via hierarchical transformers. arXiv preprint arXiv:2204.14217, 2022. Eichenberg, C., Black, S., Weinbach, S., Parcalabescu, L., and Frank, A. Magma\u2013multimodal augmentation of gen- erative models through adapter-based finetuning. EMNLP, 2022. Esser, P., Rombach, R., and Ommer, B. Taming transformers for high-resolution image synthesis. In CVPR, 2021. Gehman, S., Gururangan, S., Sap, M., Choi, Y., and Smith, N. A. Realtoxicityprompts: Evaluating neural toxic de- generation in language models. EMNLP, 2020. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. NeurIPS, 2022. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. ICLR, 2020. Chan, S. C., Santoro, A., Lampinen, A. K., Wang, J. X., Singh, A., Richemond, P. H., McClelland, J., and Hill, F. Data distributional properties drive emergent few-shot learning in transformers. NeurIPS, 2022. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. Parameter-efficient transfer learning for nlp. In ICML, 2019. Chopra, S., Hadsell, R., and LeCun, Y. Learning a sim- ilarity metric discriminatively, with application to face verification. In CVPR, 2005. Huang, T.-H., Ferraro, F., Mostafazadeh, N., Misra, I., Agrawal, A., Devlin, J., Girshick, R., He, X., Kohli, P., In NAACL-HLT, Batra, D., et al. Visual storytelling. 2016. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh,"}