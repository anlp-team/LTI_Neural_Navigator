{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of an RNN-T model?", "answer": " The purpose of an RNN-T model is to transform input speech frames into a high-level representation, and to model the sequence of non-blank labels that have been output previously.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " How does the prediction network in an RNN-T model generate output labels?", "answer": " The prediction network in an RNN-T model generates output labels by producing the previous non-blank label sequence.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " What is the role of the joint network in an RNN-T model?", "answer": " The joint network in an RNN-T model produces a probability distribution over the output symbols given the prediction network state and a specific encoded frame.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " How does an RNN-T model differ from a CTC model?", "answer": " An RNN-T model reduces some of the independence assumptions in CTC by making the output at a given time dependent on the sequence of previous non-blank predictions.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " How is the blank symbol interpreted in an RNN-T model?", "answer": " In an RNN-T model, the blank symbol represents the termination of a sequence of zero or more symbols in C for each input encoder frame.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " What does the set ARNNT(X,C) represent in an RNN-T model?", "answer": " The set ARNNT(X,C) in an RNN-T model represents all valid alignment sequences of T + L symbols in C\u2217b, which are identical to C after removing all blanks.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " What is the purpose of the recurrent neural aligner (RNA) model?", "answer": " The purpose of the recurrent neural aligner (RNA) model is to define a probability distribution over blank-augmented labels and to remove conditional independence assumptions from the RNN-T model.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " How do valid alignments differ between the RNN-T and RNA models?", "answer": " In the RNA model, valid alignments consist of length T sequences in C\u2217b with exactly T-L blank symbols and are identical to C after removing all blanks.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " What is the main difference between the prediction network state in an RNN-T model and an RNA model?", "answer": " The prediction network state in an RNN-T model depends on the previously output non-blank labels, while in an RNA model, it depends on the entire alignment sequence.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}, {"question": " How does the RNA model differ from the RNN-T model in terms of label output per frame?", "answer": " The RNA model is only allowed to output a single label \u2013 either blank or non-blank \u2013 in a single frame, unlike the RNN-T model.", "ref_chunk": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}], "doc_text": "(cid:89) P (a\u03c4 |a\u03c4 \u22121, . . . , a1, H(X)) A\u2208ARNNT (X,C) \u03c4 =1 = (cid:88) T +L (cid:89) P (a\u03c4 |ci\u03c4 , ci\u03c4 \u22121, . . . , c0, h\u03c4 \u2212i\u03c4 ) Fig. 3. An RNN-T Model [14], [48] consists of an encoder which transforms the input speech frames into a high-level representation, and a prediction- network which models the sequence of non-blank labels that have been output previously. The prediction network output, pit , represents the output after producing the previous non-blank label sequence c1, . . . , cit . The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. = A\u2208ARNNT (X,C) (cid:88) A\u2208ARNNT (X,C) \u03c4 =1 T +L (cid:89) \u03c4 =1 P (a\u03c4 |pi\u03c4 , h\u03c4 \u2212i\u03c4 ) (3) Time s <sos> e <b> e <b> e <b> e s <b> where, P = (p1, \u00b7 \u00b7 \u00b7 , pL) represents the output of the predic- tion network depicted in Figure 3 which summarizes the se- quence of previously predicted non-blank labels, implemented as another neural network: pj = N N (\u00b7|c0, . . . , cj\u22121), where c0 is a special start-of-sentence label, \u27e8sos\u27e9. Thus, as can be seen in Eq. (2), RNN-T reduces some of the independence assumptions in CTC since the output at time t is conditionally dependent on the sequence of previous non-blank predictions, but is independent of the specific choice of alignment (i.e., the choice of the frames at which the non-blank tokens were emitted). Fig. 4. Example alignment sequence (right) for an RNN-T model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs. The FSA (left) represents the set of all valid RNN-T alignment paths. model [13], by removing some of the conditional indepen- dence assumptions that we discussed previously. The RNN- T model, which is depicted in Figure 3, is best understood by contrasting it against the CTC model. As with CTC, the RNN-T model augments the output symbols with the blank symbol, and thus defines a distribution over label sequences in Cb. Similarly, as with CTC, the model consists of an encoder which processes the input acoustic frames X to generate the encoded representation H(X) = (h1, \u00b7 \u00b7 \u00b7 , hT ). Unlike CTC, however, the blank symbol in RNN-T has a slightly different interpretation; for each input encoder frame, ht, the RNN-T model outputs a sequence of zero or more symbols in C which are terminated by a single blank symbol. Thus, we may define the set of all valid alignment se- quences in RNN-T as: ARNNT (X,C) = {A = (a1, a2, \u00b7 \u00b7 \u00b7 , aT +L)}, the set of all sequences of T + L symbols in C\u2217 b , which are identical to C after removing all blanks. Finally, for a given output position \u03c4 , let i\u03c4 denote the number of non- blank labels in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121). Thus, the number of blanks in the partial sequence (a1, \u00b7 \u00b7 \u00b7 , a\u03c4 \u22121) is \u03c4 \u2212 i\u03c4 \u2212 1. For example, if T = 7, and C = (s, e, e), Our presentation of RNN-T alignments considers the \u201ccanonical\u201d case. In principle, however, the model can encode the same set of conditional independence assumptions in RNN-T (i.e., the model structure), while considering alter- native alignment structures as in the work of [49]. In their work, Moritz et al., represent valid frame-level alignments as an arbitrary graph. This formulation, for example, allows for the use of \u201cCTC-like\u201d alignments in the RNN-T model (i.e., outputting a single label \u2013 blank, or non-blank \u2013 at each frame) while conditioning on the set of previous non-blank symbols as in the RNN-T model. 3) Recurrent Neural Aligner (RNA): The recurrent neural aligner (RNA) was proposed by Sak et al. [46]. The RNA model generalizes the RNN-T model by removing one of its conditional independence assumptions. The model, depicted in Figure 5, is best understood by considering how it differs from the RNN-T model. As with CTC and RNN-T, the RNA model defines a probability distribution over blank augmented labels in the set Cb, where \u27e8b\u27e9 has the same semantics as in the CTC model: at each frame the model can only output a single label \u2013 either blank, or non-blank \u2013 before advancing to the next frame; unlike CTC (but as in RNN- T) the model only outputs a single instance of each non- blank label. More specifically, the set of valid alignments, ARNA (X,C) = (a1, \u00b7 \u00b7 \u00b7 , aT ), in the RNA model consist of length T sequences in C\u2217 b with exactly T \u2212 L blank symbols, and which are identical to C after removing all blanks. Thus, the blank This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 Prediction Network Softmax Joint Network Encoder H(X) Fig. 5. An RNA Model [46] resembles the RNN-T model [14], [48] in terms of the model structure. However, this model is only permitted to output a single label \u2013 either blank, or non-blank \u2013 in a single frame. Unlike RNN-T, the prediction network state in the RNA model, qt\u22121, depends on the entire alignment sequence at\u22121, . . . , a1. The joint network produces a probability distribution over the output symbols (augmented with blank) given the prediction network state and a specific encoded frame. s e e Time <sos> e <b> <b> s e <b> <b> Fig. 6. Example alignment sequence (right) for an RNA model with the target sequence C = (s, e, e). Horizontal transitions in the image correspond to blank outputs;"}