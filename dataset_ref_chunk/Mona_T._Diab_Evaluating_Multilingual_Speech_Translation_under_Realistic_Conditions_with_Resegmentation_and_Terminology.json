{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Mona_T._Diab_Evaluating_Multilingual_Speech_Translation_under_Realistic_Conditions_with_Resegmentation_and_Terminology.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of the ACL60/60 evaluation sets?", "answer": " The ACL60/60 evaluation sets are designed for multilingual translation of ACL2022 technical presentations into 10 target languages to enable further research in the field of multilingual speech translation.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " How does the dataset enable research into multilingual speech translation under realistic conditions?", "answer": " The dataset provides unsegmented audio, domain-specific terminology, and diverse speaker demographics to evaluate and improve model robustness under realistic recording conditions.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " Why is translating technical presentations challenging?", "answer": " Translating technical presentations is challenging due to domain-specific terminology, recordings with background noise, diverse speaker demographics, and unsegmented speech typically lasting 10-60 minutes.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " How was the data curated for the ACL60/60 evaluation sets?", "answer": " The evaluation sets were curated from professionally transcribed and translated presentations at ACL2022 to balance speaker demographics, accents, and talk content while considering recording conditions.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " What is resegmentation in speech translation?", "answer": " Resegmentation involves dynamically segmenting the output using a given tokenization to minimize word error rate to a reference segmentation for downstream evaluation.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " What are some common evaluation metrics for transcription and translation quality?", "answer": " Common evaluation metrics include chrF, BLEU, COMET for translation quality, and WER for transcription quality, with TER also used for translation evaluation.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " How does post-editing impact translation quality?", "answer": " Post-editing can bias data towards the initial MT systems used for translations and influence metrics towards similar systems.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " Why is segmentation an important challenge in speech translation datasets?", "answer": " Segmentation is critical to ensure consistent translation across languages and provide necessary context for effective translation to the desired target languages.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " What are some limitations of the ACL60/60 evaluation sets?", "answer": " Limitations include potential bias towards MT systems used for initial translations, moderate size compared to other datasets, and the risk of overfitting to specific speakers or content.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}, {"question": " How does the ACL60/60 dataset contribute to the field of multilingual speech translation?", "answer": " The dataset provides a valuable resource for studying language processing in the technical domain and aims to offer a more realistic and representative measure for generalization in this area.", "ref_chunk": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}], "doc_text": "2https://aclanthology.org/2023.iwslt-1.2\nEvaluatingMultilingualSpeechTranslationUnderRealisticConditionswithResegmentationandTerminologyElizabethSaleskyJKareemDarwishAMohamedAl-BadrashinyAMonaDiabMJanNiehuesKJJohnsHopkinsUniversityAaiXplainMMetaAIKKarlsruheInstituteofTechnologyesalesky@jhu.eduAbstractWepresenttheACL60/60evaluationsetsformultilingualtranslationofACL2022technicalpresentationsinto10targetlanguages.Thisdatasetenablesfurtherresearchintomultilin-gualspeechtranslationunderrealisticrecord-ingconditionswithunsegmentedaudioanddomain-specificterminology,applyingNLPtoolstotextandspeechinthetechnicaldomain,andevaluatingandimprovingmodelrobustnesstodiversespeakerdemographics.1IntroductionTheNLPandspeechcommunitiesarerapidlyex-panding,whichhasmotivatedincreasedinterestinmultilingualscientificcommunicationandaccessi-bility.FromtheautomaticcaptioningatNAACL2019providedbyMicrosofttothecurrentACL60-60initiative1forthe60thanniversaryofACLat2022,itisclearthattranscriptionandtranslationinthetechnicaldomainisneeded,desired,andstilladisproportionatechallengeforcurrentmodelscomparedtostandarddatasetsinthesespaces.Translatingtechnicalpresentationspresentschal-lengingconditions,fromdomain-specificterminol-ogyandadaptation,torecordingsoftencapturedwithalaptopmicrophoneandlightbackgroundnoise,diversespeakerdemographicsaswellasunsegmentedspeechtypically10-60minutesinduration.WehavecuratedevaluationsetsfrompresentationsatACL2022whichhavebeenpro-fessionallytranscribedandtranslatedwiththesup-portofACLandthe60-60initiative.Inthispa-perwedescribethemethodologytocreatethisdataset,considerationsandmethodstoevaluatespeechtranslationmodelswithit,andopenchal-lengeswebelievethisdatasetmaysupportresearchtowards.Wereleasealldataandintermediatestepstosupportfurtherresearchinthisspace.\nFigure1:MultilingualtranslationofACLpresentations.WepresenttheACL60/60evaluationsetstoen-ablegreaterdevelopmentoftoolsbythefieldforthefield.Specifically,wehopethatthisdataen-ablesfurtherresearchintospeechtranslationandotherNLPapplicationsinthetechnicaldomainwithresegmentationandterminology,givenadi-versespeakersetandrealisticrecordingconditions,withthegoalofincreasedaccessibilityandmulti-linguality.OurdatasetispubliclyavailablethroughtheACLAnthology.22EvaluationunderrealisticconditionsToevaluatetranscriptionandtranslationunderreal-isticconditionsmayrequiredifferentmetricsthanwithe.g.providedsegmentation.Herewepresentthenecessarymetricsinordertodiscussthedatasetcreationprocess.2.1ResegmentationWhilemostofflinespeechtranslationmodelsaretrainedwithprovidedsegmentation,inanapplica-tionsettingsegmentationisunlikelytobeprovided.\n1https://www.2022.aclweb.org/dispecialinitiative\n62 Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 62\u201378 July 13-14, 2023 c(cid:13)2023 Association for Computational Linguistics\n\n\n3Weuseword-leveltokenizationforalllanguagesexceptJapaneseandChinesehere,whereweusecharacter-level.4https://taku910.github.io/mecab/5WecalculateTERwith--ter-normalizedandWecautionagainstusinganyonetranslationmetricinisolation,andsuggestchrFandCOMETasthestandardevaluationmetricsforthisdataset.3CreatingtheACL60/60evaluationsets3.1LanguagesAlldataisoriginallyspokeninEnglishandthentranscribedandtranslatedtotendiverselanguagesfromthe60/60initiativeforwhichpubliclyavail-ablespeechtranslationcorporaareavailable(seeTable5:\u00a7A.3):Arabic,MandarinChinese,Dutch,French,German,Japanese,Farsi,Portuguese,Rus-sian,andTurkish.Theresultingdatasetcontainsthree-wayparallel(speech,transcripts,transla-tions)one-to-manydatafortenlanguagepairs,andmulti-wayparalleltextdatafor100languagepairs.3.2DataselectionDatawasselectedfromtheACL2022paperpre-sentationsforwhichprecordedaudioorvideopre-sentationswereprovidedtotheACLAnthology.Talkswereselectedsuchthateachofthetwoevalu-ationsets,developmentandevaluation,wouldhaveapproximatelyonehourtotalduration.Oralpre-sentationswereadvisedtobeupto12minutesperrecording,resultingin5talksforeachsetwithrel-ativelybalanceddurationsof\u223c11.5minuteseach.Fromthe324availablerecordings,thefinal10wereselectedinordertobalancespeakerdemo-graphics,accents,andtalkcontent,whilelightlycontrollingforrecordingconditions.Themajor-ityofrecordingswerecreatedusinglaptopmicro-phonesinquietconditions,butbackgroundnoise,microphonefeedback,speechrateand/orvolumeinsomecasesaffectedunderstandingofthecontent.Weselectedtalkswithrepresentativebutminimalnoisewhereconditionsdidnotaffectunderstand-ingofthecontent.Weaimedforagenderbalancerepresentativeofconferenceparticipation,6result-ingina3:7female:malespeakerratio.Thisisalsoaglobalfieldwithawidevarietyofnativeandnon-nativeEnglishaccents,whichremainsanecessarychallengeforspeechmodelstoaddresstomitigateperformancebiases(Sanabriaetal.,2023;Fengetal.,2021;Koeneckeetal.,2020;TatmanandKasten,2017).Talkswerechosenandassignedtoeachsettomaximizeaccentdiversity,aimingforL1sfromallcontinentswithlanguagefamiliesfre-\nMostmodelsaretypicallyunabletomaintainout-putqualitygivenaudiooftypicaltalklengths(10+minutes),necessitatingtheuseofautomaticseg-mentationmethods.Inordertoevaluateoutputwithvariablesegmentation,resegmentationtoafixedreferenceisnecessary.ThestandardtoolwithinthefieldformanyyearshasbeenmwerSegmenter(Matusovetal.,2005),whichresegmentsmodeloutputtomatcharefer-encesegmentationfordownstreamevaluationwithvariousmetrics.Thisisdonebydynamicallyre-segmentingtheoutputusingagiventokenizationtominimizeworderrorratetothereference.3WeusemwerSegmenterforallscoresinthispaperandsuggestthatresegmentationbethescoringstandardfortheACL60/60dataset.2.2EvaluationmetricsWecompareavarietyofevaluationmetricstoana-lyzebothtranscriptionandtranslationqualityusingtheevaluationsets,aswellastheresultsofinterme-diatestepsincorpuscreationsuchaspost-editing.Fortranslation,wecomparechrF(Popovi\u00b4c,2015)whichistokenization-agnosticandmoreap-propriateforawiderarrayoftargetlanguagesthanBLEU;BLEU(Papinenietal.,2002)ascomputedbySACREBLEU(Post,2018);andthemodel-basedmetricCOMET(Reietal.,2020),whichoftenhashighercorrelationwithhumanjudge-ments(Mathuretal.,2020)thoughislimitedbylanguagecoverageinpretrainedmodels.ForBLEUweusethesuggestedlanguage-specifictokenizersinSACREBLEUforournon-spacedelimitedtar-getlanguages,Japanese(MeCab4)andChinese(character-level).Toanalyzebothautomaticandpost-editingtran-scriptionquality,weuseworderrorrate(WER).Wenotethatweusecase-sensitiveandpunctuation-sensitiveWERhereasthesearebothmaintainedinsystemoutputduringdatasetcreationinordertobepost-editedandtranslated.Fordownstreamevalua-tionofASRmodelqualityusingthefinaldataset,itmaybedesiredtocomputeWERwithoutcaseandwithoutpunctuation;ifso,thescoreswouldnotbedirectlycomparabletothosepresentedhere.Wealsousetranslationerrorrate(TER)(Snoveretal.,2006)toassesstheexpectedlevelofeditingnecessarytomatchthefinalreferencequality.5\n--ter-asian-supportinSACREBLEU.6AggregateconferenceparticipationstatisticsprovidedbyACL2022;see\u00a7A.2.\n63\n\n\n90Word count\n160Num. Segments\n50\n50\n250\n200\n120\n60\n60\n80\n80\n10\n10\n7https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-textbasedonpauses,speech,andnon-speechphenom-ena.Figure2showstheresultingdistributionofsegmentlengths.Evaluatingtheseinitialautomatictranscriptsagainstthefinalreleasedversionwithresegmentation(\u00a72.1),theautomatictranscriptionyieldedaWERof15.4and22.4forthedevelop-mentandevaluationsets,respectively.3.4Humanpost-editing:TranscriptionWecontractedwithaiXplainInc.toprofessionallypost-edittheASRoutput.Therewasathreetierreviewprocess:aninitialannotatorpost-editedpersegment,followedbyaqualityassurance(QA)an-notatorwhowentthrougheachfulltalktoensurequalityandconsistency,andthenfinally10-20%ofthesegmentswererandomlychosenforafinalcheck.Inadditiontosemanticcontent,annotatorsmaytheoreticallyalsofixsegmentationboundariesbutinpracticethisrarelyoccurs.Theannotatorsprovidedadditionalinformationaboutthespeak-ers,namelygender(male,female)andage(child,youngadult,adult,elderly).Theannotatorswerealsoshownthevideoofthepresentationtoaidthemingrecognizingtechnicalterms,whichmayappearintheslides.Disfluencieswerestandardizedsuchthatfalsestartsandrepetitionswerekeptwheretherewereperceivablepausesbetweenthem,andtwohesitationspellingvariations(ah,um)wereused.TheannotatorguidelinesandLabelStudiointerfaceareshownin\u00a7A.4.Aftertheprofessionalpost-editingpass,adomainexpertverifiedandcor-rectedthetechnicalterms.Post-editinganalysis.ASRoutputisstronglymonotonicwithrespecttotheoriginalspeech,andaccordinglymostpost-editsareforincorrectlytran-\nsentences(b)TextsegmentlengthdistributionFigure2:DistributionofEnglishsegmentlengthsviaspeechduration(seconds)andtextlength(wordcount)foreachofthreesegmentations:VAD,subtitles,andsentences.quentlyrepresentedintheACLcommunitywhilebalancingtopicdiversityandgender.Wenotena-tivelanguageandcountrywhereavailable.Talkswerechosentocoveradiversesetoftracksandtopicsandthereforediversetechnicalvocabularyrepresentativeoftheneedsofthefield.Wherepre-sentationswerechosenwithinthesametrack,theycovereddifferentfocusesandmethodology,e.g.mathwordproblemsversusreleasenotegenerationorfew-shotadaptationforstructureddata.Meta-dataforalltalkswithexactdurationsandtrackandspeakerannotationsareshowninTable3in\u00a7A.1.Holdingoutspeakersandtopicspersetopti-mizesforoverallsystemgeneralizationbutreducesthematchbetweendevandevalsets;thise.g.re-ducesthebenefitoffinetuningonthedevsettomaximizetestsetperformanceandoverfittingthemodelorchosenhyperparameterstothedevsetwilladverselyaffecttestsetperformance.How-ever,highperformanceonbothsetsismorelikelytoindicategeneralizablesystemsandrepresenta-tiveperformancebeyondthesedatapointsthanifthedevandevaldataweremorecloselymatched.3.3AutomatictranscriptionThefirstpassthroughthedatausedautomaticseg-mentationandtranscriptiontoprovideinitialtran-scripts.WeusedtheAzureAPIspeech-to-textservice,7whichhasthebestcostandqualitybal-anceofcurrentlyavailablemodels.Inadditiontotranscription,theserviceperformsspeakerdiariza-tion,withimplicitvoiceactivitydetection(VAD),segmentingtheinitially\u223c11.5minuteaudiofilesintosegmentsofapproximately30secondsorless\n0\n0\n0\n0\n30\nsubtitles\nsubtitles\n30Seconds\n300\n150\nVAD\nVAD\n100\n100\n25\n40\n40\n140\n350\n15\nsentences(a)Speechsegmentlengthdistribution\n5\n20\n20\n20\n400Num. Segments\n70\n64\n\n\nREF:multilingualBERTPERFORMSbetterthanBETOHYP:multilingualBIRDPERFORMbetterthanBETTERSSS\nFigure3:SampleASRerrorsfromdevusingSCLITE.CorrectionsareemphasizedwithCASE.scribedwords,case,andpunctuation.93%ofwordswerecorrectlytranscribedbytheinitialASRpass.SpuriouspunctuationandcasingintheASRoutput(ex\u2018Thank.You.\u2019)accountedfor43%oftheerrorscapturedbyWER.Settingpunctuationandcaseaside,intheprofessionalpost-editingpass,60%ofsentenceshadatleastonecorrectionmade.Themajorityofpost-editswereword-levelsub-stitutionsforincorrectlytranscribedwords(62%).Droppedwordswerenotcommon,withonly1.6%ofwordsdroppedbytheASRmodelandlaterin-serted.Slightlymorecommon(1.8%)wereinser-tionsduetowordsincorrectlytranscribedasmulti-pletokensbytheASRsystem,andlatercorrected.ExamplesareshowninFigure3.Furthercorrectionsbyadomainexpertweremadefor3%ofwords.Whilethemajoritywerecorrectionstoterminologyrequiringtechnicalcon-text(\u2018CONEL\u2019\u2192\u2018CONLL\u2019or\u2018positionor\u2019\u2192\u2018po-sitional\u2019),somefixeswereforsubtlenumberandtensechangesintheASRtranscriptionpossiblyin-fluencedbyrecordingconditionsorpronunciation.Technicalterms.Thesubsetoftechnicaltermsappearingintheterminologylistscreatedbythe60-60initiativewereautomaticallytaggedonthesourceside(seeFigure4).Theselistswerenotexhaustivebutprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsandtheirevaluation,andwhichfutureworkmayfindbeneficial.TechnicaltermscomprisedthemajorityofASRerrors.86%ofthetaggedterminologywerecor-rectlytranscribedtheASRmodel,8%werecor-rectedbytheprofessionalpost-editors,andthere-maining6%werecorrectedbyadomainexpert.3.5SentencesegmentationWhileitiscommoninspeechcorporatosegmentbasedonvoiceactivitydetectionorsubtitle-likecri-\nREF:wefindaBILSTM**CRFmodelusingflareHYP:wefindaBIASTMCRFmodelusingflareSD\nREF:alsoFASTTEXTCHARACTEREMBEDDINGSHYP:alsoFASTTEXKITCHENBEDDINGSSSS\nFigure4:Exampleoftaggedterminologyfromdev.Terminologylistswerenotexhaustive;[text-to-speech]didnotappear,leading[text]and[speech]tobetaggedseparately.teria,thismayresultinsegmentswhicharenotpar-allelacrosslanguages(inthecaseofmultilingualspeech),whicharetooshorttotranslatewithoutadditionalcontext,orwhicharetoolongforeffec-tivesystemevaluation.Foramultilingualdatasetintendedtobemulti-wayparallelandtobeusedfortranslation,itiscriticaltohaveconsistentseg-mentationacrossalllanguagesandforallsegmentstocontainthenecessarycontexttotranslatetothedesiredtargetlanguages.TheVADsegmentsfacilitatedtranscription,butresultedinawidedistributionofsegmentlengths,somejustonetotwowordslong,andotherscon-tainingmultiplesentences,potentiallyskewingdownstreamevaluationmetricsandprovidingamismatchtocommontrainingconditions.Oneoptionwouldbetosubdividethesegmentsusingsubtitleguidelines,8wherethosesegmentswhichdonotconformtoparticularlengthguidelinesarerealignedintosmallersegmentswhichisdoneus-ingforcedalignment.However,subtitlesegmentsoftencontainpartialsentences,which,particularlywhenincludinglanguageswithdifferentwordor-dersordegreesofreorderingfromthesourcelan-guage(English),mayplaceverbsacrosssegmentboundariesforsomelanguagesandnotothers.Sen-tences,then,maybeamoreappropriateunitformulti-wayparallelsegments.Weresegmentedthefinalpost-editedEnglishtranscriptionsintosen-tencesmanuallytoavoidnoisefromcurrentlyavail-abletools.Examplesofallthreesegmentations(VAD,subtitles,andsentences)areshowninFig-ure12in\u00a7A.8.Toensurethespeechandtextwerecorrectlyalignedgiventhefinalsentenceseg-ments,theywerere-forcealignedusingWHISPER-TIMESTAMPED(Louradour,2023),anextensionofOpenAI\u2019sWhispermodel(Radfordetal.,2022)whichusesDTW(Giorgino,2009)totimealignatthewordlevel,andweremanuallyrecheckedbytheannotators.\n8Subtitleguidelinesareshownin\u00a7A.7.\n65\n\n\nevalchrF77.271.756.383.753.686.684.865.377.062.7BLEU55.448.527.168.347.371.568.739.451.667.9COMET86.283.679.584.589.188.187.982.585.987.4\ndevchrF75.372.854.980.056.982.782.359.369.060.5BLEU54.148.325.363.050.763.665.930.539.165.9COMET86.283.676.884.589.188.187.982.585.987.4\n9https://www.modernmt.com/api/10https://azure.microsoft.com/en-us/products/cognitive-services/translatornotnecessarilyindicatedbythesemetrics.3.7Humanpost-editing:TranslationPost-editinghasbecometheindustrystandarddueitsincreasedproductivity,typicallyreducingpro-cessingtimeandcognitiveloadcomparedtodirecttranslation,particularlyfordomain-specifictexts(O\u2019Brien,2007;GrovesandSchmidtke,2009;Tat-sumi,2009;PlittandMasselot,2010).WecontractedwithTranslatedtoprofessionallypost-edittheMToutput.Therewasatwotierre-viewprocess:aninitialannotatorwhowasanativespeakerofthetargetlanguagepost-editedperseg-ment,followedbyasecondtoreviewtheoutputandconsistencyofthefirst.Annotatorguidelinesandthepost-editinginterfaceareshownin\u00a7A.5.Technicalterms.TerminologywasnothandledseparatelyduringtheMTstepnorautomaticallytagged,giventhattheMTsystemsmayomitorincorrectlytranslatetechnicalterms.Wedidnotuseconstraineddecodinggiventheterminologyliststranslationsastheirvaliditycouldbecontext-dependentandsometermshadmultiplepossibletranslations.Instead,translationpost-editorswereinstructedtocorrectthetranslationsoftaggedter-minologyonthesourceiftheywerenotmaintainedandthentagtheappropriatetargettranslationsforeachsourcetaggedsourcespan.Capitalizedacronymsandterminologynotonthelistsandun-knowntothetranslatorswasleftinEnglish.Post-editinganalysis.Whilethemetricsintheprevioussectiongiveasensefortheautomatictranslationquality,theydonotnecessarilyreflecttheeffortrequiredtopost-editthetranslationstofinalreferencequality.UsingTERtoassessthedegreeofpost-editingnecessary,weseeinFig-ure5thatthisvariesbylanguage.Mostnoticeably,weseethatFarsi,Russian,Japaneseastargetlan-guagesrequiredthehighestamountofpost-editing.\nTable1:EvaluatingtheinitialcommercialMTfromground-truthtranscriptsagainstthefinalreleasedreferences.BLEUscoresingreyarecalculatedusinglanguage-specifictokenization(ja)oratthecharacter-level(zh);see\u00a72.2.Wecomparethedistributionofsegmentlengthsforeachofthethreeapproaches(VAD,subtitles,andsentences)intermsofbothduration(seconds)andnumberofwords(English)inFigure2.VADresultsinthemostunevendistribution,withseg-mentsrangingfrom<1secondto>30seconds.Sub-titlesresultinmoreuniformbutdistinctlyshortersegments,with58%containinglessthan10wordsand19%shorterthantwoseconds,likelytooshortforsomedownstreamtasksormetrics.Sentencesresultinlessextremesegmentlengths.Examplesofeachsegmentationareshownin\u00a7A.8.Thefinaldatacontains468sentencesinthedevelopmentsetand416sentencesintheevaluationset.3.6MachinetranslationThefirsttranslationpassusedpubliclyavailablebilingualMTmodelstotranslatethefinalsentencesegments.WeusedtheModernMTAPI9forthe9of10languagepairssupported,andtheAzureAPI10forEnglish-Farsi.Weevaluatethecommer-cialmachinetranslationoutputagainstthefinalreleasedtranslationreferences(\u00a73.7)usingthemet-ricsdiscussedin\u00a72.2,showninTable1.Eachmetricsuggestsadifferentstoryabouttranslationqualityandthedegreetowhichitislanguage-specific.WhileCOMETsuggestsrel-ativelyconsistentperformanceacrosslanguages,chrFandBLEUdonot.chrFandBLEUsug-gestsignificantlyworseperformanceforasubsetoftargetlanguages,includingallbutoneofthenon-Latinscriptandnon-IndoEuropeanlanguages.BLEUyields1.7\u00d7greatervariancethanchrF.Byallmetrics,though,MTqualitywasconsistentbe-tweenthedevelopmentandevaluationsets.Weseeinthenextsectionthattheamountofpost-editingrequiredtocreatethefinalreferences,however,is\nMetricardefafrjanlptrutrzh\n66\n\n\nTER [eval]Figure5:Estimatedtranslationpost-editingeffortre-quiredpertargetlanguage,asmeasuredbyTER.ForFarsiandJapanese,weseethatthisispre-dominantlyduetoreordering.Isolatingreorder-ingfromsemanticcorrectionsbylookingonlyatthosetokens11whichdidnotneedtobecorrected,weuseLevenshteindistancetoassessthedegreeofreorderingfromtheMToutputrequired.Weobservedastrongbiastowardssourcelanguagewordorderinthemachinetranslationoutput,caus-ingagreaterdegreeofpost-editingforlanguageswithdifferingwordorders.Figure6showsthatreorderingrequirementsaremoderatelycorrelatedwithoverallpost-editingeffortformostlanguages(\u03c1=0.41),whileTERisonlyweaklysuggestedbyCOMET(\u03c1=0.29)andisnegativelycorrelatedwithchrFandBLEU(\u22120.63,\u22120.21respectively).Formosttargetlanguages,therewasnosignifi-cantdifferenceinpost-editingeffortbetweendevandtest,butwheretherewasadifferenceitwasthedevtalksthatrequiredadditionalediting,mostno-ticeablyforTurkishandRussianandtoalesserde-greeDutch.Dividingthedataintoindividualtalks,whicheachvaryincontentwithinthetechnicaldo-main,therewassomevariationinthequalityofthefirst-passMT(Figure7).Wefoundthatwhichtalksrequiresimilarlevelsofpost-editingismoderatelytostronglycorrelatedacrosslanguages,suggestingthiswasduetotopicratherthanlanguage,withthe\nnl\nnl\n50\n8\nfa\nfa\nja\nja\n10\n10\n4\n0\nzh\nzh\n30\nFigure6:DegreeofreorderingdoneinMTpost-editing.exceptionofFarsiandJapanese(Figure8).Thiscorrelationdoesnotappeartobeinfluencedbylan-guagefamilyandwasnotrelatedtotheproportionoftaggedterminologypertalk.ForRussianandTurkish,aparticulartalkskewedoveralldevTER,possiblyduetoagreaterproportionofpolysemoustermswithdomain-specificmeaninginthatarea.Terminology.Taggedterminologywasmoreof-tencorrectlyautomaticallytranscribedthantrans-lated.Between70-75%ofthetaggedspansweretranslatedcorrectlybytheinitialMTmodelde-pendingonthetargetlanguage,asmeasuredbyanexactmatchwiththefinaltaggedpost-editedspan.Theremaining25-30%weremanuallycorrectedbythepost-editors.Inaddition,2-5%ofwordsoverallwereleftinEnglish,predominantlymadeupofadditionalterminologyandnames.4ChallengestoAddresswithACL60/604.1SegmentationSpeechtranslationdatasetscustomarilyprovideasegmentationfortranslationandevaluation,seg-mentedeithermanually(e.g.CoVoST)orautomat-ically(e.g.MuST-C).Inrealisticusecases,suchsegmentationisunavailableandlongaudiocannotbeprocesseddirectly,resultinginmismatchedcon-ditionsatinferencetime.Therecanbeanoticeableperformancegapbetweenmanualsegmentationandautomaticmethods(Tsiamasetal.,2022).Weillustratetheimpactofdifferentspeechseg-mentationsondownstreamtranscriptionandtrans-lationqualitybycomparingmanualsentenceseg-mentationtotheinitialVADsegmentsaswellastoSHAS(Tsiamasetal.,2022),usingthetoplinecommercialASRandMTsystemsusedduringthe\nfr\nfr\n12\ntr\ntr\n14\nde\nde\n11CharactersratherthanwordswereusedforthisanalysisforJapaneseandChinese.\nar\nar\nTER [dev]\n2\n40\npt\npt\n6\nru\nru\n20\n67\n\n\nzhFigure7:RangeinTERbytalkperlanguage.\nnl\nnl\nnl\n50\n0.8\n12chrFforindividuallanguagesisshowninTable6.4.2DemographicfairnessThefieldisdiverseandrapidlygrowingwithawidevarietyofspeakerdemographicsandnativeandnon-nativeEnglishaccents.Aswetrainincreas-inglylargeandmultilingualmodelsitisimportanttoevaluatetheirfairnesstoensureanybiaseswemayfinddecreaseratherthanincreaseovertime,whichwebelievethisdatasetmayhelpwith.Thevarietyofspeakerdemographicsinboththefieldandtheseevaluationsetsremaindisproportion-atelychallengingtocurrentASRmodels.LookingattheaverageWERamongtalksofeachgender,weseeamarginof10.5.15%ofdevsentencesand26%ofevalsentencesweremisclassifiedasnon-EnglishlanguageswhenusingthemultilingualWhisperBASEmodel,showingabiasagainstvariedpronunciationsandL1sthatitisnecessarytoad-dresswhenpursuingmultilingualmodelling.WERis23%betterwhenthemodelispromptedtogen-erateEnglishonly,however,thereisstillafurther16%gaptotheEnglish-onlyBASEmodel.Mov-ingtothelargermultilingualmodel,thediscrep-ancyinperformancewithandwithoutlanguagepromptingbecomes2.4\u00d7larger,thoughoverallperformanceimproves.Atworst,the\u2206WERbe-tweenspeakersis62.2,andatbest,8.0,highlight-ingasignificantdiscrepancywhichneedstobeimproved.Demographicfairnessisanimportantissuewhichrequirestargetedresearchtoaddress.Wehopetheseevaluationssetsmayfacilitatefurtherresearchinthisspace,despitetheirsmallsize.4.3DomainadaptationandterminologyTerminology.Constraineddecodingoftechni-caltermsordomain-specifictranslationsisanarea\n8\nfa\nfa\nfa\nja\nja\nja\nManualsentences15.221.469.471.5CommercialVAD15.422.462.059.6SHAS16.421.561.960.4\n0.2\n10\n4\n3\n0\n0\nzh\n30\nfr\nfr\nfr\n1\ntr\ntr\ntr\n7\n60TER\n0.0\nde\nde\nde\nar\nar\nar\n0.6\nTable2:Comparisonbetweenmanualsentencesegmen-tationandhighqualityautomaticsegmentationforASRandcascadedSTinWERandavg.chrF,respectively.Segmentationisanimportantopenchallenge,andwesuggestthatthisdatasetbeusedtoevalu-atesegmentationbymakingthedatasetstandardscoringwithresegmentation.\n2\n40\npt\npt\npt\n6\n9Talk idx\n1.0Figure8:CorrelationinTERacrosslanguages.datasetcreationpipeline.AsseeninTable2,12undercertaincircumstancesautomaticsegmenta-tionmethodscanperformaswellasmanualsen-tencesegmentation,thoughthisisnotalwaysthecaseandsmallresultingdifferencesinASRperfor-mancemaycascadeintolargerperformancegapsindownstreamMT,meritingfurtherresearch.Variationduetosegmentationalsodependsonmodeltrainingconditions.Modelsaretypicallyoptimizedforthesegmentlengthsobservedintrainingand/ormayuseadditionalinternalseg-mentation.Forexample,whenwecomparetheWhisperLARGEmodel(Radfordetal.,2022)whichistrainedonlongersegments,sentencesaresub-optimalcomparedtoSHASandVAD(0.1-0.9WER),andwhentheyarefurthersegmentedupto4\u00d7byitsinternalVADthiscascadestodispro-portionatelyworsedownstreamMTperformance(byupto8chrF)thanwiththeAzureASR.\nASRMTSegmentationdevtestdevtest\nru\nru\nru\n5\n0.4\n20\nzh0.680.110.810.540.790.770.710.690.430.680.270.730.420.770.440.560.680.750.110.27-0.080.340.100.170.430.500.780.810.73-0.080.150.760.730.580.570.260.540.420.340.150.220.160.290.270.640.790.770.100.760.220.560.670.850.420.770.440.170.730.160.560.710.610.260.710.560.430.580.290.670.710.850.520.690.680.500.570.270.850.610.850.610.430.750.780.260.640.420.260.520.61\n68\n\n\nterminology: ASR\nnl\n50\nMetric\nfa\nterminology: MT\nja\n60\n80\n10\n0\n30\nfr\n90\ntr\nde\nar\n100\nofactiveresearch(Huetal.,2019;PostandVi-lar,2018;HokampandLiu,2017).Theterminol-ogylistswerenotexhaustive,containingjustover250terms,butprovideaninitialkeywordsettobootstrapidentificationandtranslationoftechnicaltermsincontextandtheirevaluation,whichfutureworkmayfindbeneficial.Wehighlightthereductioninterminologyre-callbetweenthestrongASRandMTsystemsusedinthedatasetcreationpipelinebelowinFig-ure9.Itisclearthatevencommercialsystemsstrugglewithdomain-specificterminologyparticu-larlywithoutadaptation.Whiletherearediscrep-anciesacrosslanguagepairs,terminologyrecallisstronglycorrelatedwithoveralltranslationperfor-mance(\u03c1=0.8)asmeasuredbychrF.\nzhLanguage\n40\npt\nru\n20\nchrFFigure9:TerminologyrecallofASRvsMT,withover-alltranslationperformanceshownbehind(chrF).Lightweightdomainadaptation.Therearefewpubliclyavailabledatasetswithtechnicalcontent,andfewertranslated.Whileitispossibletoscrapein-domainmateriale.g.fromtheACLAnthology,thiswouldbeinthesourcelanguage(English)onlyratherthanthetargetlanguages.Whileonlyhavingtarget-domaindatainthesourcelanguageisareal-isticscenario,itisnotthesettingtypicallyfoundincurrentresearchorapproaches,andhighlightstheneedfornewmethodsfordomainadaptationwhichcanmakeuseofthisdata.Weadditionallyprovidepapertitlesandabstracts,whicharelikelytocontainbothparticularlyimportantvocabularyandcuethetalktopic.Wehopethisdatamayprovebeneficialforlightweightmethodstoadapttothetechnicaldomainorspecifictalksettingsortolexi-callyconstrainorpromptparticulartranslations.5RelatedworkPreviousworkhasstudieddatafromtheACLAn-thologyfortermminingandidentification(Schu-mannandMart\u00ednezAlonso,2018;Jinetal.,2013)andconceptrelation(G\u00e1boretal.,2016)inthescientificdomain.FewspeechtranslationdatasetsinthetechnicaldomainexistbutthosethatdosuchastheQCRIEducationalCorpus(Abdelalietal.,2014;Guzmanetal.,2013)haveprimarilytargetededucationallecturesandvideos.Additionaldatasetsspecifi-callyforspeechtranslationevaluation(Conneauetal.,2023)areprimarily\u2018generaldomain.\u2019Significantpreviousworkhasstudiedvariousaspectsoftranslationpost-editing,includingpost-editingeffort(Scartonetal.,2019),evaluatingpost-editingqualityandreferencebias(Bentivoglietal.,2018),biasfromtheinitialMTqualityandoutputpatterns(Zouharetal.,2021;PicininiandUeffing,2017),andthetheefficacyofpost-editinginhighlytechnicaldomains(Pinnisetal.,2016)andresultingtranslationbiases(\u02c7CuloandNitzke,2016).TheimpactofautomaticsegmentationqualityonvariousSTmetricshasbeenevaluatedinrecentIWSLTsharedtasks(Ansarietal.,2020;Anasta-sopoulosetal.,2021,2022)andresearch(Tsiamasetal.,2022;Senetal.,2022;Ansarietal.,2021)usingotherdatasets(TED)withlongerreferencesegmentationsthanours.Withlongersequencesthereisgreaterpotentialforvariation,andpastcam-paignshaveobservedlargerdifferencesbetweensegmentationsthanseenhereandevenimprove-mentsovertheprovidedsegmentation.Significantadditionalworkhasbeendoneinthesimultaneoustranslationspace,whichwedonotaddresshere.6ConclusionsWeintroducedanewdatasettoevaluatemultilin-gualspeechtranslationfromEnglishintotentargetlanguagesspecificallyinthetechnicalNLPdomain.Wehavediscussedindetailthestepstocreatethecorpusandthetoolsandconsiderationsrequired.Wehavealsoprovidedafurtherviewintoevalua-tionmethodologymimickingrealisticconditionswheresegmentationisnotprovided.Wehopethatthisdatasetmaybeusefulforthefieldtostudytheeffectivenessofthetoolswedevelopbothfortrans-lationandadditionalapplicationsinthetechnicaldomaininanincreasinglymultilingualspace.\n70\n69\n\n\nLimitationsWhilewehavedoneourbesttocreatehigh-qualityevaluationdata,therearelimitationsthatshouldbekeptinmindwhenusingthesedatasets.Itisknownthatcreatingtranslationsbypost-editingmaybiasdatatowardstheoutputoftheMTsystemsusedforinitialtranslations;however,manytranscriptionandtranslationvendorsnowexclusivelyusepost-editingratherthantranslationfromscratchandsodirecttranslationmaynotbeanoptioninallcases.ThiscouldinfluencemetricstowardsimilarMTsystems.Thepresentedevaluationsetsaremoder-atelysizedcomparedtodatasetsinotherdomainswithplentifulmineddata,andmaybebestusedinconjunctionbyreportingonboththedevelop-mentandevaluationsetsforstatisticalsignificance.Theevaluationsetsalsohaveanecessarilylimitedsetofspeakerswhichmaynotbefullyrepresenta-tive.Systemswhichtunetothedevelopmentsetruntheriskofover-fittingtospecificspeakersorcontent.Wedonotperformacomparisontohu-manevaluationhere,butreferinterestedreaderstotheIWSLT\u201923evaluationcampaignfindingspaperwhichrunsthiscomparisonforavarietyofsystemswiththeACL60/60data(Agarwaletal.,2023).EthicalConsiderationsThisdatasetisconstructedfromasmallsetofspeakerswhereeachspeakermaybetheonlyrep-resentativeofcertaincross-sectionalaxes,andassuch,evenreportingaggregatemetadatamaybreakanonymity.Whilewedonotdistributespeakeran-notationswiththedatasomeinformationisinher-entlyrecoverableduetothelinktotheAnthology.Wenonethelessbelievethisdatawillbebeneficialtothecommunityinordertostudylanguagepro-cessingontechnicaldata,anditisnecessarytohaveadiverseevaluationsettoprovideamorereal-isticandrepresentativemeasureforgeneralization.Itisdifficultandcostlytoconstructdatasetswithhuman-editedtranscriptsandtranslationsandthiswasthelargestsetpossibletocollect.Post-editorswerecompensatedwithprofessionalwages.AcknowledgementsWeareverygratefultofundingandsupportfromACLandthe60/60initiativetocreatethisdataset.WethankourannotatorsandthegeneroussupportofaiXplainandTranslated.ElizabethSaleskyissupportedbytheAppleScholarsinAI/MLfellow-ship.ReferencesAhmedAbdelali,FranciscoGuzman,HassanSajjad,andStephanVogel.2014.TheAMARAcorpus:Buildingparallellanguageresourcesfortheeduca-tionaldomain.InProceedingsoftheNinthInter-nationalConferenceonLanguageResourcesandEvaluation(LREC\u201914),pages1856\u20131862,Reykjavik,Iceland.EuropeanLanguageResourcesAssociation(ELRA).MilindAgarwal,SwetaAgrawal,AntoniosAnasta-sopoulos,Ond\u02c7rejBojar,ClaudiaBorg,MarineCarpuat,RoldanoCattoni,MauroCettolo,MingdaChen,WilliamChen,KhalidChoukri,AlexandraChronopoulou,AnnaCurrey,ThierryDeclerck,Qian-qianDong,YannickEst\u00e9ve,KevinDuh,MarcelloFederico,SouhirGahbiche,BarryHaddow,BenjaminHsu,PhuMonHtut,HirofumiInaguma,D\u00e1vidJa-vorsk\u00fd,JohnJudge,YasumasaKano,TomKo,RishuKumar,PengweiLi,XutaiMa,PrashantMathur,EvgenyMatusov,PaulMcNamee,JohnP.McCrae,KentonMurray,MariaNadejde,SatoshiNakamura,MatteoNegri,HaNguyen,JanNiehues,XingNiu,AtulOjhaKr.,JohnE.Ortega,ProyagPal,JuanPino,LonnekevanderPlas,PeterPol\u00e1k,ElijahRippeth,ElizabethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,YunTang,BrianThompson,KevinTran,MarcoTurchi,AlexWaibel,MingxuanWang,ShinjiWatanabe,andRodolfoZe-vallos.2023.FindingsoftheIWSLT2023EvaluationCampaign.InProceedingsofthe20thInternationalConferenceonSpokenLanguageTranslation(IWSLT2023).AssociationforComputationalLinguistics.AntoniosAnastasopoulos,Lo\u00efcBarrault,LuisaBen-tivogli,MarcelyZanonBoito,Ond\u02c7rejBojar,RoldanoCattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,MahaElbayad,ClaraEmmanuel,YannickEst\u00e8ve,MarcelloFederico,ChristianFedermann,SouhirGahbiche,HongyuGong,RomanGrundkiewicz,BarryHaddow,BenjaminHsu,D\u00e1vidJavorsk\u00fd,V\u02d8eraKloudov\u00e1,SurafelLakew,XutaiMa,PrashantMathur,PaulMcNamee,KentonMurray,MariaN\u02c7adejde,SatoshiNakamura,MatteoNegri,JanNiehues,XingNiu,JohnOrtega,JuanPino,Eliz-abethSalesky,JiatongShi,MatthiasSperber,Se-bastianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Yo-geshVirkar,AlexanderWaibel,ChanghanWang,andShinjiWatanabe.2022.FindingsoftheIWSLT2022evaluationcampaign.InProceedingsofthe19thInternationalConferenceonSpokenLanguageTranslation(IWSLT2022),pages98\u2013157,Dublin,Ireland(in-personandonline).AssociationforCom-putationalLinguistics.AntoniosAnastasopoulos,Ond\u02c7rejBojar,JacobBremer-man,RoldanoCattoni,MahaElbayad,MarcelloFed-erico,XutaiMa,SatoshiNakamura,MatteoNegri,JanNiehues,JuanPino,ElizabethSalesky,Sebas-tianSt\u00fcker,KatsuhitoSudoh,MarcoTurchi,Alexan-derWaibel,ChanghanWang,andMatthewWiesner.2021.FINDINGSOFTHEIWSLT2021EVAL-UATIONCAMPAIGN.InProceedingsofthe18th\n70\n\n\nInternationalConferenceonSpokenLanguageTrans-lation(IWSLT2021),pages1\u201329,Bangkok,Thailand(online).AssociationforComputationalLinguistics.EbrahimAnsari,AmittaiAxelrod,NguyenBach,Ond\u02c7rejBojar,RoldanoCattoni,FahimDalvi,NadirDurrani,MarcelloFederico,ChristianFedermann,JiataoGu,FeiHuang,KevinKnight,XutaiMa,AjayNagesh,MatteoNegri,JanNiehues,JuanPino,Eliz-abethSalesky,XingShi,SebastianSt\u00fcker,MarcoTurchi,AlexanderWaibel,andChanghanWang.2020.FINDINGSOFTHEIWSLT2020EVAL-UATIONCAMPAIGN.InProceedingsofthe17thInternationalConferenceonSpokenLanguageTrans-lation,pages1\u201334,Online.AssociationforCompu-tationalLinguistics.EbrahimAnsari,Ond\u02c7rejBojar,BarryHaddow,andMo-hammadMahmoudi.2021.SLTEV:Comprehensiveevaluationofspokenlanguagetranslation.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics:SystemDemonstrations,pages71\u201379,On-line.AssociationforComputationalLinguistics.LuisaBentivogli,MauroCettolo,MarcelloFederico,andChristianFedermann.2018.Machinetransla-tionhumanevaluation:aninvestigationofevaluationbasedonpost-editinganditsrelationwithdirectas-sessment.InProceedingsofthe15thInternationalConferenceonSpokenLanguageTranslation,pages62\u201369,Brussels.InternationalConferenceonSpokenLanguageTranslation.AlexisConneau,MinMa,SimranKhanuja,YuZhang,VeraAxelrod,SiddharthDalmia,JasonRiesa,ClaraRivera,andAnkurBapna.2023.Fleurs:Few-shotlearningevaluationofuniversalrepresentationsofspeech.In2022IEEESpokenLanguageTechnologyWorkshop(SLT),pages798\u2013805.Oliver\u02c7CuloandJeanNitzke.2016.Patternsoftermino-logicalvariationinpost-editingandofcognateuseinmachinetranslationincontrasttohumantransla-tion.InProceedingsofthe19thAnnualConferenceoftheEuropeanAssociationforMachineTranslation,pages106\u2013114.MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,MatteoNegri,andMarcoTurchi.2019.MuST-C:aMultilingualSpeechTranslationCorpus.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages2012\u20132017,Min-neapolis,Minnesota.AssociationforComputationalLinguistics.SiyuanFeng,OlyaKudina,BenceMarkHalpern,andOdetteScharenborg.2021.Quantifyingbiasinauto-maticspeechrecognition.ArXiv,abs/2103.15122.KataG\u00e1bor,Ha\u00effaZargayouna,DavideBuscaldi,Is-abelleTellier,andThierryCharnois.2016.SemanticannotationoftheACLAnthologycorpusfortheauto-maticanalysisofscientificliterature.InProceedingsoftheTenthInternationalConferenceonLanguageResourcesandEvaluation(LREC\u201916),pages3694\u20133701,Portoro\u017e,Slovenia.EuropeanLanguageRe-sourcesAssociation(ELRA).ToniGiorgino.2009.Computingandvisualizingdy-namictimewarpingalignmentsinr:Thedtwpack-age.JournalofStatisticalSoftware,31(7).DeclanGrovesandDagSchmidtke.2009.Identifica-tionandanalysisofpost-editingpatternsforMT.InProceedingsofMachineTranslationSummitXII:CommercialMTUserProgram,Ottawa,Canada.FranciscoGuzman,HassanSajjad,StephanVogel,andAhmedAbdelali.2013.TheAMARAcorpus:build-ingresourcesfortranslatingtheweb\u2019seducationalcontent.InProceedingsofthe10thInternationalWorkshoponSpokenLanguageTranslation:Papers,Heidelberg,Germany.ChrisHokampandQunLiu.2017.Lexicallycon-straineddecodingforsequencegenerationusinggridbeamsearch.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages1535\u20131546,Vancouver,Canada.AssociationforComputationalLinguistics.J.EdwardHu,HudaKhayrallah,RyanCulkin,PatrickXia,TongfeiChen,MattPost,andBenjaminVanDurme.2019.Improvedlexicallyconstraineddecodingfortranslationandmonolingualrewriting.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages839\u2013850,Minneapolis,Minnesota.AssociationforComputa-tionalLinguistics.J.Iranzo-S\u00e1nchez,J.A.Silvestre-Cerd\u00e0,J.Jorge,N.Rosell\u00f3,A.Gim\u00e9nez,A.Sanchis,J.Civera,andA.Juan.2020.Europarl-st:Amultilingualcorpusforspeechtranslationofparliamentarydebates.InICASSP2020-2020IEEEInternationalConfer-enceonAcoustics,SpeechandSignalProcessing(ICASSP),pages8229\u20138233.YipingJin,Min-YenKan,Jun-PingNg,andXiangnanHe.2013.Miningscientifictermsandtheirdefini-tions:AstudyoftheACLAnthology.InProceed-ingsofthe2013ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages780\u2013790,Seattle,Washington,USA.AssociationforComputa-tionalLinguistics.AllisonKoenecke,AndrewJooHunNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,andSharadGoel.2020.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmerica,117:7684\u20137689.\n71\n\n\nJ\u00e9r\u00f4meLouradour.2023.whisper-timestamped.https://github.com/linto-ai/whisper-timestamped.NitikaMathur,JohnnyWei,MarkusFreitag,QingsongMa,andOnd\u02c7rejBojar.2020.ResultsoftheWMT20metricssharedtask.InProceedingsoftheFifthCon-ferenceonMachineTranslation,pages688\u2013725,On-line.AssociationforComputationalLinguistics.EvgenyMatusov,GregorLeusch,OliverBender,andHermannNey.2005.Evaluatingmachinetranslationoutputwithautomaticsentencesegmentation.InPro-ceedingsoftheSecondInternationalWorkshoponSpokenLanguageTranslation,Pittsburgh,Pennsylva-nia,USA.SharonO\u2019Brien.2007.Anempiricalinvestigationoftemporalandtechnicalpost-editingeffort.TheInfor-mationSociety,2:83\u2013136.KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002.Bleu:amethodforautomaticevalu-ationofmachinetranslation.InProceedingsofthe40thAnnualMeetingoftheAssociationforCompu-tationalLinguistics,pages311\u2013318,Philadelphia,Pennsylvania,USA.AssociationforComputationalLinguistics.SilvioPicininiandNicolaUeffing.2017.Adetailedinvestigationofbiaserrorsinpost-editingofMTout-put.InProceedingsofMachineTranslationSummitXVI:CommercialMTUsersandTranslatorsTrack,pages79\u201390,NagoyaJapan.MarcisPinnis,RihardsKalnins,RaivisSkadins,andIngunaSkadina.2016.Whatcanwereallylearnfrompost-editing?InConferencesoftheAssocia-tionforMachineTranslationintheAmericas:MTUsers\u2019Track,pages86\u201391,Austin,TX,USA.TheAssociationforMachineTranslationintheAmericas.MirkoPlittandFran\u00e7oisMasselot.2010.Aproductivitytestofstatisticalmachinetranslationpost-editinginatypicallocalisationcontext.InPragueBulletinofMathematicalLinguistics.MajaPopovi\u00b4c.2015.chrF:charactern-gramF-scoreforautomaticMTevaluation.InProceedingsoftheTenthWorkshoponStatisticalMachineTranslation,pages392\u2013395,Lisbon,Portugal.AssociationforComputationalLinguistics.MattPost.2018.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMachineTranslation:ResearchPapers,pages186\u2013191,Brussels,Belgium.AssociationforComputa-tionalLinguistics.MattPostandDavidVilar.2018.Fastlexicallycon-straineddecodingwithdynamicbeamallocationforneuralmachinetranslation.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongPa-pers),pages1314\u20131324,NewOrleans,Louisiana.AssociationforComputationalLinguistics.AlecRadford,JongWookKim,TaoXu,GregBrock-man,ChristineMcLeavey,andIlyaSutskever.2022.Robustspeechrecognitionvialarge-scaleweaksu-pervision.arXivpreprintarXiv:2212.04356.RicardoRei,CraigStewart,AnaCFarinha,andAlonLavie.2020.COMET:AneuralframeworkforMTevaluation.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcess-ing(EMNLP),pages2685\u20132702,Online.AssociationforComputationalLinguistics.RamonSanabria,NikolayBogoychev,NinaMarkl,An-dreaCarmantini,OndrejKlejch,andPeterBell.2023.Theedinburghinternationalaccentsofenglishcor-pus:Towardsthedemocratizationofenglishasr.ScartonScarton,MikelL.Forcada,MiquelEspl\u00e0-Gomis,andLuciaSpecia.2019.Estimatingpost-editingeffort:astudyonhumanjudgements,task-basedandreference-basedmetricsofMTquality.InProceedingsofthe16thInternationalConferenceonSpokenLanguageTranslation,HongKong.Associa-tionforComputationalLinguistics.Anne-KathrinSchumannandH\u00e9ctorMart\u00ednezAlonso.2018.AutomaticannotationofsemantictermtypesinthecompleteACLAnthologyreferencecorpus.InProceedingsoftheEleventhInternationalConfer-enceonLanguageResourcesandEvaluation(LREC2018),Miyazaki,Japan.EuropeanLanguageRe-sourcesAssociation(ELRA).SukantaSen,Ond\u02c7rejBojar,andBarryHaddow.2022.Simultaneoustranslationforunsegmentedinput:Aslidingwindowapproach.MatthewSnover,BonnieDorr,RichSchwartz,LinneaMicciulla,andJohnMakhoul.2006.Astudyoftrans-lationeditratewithtargetedhumanannotation.InProceedingsofthe7thConferenceoftheAssociationforMachineTranslationintheAmericas:TechnicalPapers,pages223\u2013231,Cambridge,Massachusetts,USA.AssociationforMachineTranslationintheAmericas.RachaelTatmanandConnerKasten.2017.Effectsoftalkerdialect,gender&raceonaccuracyofbingspeechandyoutubeautomaticcaptions.InInter-speech.MidoriTatsumi.2009.Correlationbetweenautomaticevaluationmetricscores,post-editingspeed,andsomeotherfactors.InProceedingsofMachineTrans-lationSummitXII:Posters,Ottawa,Canada.IoannisTsiamas,GerardI.G\u00e1llego,Jos\u00e9A.R.Fonol-losa,andMartaRuizCosta-juss\u00e0.2022.Shas:Approachingoptimalsegmentationforend-to-endspeechtranslation.InInterspeech.ChanghanWang,JuanPino,AnneWu,andJiataoGu.2020.CoVoST:Adiversemultilingualspeech-to-texttranslationcorpus.InProceedingsoftheTwelfthLan-guageResourcesandEvaluationConference,pages4197\u20134203,Marseille,France.EuropeanLanguageResourcesAssociation.\n72\n\n\nVil\u00e9mZouhar,MartinPopel,Ond\u02c7rejBojar,andAle\u0161Tamchyna.2021.Neuralmachinetranslationqualityandpost-editingperformance.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages10204\u201310214,OnlineandPuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.\n73\n\n\nMChineseChinaChina0:12:03NLPApplicationsM\u2014BelgiumNetherlands0:12:02ResourcesandEvaluationFRomanianRomaniaGermany0:09:22LanguageGrounding,SpeechandMultimodalityMJapaneseJapanJapan0:14:02NLPApplicationsMHebrewIsraelIsrael0:11:53NLPApplications\n0:57:13Totaldevelopmentsetduration\n0:59:22Totalevaluationsetduration\nWoman90928.7Man216468.3Non-binary/Genderqueer/Thirdgender14<1Genderfluid/Gendernon-confirming<10<1Prefernottosay772.4Specifyyourown<10<1\nTOTAL3170100\nTable3:Additionalmetadatafortalksintheevaluationsets.A.2ACL2022ConferenceParticipationStatisticsAggregatestatisticsforself-identifiedgenderaslistedonconferenceregistrationswereprovidedbyACL.\nTable4:AggregatestatisticsongenderofACL2022conferenceparticipants.\nMKinyarwandaRwandaUSA0:11:35Theme:LanguageDiversity(BestPaper)M\u2014\u2014USA0:11:35DialogueandInteractiveSystemsFSpanishSpainSpain0:12:17ResourcesandEvaluationFMarathiIndiaUSA0:12:09QuestionAnsweringMPolishPolandPoland0:09:37MachineLearningforNLP\nGenderL1CountryAffiliationTimeTrack\nAAppendixA.1AdditionalMetadataforACL60/60EvaluationSetsBelowwelistthedurationfortalksintheevaluationsets,alongwithadditionaldemographicmetadataaboutthepresentingauthor(speaker)andcontent(conferencetrack).ConferencetracksaretakenfromtheACL2022handbook.Genderannotationswerecheckedwithspeakers\u2019listedpronouns13andvalidatedbyspeakerswhereavailable.ForspeakerdemographicsandaccentwelistL1andnativecountrywhereavailable,aswellascountryofaffiliationasaroughproxy.\n13Thoughwenotepronounsdonotalwaysindicategender.\nGender#%\n74\n\n\nMuST-C(DiGangietal.,2019)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhCoVoST(Wangetal.,2020)enall(10)ar,de,fa,fr,ja,nl,pt,ru,tr,zhEuroparl-ST(Iranzo-S\u00e1nchezetal.,2020)ensome(4)de,fr,pt,tr\nCorpusSrcTgt\nTable5:CurrentpubliclyavailablealignedspeechtranslationcorporacoveringtheACL60/60languagepairs.TargetlanguagesareabbreviatedusingISO639-1codesasfollows\u2013Arabic:ar,German:de,Farsi:fa,French:fr,Japanese:ja,Dutch:nl,Portuguese:pt,Russian:ru,Turkish:tr,MandarinChinese:zh.A.4TranscriptionPost-editingGuidelinesandInterfaceThefollowingguidelineswereusedfortranscriptionpost-editingbyaiXplain.Theacceptancecriterionwaswordaccuracy>95%.\u2022Accuracy.Onlytypethewordsthatarespokenintheaudiofile.Phrasesorwordsyoudon\u2019tunderstandshouldNOTbeomitted.Instead,theyshouldbeannotatedusingthelabel\u201c#Unclear\u201d.\u2022Keepeverythingverbatim.Includeeveryutteranceandsoundexactlyasyouhear.Allfillerwordsshouldbeincluded(ex.#ah,#hmm).Iftheusercorrectshis/herself,alltheutterancesshouldbetranscribedandcorrectedwordsneedtoprecededwitha#mark(ex.Shesays#saidthat).\u2022Donotparaphrase.Donotcorrectthespeaker\u2019sgrammarnorrearrangewords.Also,donotcutwordsthatyouthinkareoff-topicorirrelevant.Anywordsnotspokenshouldnotbeincluded.Typetheactualwordsspoken.Ifthespeakermakesagrammaticalmistake,thetranscriptmustreflectthemistake(ex.Ifthespeakersays:\u201chewere\u201d,itshouldbetranscribedasiswithoutcorrection).\u2022Repeatrepeatedwordsinthetranscript.Forexample,iftheusersays:IIsaid,youmustincludebothinstancesofI.\u2022Donotaddadditionalinformationsuchaspagenumbers,jobnumbers,titlesoryourcommentsinyoursubmission.\u2022ForeignwordsshouldbetransliteratedusingLatinletters.\u2022Allabbreviationsneedtobespelledout.Forexample,doctorshouldNOTbespelledasDr.Similarly,percentshouldNOTbespelledas%.\u2022Allnumbersandspecialsymbols(ex.:%,$,+,@,=,etc.),orcombinationsofbothmustbespelledoutaswords,andmustmatchwhatthespeakersaysexactly.\u2022Allpropernames(ex.Google,NATO,Paris)shouldbetransliteratedinEnglish.\u2022Properpunctuationneedstobeplacedinthetext(ex.He,theboy,.).Pleasepayspecialattentionanddonotmiss/omitthesepunctuationmarks:,.?!:)(\u2022Personallyidentifiableinformation(likephonenumber,address,IDs)shouldbemarkedinthetextas<PII></PII>.Forexample:Myaddressis<PII>address</PII>\u2022Usedoubledashes\u201c--\u201dtoindicatetruncatedwords,attachedwhetheratthebeginningortheendoftheword(ex.transfor\u2013).\nA.3PubliclyAvailableCorporaBelowarethecurrentpubliclyavailablemulti-wayparallelspeechtranslationcorporawithEnglishasthespeechsource.WenotethatforMuST-Cnotalltargetlanguagesareavailableinallversionsofthecorpusassuccessiveversionsaddedadditionallanguagecoverage.Forfullcoveragev1.2oraboveisrequired.\n75\n\n\nFigure10:LabelStudiointerfacefortranscriptionpost-editing.A.5TranslationPost-editingInstructionsandInterfaceThetranslationpost-editingtaskwascarriedoutinMatecat14,anopen-sourceCATtoolthatallowsannotatorstocollaborateandgetsuggestionsfromModernMTinreal-time.Matecatalsooffersanembeddedglossaryfeaturethatensureseffectiveandconsistentterminologymanagement(asshownintheinterfaceimageinFigure11below,featuringMatecatglossarysuggestions).Thefollowingguidelineswereusedfortranslationpost-editing:\u2022Anytermfoundinthe60-60terminologieslist,shouldbetranslatedusingthetranslationintheterminologieslist.\u2022Anyabbreviationifnotfoundintheterminologieslist,shouldbekeptitintheEnglishform\u2022Thetermsintheterminologieslistmaycontainoneormoretranslationforeachtermseparatedby\u2018:::\u2019.Thetranslatorshouldpicktheproperonebasedonthecontext\u2022Ifthetranslatorthinksthatnoneofthegiventranslationsforaspecifictermmakessenseinthegivencontext,thetranslatorscanuseabettertranslationiftheyareveryconfident.Ifnotveryconfident,keepthewordintheEnglishform\n14https://site.matecat.com/\n76\n\n\ndevSentences66.968.753.473.947.874.374.055.062.450.462.7CommercialVAD66.668.552.774.146.273.673.753.960.649.862.0SHAS66.568.652.873.746.973.873.554.359.949.762.0\nevalSentences64.066.151.369.043.971.071.955.863.846.060.3CommercialVAD63.566.351.169.043.770.472.055.162.947.160.1SHAS64.466.451.569.642.071.472.455.763.145.460.2\nTable6:CascadedSTbylanguagefordifferentsourcespeechsegmentations,resegmentedandscoredwithchrF.A.7SubtitleGuidelinesSubtitleguidelinesfollowingindustrystandards,seeforexampleNetflix15andTED16:\u2022Noonesegmentisallowedtobelongerthan30seconds.\u2022Eachlinecannotbelongerthan42characters.\u2022Amaximumof2linesoftextcanbeshownonscreenatonce.\u2022Thesubtitlereadingspeedshouldkepttoamaximumof\u223c20characterspersecond.17IfoneofthesegmentscreatedbytheVADdoesnotadheretotheaboveguidelines,anEnglishmodelisusedtoforcealignmentthelongaudiosegmentanditstranscripttogetthetimestampofeachtoken,andthenthesegmentissplitintoshortersubsegments.Notethattheseguidelinesareautomaticallyapplied;theabovemeansthatifaVADsegmentconformstotheseguidelinesitwillnotberesegmented,andsubtitlesegmentsmaydifferfrommanuallycreatedsubtitlesweresemanticcoherencemaybeprioritizedoverlongersegmentswithintheseguidelines,ortextmaybelightlychangedfromwhatisspokentooptimizesubtitlequality(herenotallowed).\nFigure11:Matecatinterfacefortranslationpost-editing.A.6SegmentationComparison\n15https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-Timed-Text-Style-Guide16https://www.ted.com/participate/translate/subtitling-tips17Variesbyprogramaudience,commonlybetween17and21.\nSetSegmentationardefafrjanlptrutrzhAvg.\n77\n\n\nFigure12:Examplesofeachdiscussedtranscriptsegmentationapproachforsampledatafromthedevelopmentset.\nA.8SegmentationExamplesExamplesofeachtranscriptsegmentationapproachdiscussed(VAD,subtitles,andsentences)forsampledatafromthedevelopmentset.ExampleswerechosentoshowsegmentsfromthelongestandshortestVADquartiles,andtheresultingsubtitlesfollowingsubtitleguidelinesfrom\u00a7A.7.\n78"}