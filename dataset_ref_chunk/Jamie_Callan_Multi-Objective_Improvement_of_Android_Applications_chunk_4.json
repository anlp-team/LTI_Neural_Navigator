{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Jamie_Callan_Multi-Objective_Improvement_of_Android_Applications_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main focus of the text regarding software improvement?", "answer": " The main focus is on using genetic improvement (GI) techniques for enhancing software performance, particularly in the mobile domain.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What did Bokhari et al (2017) achieve in terms of Android app improvement?", "answer": " They were able to reduce the energy consumption of Android apps using deep parameter optimization.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What was the achievement of Callan and Petke in reducing the time taken to move between Activities of Android apps?", "answer": " They were able to reduce the time taken to move between Activities, the main UI components, of Android apps.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What are multi-objective (MO) algorithms used for in software improvement?", "answer": " MO algorithms are used to improve conflicting properties such as runtime and memory consumption by generating a Pareto front of non-dominated solutions.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What types of algorithms have shown success in multi-objective improvement for genetic improvement?", "answer": " Genetic Algorithm (GA) based algorithms such as NSGA-II and SPEA2 have shown success in multi-objective improvement.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What is the role of Pareto dominance in comparing solutions in MO algorithms?", "answer": " Pareto dominance is used to compare different individuals and determine trade-offs between different properties by identifying solutions where one is better than another in at least one objective.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " How do NSGA-II and NSGA-III select individuals for the next generation in MO algorithms?", "answer": " They sort the population into Pareto fronts based on fitness and select individuals from the top fronts, considering crowding metrics to maintain diversity.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " How does SPEA2 differ from NSGA algorithms in individual selection?", "answer": " SPEA2 calculates the strength of each individual based on how many others it Pareto dominates, and selects individuals based on raw fitness and crowding metrics.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What are some practical changes when using genetic improvement for Android apps compared to traditional desktop environments?", "answer": " Android apps require compilation, packaging, and launching on actual devices due to API dependencies like the Context class not available on desktops.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}, {"question": " What is the key feature of Android apps that makes them incompatible with traditional tooling?", "answer": " Android apps make use of APIs and features like the Context class that are only available on actual devices, making them incompatible with desktop testing environments.", "ref_chunk": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}], "doc_text": "have also proven effective (Blot and Petke (2021)). Although there is a lot of literature on the improvement of traditional software using GI, little is known about how the technique would fare in the mobile domain. Initial approaches have shown mixed results, with none trying to optimize multiple properties. Bokhari et al (2017) were able to reduce the energy consumption of Android apps, using deep parameter optimization, i.e., mutating parameters within source code, not exposed to the user. Callan and Petke (2022a) were able to reduce the time taken to move between Activities, the main UI components, of Android apps. However, when attempting to improve the frame rate of Android apps, Callan and Petke did not find improving patches (Callan and Petke (2021)). 3.2 Multi-Objective Optimization Performance properties such as runtime and memory consumption often are at odds with each other, i.e., one can improve runtime by caching results, thus increasing mem- ory use, and vice versa. In order to improve such conflicting properties, multi-objective (MO) algorithms have been proposed (Srinivas and Deb (1994)), which produce a Pareto front of non-dominated solutions. A solution x Pareto dominates another y if all of x\u2019s objectives are as good as y\u2019s and at least one objective is better than y\u2019s. Past work utilising MO algorithms for GI is sparse, with the majority of work focusing on single-objective improvement. However, in the work where MO improve- ment has been successful Genetic Algorithm (GA) based algorithms have been used. Wu et al (2015) and Callan and Petke (2022b) used NSGA-II (Deb et al (2000)), White et al (2011) used SPEA2 (Kim et al (2004)), with Mesecan et al (2022) comparing four MO algorithms, with SPEA2 and NSGA-III (Deb and Jain (2014)) performing best. In each algorithm, a population of solutions (in our case program variants) is generated and their fitnesses are measured. In order to generate new patches, mutation, and crossover operators are used to generate child populations and then individuals are selected for the next generation from both child and parent populations. 7 The algorithms vary in their selection phases. The algorithms use Pareto dom- inance to compare different individuals who may find trade-offs between different properties. Both NSGA-II and NSGA-III sort the population into Pareto fronts based on their fitnesses. The population of the next generation is then selected from the top fronts, one at a time, until a set number of individuals are chosen. If a front needs to be split, as it is too big for the population size, it is sorted by a crowding metric, and the least crowded members are selected. In NSGA-II, crowding is based on distance from other individuals in the fitness landscape. Whereas in NSGA-III, crowding is based on reference lines and the number of individuals that are closest to them, or niched to them. NSGA-III selects individuals spread across as many niches as possible in the final front to maintain diversity. Unlike the NSGA algorithms, SPEA2 does not separate the population into Pareto fronts. Instead, the strength of each individual is calculated. This is equal to the number of other individuals that the individual Pareto dominates. The raw fitness of an individual is then calculated as the sum of the strengths of all other individuals which it dominates. Like the NSGA algorithms crowding metric is calculated. For this, all other individuals are sorted into a list based on proximity to the individual of interest. The metric is inversely proportional to the distance of the kth individual in the list. The parameter k is equal to the square root of the total population size. Finally, the raw fitness and the crowding metric are simply added together and used to select individuals. It is yet unclear which multi-objective approach works best for the purpose of genetic improvement, thus we explore the capabilities of these three algorithms shown successful in previous work. 4 Multi-Objective GI for Android There are a number of practical changes when using genetic improvement to enhance the performance of Android apps when compared to traditional desktop environments. Android applications make use of APIs for features like UI elements which are only present on actual devices. The Android library available when testing applications on desktop operating systems overwrites the APIs such that they throw errors when invoked. Most Android code utilises the Context class (Android Development Team (2022a)), in the applications we use in our experiments, the context class is explicitly imported in over 1/3 of files. This does not include the instances where it is implicitly imported as a nested dependency. This class gives the code access to the shared state of the application but is only available on devices. This means that in order to run tests that exercise any component of an application\u2019s code that accesses this state, the entire application must be compiled, packaged, transpiled, installed, and launched before it can be tested. This can take a considerable amount of time, often longer than the tests themselves (Callan and Petke (2021)). Android apps are generally built using Gradle with the Android Gradle plugin. This makes them incompatible with much of the tooling surrounding automatic compilation and testing of code (Android Development Team (2022b, 2023a)). 8 AndroidAppRobolectricTests Mutation + CrossoverGradle CompilationFitnessSearchFitness ResultsNew PopulationCandidate PatchesSelection Fig. 1 GI framework for Android app improvement, with search based on a genetic algorithm. In the case of local search, only mutation is applied. | g i n . e d i t . s t a t e m e n t . D e l e t e S t a t e m e n t Example . j a v a : 6 0 8 | g i n . e d i t . s t a t e m e n t . CopyStatement Example . j a v a : 1 3 0 7 \u2212> Example . j a v a . j a v a : 3 2 0 : 3 6 5 | Fig. 2 An example"}