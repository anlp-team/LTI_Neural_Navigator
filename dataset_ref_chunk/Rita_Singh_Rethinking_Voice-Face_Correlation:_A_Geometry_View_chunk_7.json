{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Rita_Singh_Rethinking_Voice-Face_Correlation:_A_Geometry_View_chunk_7.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some possible reasons for the lack of predictability of anthropometric measurements (AMs) based on the current empirical results?", "answer": " Some possible reasons include imperfect modeling, limited data, data noise, etc.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " How does utilizing the phonatory module during training affect the accuracy of predicted AMs?", "answer": " Utilizing the phonatory module during training enhances the accuracy of predicted AMs.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What improvement in error was observed when utilizing the phonatory module for predictable AMs?", "answer": " Utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " Did the phonatory module have an apparent effect on unpredictable AMs?", "answer": " The phonatory module did not have any apparent effect on unpredictable AMs.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What phoneme had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value and what does this suggest?", "answer": " /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, suggesting that AMs are generally unpredictable from this phoneme.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " Which phoneme had the lowest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value and what does this suggest?", "answer": " /b/ had the lowest value of -0.06, suggesting that AMs are generally unpredictable from this phoneme.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What do negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values for certain phonemes indicate?", "answer": " Negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values suggest that AMs are generally unpredictable from the corresponding phoneme.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What was the approach presented in the paper to explore the voice-face correlation?", "answer": " The paper focuses on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion to explore the voice-face correlation.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What did the voice-anthropometric measurement (AM)-face paradigm identify?", "answer": " The paradigm identified predictable facial AMs from the voice to guide 3D face reconstruction.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}, {"question": " What is the significance of the results regarding the voice-face correlation presented in the paper?", "answer": " The results offer a new perspective on voice-face correlation, which can be valuable for anthropometry science and future research.", "ref_chunk": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}], "doc_text": "we do not claim they are not predictable from voice. Instead, we fail to demonstrate their predictability based on our current empirical results. The possible reasons include imperfect modeling, limited data, data noise, etc. 4.4 Effect of Phonatory Module As presented in Table 1, it is evident that utilizing the phonatory module during training enhances the accuracy of predicted AMs. Our evaluation involved computing the normalized error across all AMs with various confidence thresholds. Although the models with and without the phonatory module exhibited a marginal difference in error when evaluating all the data, the ones trained with the phona- tory module showed a clear improvement in error when considering more confident samples. Furthermore, we conducted an error evaluation for predictable and unpredictable AMs as depicted in Table 2. We observed that utilizing the phonatory module resulted in a 0.102-point decrease in normalized error for predictable AMs, highlighting its effectiveness in improving the prediction performance. Interestingly, the phona- tory module did not have any apparent effect on unpredictable AMs. Overall, the results indicate that utilizing the phonatory module during training is beneficial for predicting AMs, particularly for predictable ones. 4.5 Phoneme-level Analysis We also experiment with the voice-face correlation at the phoneme level. For this experiment, we train and evaluate estimators by taking one phoneme as input each time. We computed the average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value for each phoneme across all AMs, as shown in Fig. 7. Our results indicate that /i:/ had the highest average 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value of 0.199, while /b/ had the lowest value of -0.06. When the 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 value is less than 0, it suggests that AMs are generally unpredictable from the corresponding phoneme. Conference\u201923, July 2023, Ottawa, Canada Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 100 %90 %80 %70 %60 %50 %MaleFemale Figure 6: Error maps of the reconstructed 3D facial shapes for the male and female subsets. From left to right: the error maps corresponding to 100% (i.e. the entire test set) to 50% of the test set. Phonemes 1\u2212\ud835\udc36\ud835\udc3c! Figure 7: Phonemes with corresponding averaged \ud835\udc36\ud835\udc3c\ud835\udc62 in decreas- ing order. about facial features, making it easier for the model to capture the hidden correlation when predicting AMs. 4.6 In Section 4.3, we have discovered a number of predictable AMs, from which we choose 10 AMs with the highest 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 for the subsequent reconstructions on male and female subsets. 3D Facial Shape Reconstruction To evaluate the performance, we compute the per-vertex errors between the reconstructed 3D facial shape and their ground truths. We also filter out a portion of voice samples with the highest uncer- tainties and evaluate the errors in the remaining data. The filter-out rate is from 0% to 50%, as shown from left to right in Fig. 6. Unsurprisingly, we achieve the lowest errors around the nose region for male and female subsets, consistent with the AM estima- tions. Moreover, the reconstruction errors decrease significantly by filtering out the voice samples with the highest uncertainties. This indicates that the learned uncertainty is effectively associated with the reconstruction quality and allows the system to decide whether to trust the model or not. We observed that the three phonemes with the lowest and negative 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 values were /t/, /b/, and /d/, all of which are plosive consonants. During the pronunciation of plosive consonants, there is a complete stoppage of airflow followed by a sudden release of air through minimal mouth opening and closing. As a result, there is minimal movement of the facial muscles and structures, making it challenging for the model to predict AMs based solely on these phonemes. In contrast, most vowels achieved good performance in the test set, with all of the top 6 phonemes belonging to vowels with 1 \u2212 \ud835\udc36\ud835\udc3c\ud835\udc62 > 0.10. Compared to consonants, the production of vowels does not involve constriction of airflow in the vocal tract. Instead, the facial muscles have relatively greater movement during the pronunciation of these phonemes, such as jaw movement due to mouth opening or lip spreading. Thus, vowel phonemes may carry more information 5 CONCLUSION In conclusion, this paper presents a novel approach to exploring the voice-face correlation by focusing on the geometric aspects of the face rather than relying on semantic cues such as gender, age, and emotion. The proposed voice-anthropometric measurement (AM)- face paradigm identifies predictable facial AMs from the voice to guide 3D face reconstruction, which results in significant correla- tions between voice and specific parts of the face geometry, such as the nasal cavity and cranium. This approach not only eliminates the influence of unpredictable AMs but also offers a new perspective on voice-face correlation, which can be valuable for anthropometry science. The results of this study open up possibilities for future research in this area, such as developing more accurate voice-guided face synthesis techniques and a better understanding of the relation- ship between voice and facial geometry. Rethinking Voice-Face Correlation: A Geometry View REFERENCES [1] Zulfiqar Ali, Ghulam Muhammad, and Mohammed F Alhamid. 2017. An auto- matic health monitoring system for patients suffering from voice complications in smart cities. IEEE Access 5 (2017), 3900\u20133908. [2] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in neural information processing systems 33 (2020), 12449\u201312460. [3] Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, and David A. van Leeuwen. 2012. Age Estimation from Telephone Speech using i-vectors. In Interspeech. [4] Volker Blanz and Thomas Vetter. 1999. A morphable model for the synthesis of 3D faces. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. 187\u2013194. [5] Volker Blanz and Thomas Vetter. 2003. Face recognition based on fitting a 3D morphable model. IEEE Transactions on pattern analysis and machine intelligence 25, 9 (2003), 1063\u20131074. [6] Ray Bull, Harriet Rathborn, and Brian R Clifford. 1983. The voice-recognition accuracy of blind listeners. Perception 12, 2 (1983), 223\u2013226. [7] R. H. C. Bull,"}