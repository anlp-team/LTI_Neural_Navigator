{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Yonatan_Bisk_WebArena:_A_Realistic_Web_Environment_for_Building_Autonomous_Agents_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What type of profiles were set up for different users on different platforms?", "answer": " User profiles with specific roles and access permissions were set up for different users on different platforms.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " How are users automatically logged into their accounts?", "answer": " Users are automatically logged into their accounts using a pre-cached cookie.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What is unique about the publicly available agent evaluation environment described in the text?", "answer": " It is the first publicly available agent evaluation environment to implement user roles that are not universally identical.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What distributions are shown in Figure 6 of the text?", "answer": " The distribution of intents across the websites are shown in Figure 6.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What are some of the experiment configurations mentioned in the text?", "answer": " The text mentions experiments with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with specific parameters.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " Under what circumstances is the execution halted during the experiments?", "answer": " Execution is halted if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " Why is a high temperature of 1.0 used in the experiments?", "answer": " A high temperature of 1.0 is used to encourage exploration in the experiments.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What is the significance of the agent latching onto the first related piece of information in the text?", "answer": " The agent demonstrates a tendency to latch onto the first related piece of information without sufficiently verifying its relevance or accuracy, which can lead to failures in observation interpretation.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What are some of the failure instances mentioned in the additional error analysis of the text?", "answer": " Failures in observation bias and observation interpretation are mentioned in the additional error analysis.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}, {"question": " What is the hypothesis regarding the observed failures in GPT models mentioned in the text?", "answer": " The observed failures in GPT models are hypothesized to be related to the current pretraining and supervised fine-tuning on dialogues, leading to a lack of explorations and overlooking minor variations in observations.", "ref_chunk": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}], "doc_text": "merge requests and issues. This user also manages a handful of personal projects privately. On Reddit, our chosen profile was a user who actively participates in discussions, with many posts and comments. Lastly, on our E-commerce CMS, we set up a user profile for a shop owner who has full read-and-write access to all system contents. All users are automatically logged into their accounts using a pre-cached cookie. To our best knowledge, this is the first publicly available agent evaluation environment to implement such a characteristic. Existing literature typically operates under the assumption of universally identical user roles Shi et al. (2017); Liu et al. (2018); Deng et al. (2023). A.4 INTENT DISTRIBUTION The distribution of intents across the websites are shown in Figure 6. A.5 EXPERIMENT CONFIGURATIONS We experiment with GPT-3.5-TURBO-16K-0613, GPT-4-0613, and TEXT-BISON-001 with a temperature of 1.0 and a top-p parameter of 0.9. The maximum number of state transitions is set to 30. We halt execution if the same action is repeated more than three times on the same observation or if the agent generates three consecutive invalid actions. These situations typically indicate a high likelihood of execution failure and hence warrant early termination. For TEXT-BISON-001, we additionally allow ten retries until it generates a valid action. Primarily, we use a high temperature of 1.0 to encourage the exploration. To aid replicating the results, we provide the results of GPT-3.5-TURBO-16K-0613 with temperature 0.0 in Table 5 and the execution trajectories in our code repository. 16 Under review CoT UA Hint Model SR \u2713 \u2717 GPT-3.5 6.28 Table 5: The task success rate (SR %) of GPT-3.5-TURBO-16K-0613 with temperature 0.0. A.6 PROMPT FOR F U Z Z Y_M A T C H Help a teacher to grade the answer of a student given a question. Keep in mind that the student may use different phrasing or wording to answer the question. The goal is to evaluate whether the answer is semantically equivalent to the reference answer. question: {{intent}} reference answer: {{reference answer}} all the string \u2019N/A\u2019 that you see is a special sequence that means \u2019not achievable\u2019 student answer: {{prediction}} Conclude the judgement by correct/incorrect/partially correct. Predictions that are judged as \u201ccorrect\u201d will receive a score of one, while all other predictions will receive a score of zero. A.7 THE PROMPTS OF THE BASELINE WEB AGENTS The system message of the reasoning agent for both GPT-3.5 and GPT-4 is in Figure 7, and two examples are in Figure 8. The system message of the direct agent for GPT-3.5 is in Figure 9 and the two examples are in Figure 10. UA hint refers to the instruction of \u201c If you believe the task is impossible to complete, provide the answer as \"N/A\" in the bracket.\u201d. We remove this sentence in our ablation studies. A.8 ADDITIONAL ERROR ANALYSIS Observation Bias Realistic websites frequently present information on similar topics across various sections to ensure optimal user accessibility. However, a GPT-4 agent often demonstrates a tendency to latch onto the first related piece of information it encounters without sufficiently verifying its relevance or accuracy. For instance, the homepage of the E-Commerce CMS displays the best-selling items based on recent purchases, while historical best-seller data is typically accessed via a separate report. Presented with the task of \u201cWhat is the top-1 best-selling product in 2022\u201d, the GPT-4 agent defaults to leveraging the readily available information on the homepage, bypassing the necessary step of generating the report to obtain the accurate data. Failures in Observation Interpretation Interestingly, while GPT-4 is capable of summarizing the observations, it occasionally overlooks more granular information, such as the previously entered input. As in the right-hand example of Figure 11, [5172] StaticText indicates that the search term \u201cDMV area\u201d has already been entered. However, the agent disregards this detail and continuously issues the command type [2430] [DMV area] until it reaches the maximum step limit. Furthermore, the agent often neglects the previous action information that is provided alongside the observation. We hypothesize that these observed failures are related to the current pretraining and supervised fine-tuning on dialogues employed in GPT models Ouyang et al. (2022). These models are primarily trained to execute instructions given immediate observations (i.e.,, the dialogue history); thereby, they may exhibit a lack of explorations. Furthermore, in dialogue scenarios, subtle differences in NL expressions often have less impact on the overall conversation. As a result, models may tend to overlook minor variations in their observations. 17 Under review You are an autonomous intelligent agent tasked with navigating a web browser. You will be given web-based tasks. These tasks will be accomplished through the use of specific actions you can issue. Here\u2019s the information you\u2019ll have: The user\u2019s objective: This is the task you\u2019re trying to complete. The current web page\u2019s accessibility tree: This is a simplified representation of the webpage, providing key information. The current web page\u2019s URL: This is the page you\u2019re currently navigating. The open tabs: These are the tabs you have open. The previous action: This is the action you just performed. It may be helpful to track your progress. The actions you can perform fall into several categories: Page Operation Actions `click [id]`: This action clicks on an element with a specific id on the webpage. `type [id] [content] [press_enter_after=0|1]`: Use this to type the content into the field with id. By default, the \"Enter\" key is pressed after typing unless press_enter_after is set to 0. `hover [id]`: Hover over an element with id. `press [key_comb]`: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v). `scroll [direction=down|up]`: Scroll the page up or down. Tab Management Actions: `new_tab`: Open a new, empty browser tab. `tab_focus [tab_index]`: Switch the browser\u2019s focus to a specific tab using its index. `close_tab`: Close the currently active tab. URL Navigation Actions: `goto [url]`: Navigate to a specific URL. `go_back`: Navigate to the previously viewed page. `go_forward`: Navigate to the next page (if a previous `go_back` action was performed). Completion Action: `stop [answer]`: Issue this"}