{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_Federated_Learning_as_Variational_Inference:_A_Scalable_Expectation_Propagation_Approach_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are the statistics shown in Table 3 for the StackOverflow experiments?", "answer": " The statistics shown in Table 3 for the StackOverflow experiments are the averages and standard deviations aggregated over 5 seeds.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What is the purpose of the StackOverflow experiments mentioned in the text?", "answer": " The purpose of the StackOverflow experiments is to investigate whether FedEP can scale to regimes with a large number of clients.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What does FedSEP stand for?", "answer": " FedSEP stands for stateless stochastic EP.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " Why is the stateful version of FedEP considered meaningless in the context of large number of clients?", "answer": " The stateful version of FedEP is considered meaningless because in setups with a large number of clients, the average client will likely only ever participate in a single update round.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What is the conclusion drawn from the experiments comparing FedSEP to full EP?", "answer": " The conclusion drawn is that FedSEP can almost match the performance of full EP despite being much simpler.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " Why is scaled identity considered a strong baseline in the experiments mentioned?", "answer": " Scaled identity is considered a strong baseline because it works well as an approximation and leads to good performance.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What do the transitions from FedAvg to FedPA/FedEP at the 400th round signify?", "answer": " The transitions signify significant increases in performance observed when switching from FedAvg to FedPA/FedEP.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " Why does the text mention the use of I (Scaled Identity Covariance), M (MCMC), L (Laplace), and V (NGVI) in the experiments?", "answer": " The text mentions the use of these techniques to refer to different inference techniques in the experiments.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What do the experiments on CIFAR study according to the text?", "answer": " The experiments on CIFAR study the challenges when scaling FedEP to richly parameterized neural models with millions of parameters.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}, {"question": " What is the main focus of the StackOverflow experiments?", "answer": " The main focus of the StackOverflow experiments is to demonstrate the scalability of EP to a large number of clients even when assuming clients are stateless.", "ref_chunk": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}], "doc_text": "1240\u2020 \u2212 1290\u2021 50.7(0.4) 50.4(0.5) 47.7(0.3) 49.6(0.6) FedEP (I) FedEP (M) FedEP (L) FedEP (V) 48.7(0.4) 48.8(0.4) 46.5(0.4) 47.8(0.5) 473(17) 461(13) 523(28) 487(24) (133) (\u2212) Table 3: StackOver\ufb02ow Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the best precision (prec.), recall, micro- and macro-F1 (mi/ma-F1) attained by round 1500 (based on 100- round running averages). FedSEP (I) FedSEP (M) FedSEP (L) FedSEP (V) \u2212 \u2212 \u2212 \u2212 48.9(0.4) 48.9(0.4) 47.8(0.4) 48.5(0.5) 48.2(0.4) 48.2(0.4) 47.2(0.4) 47.8(0.4) 438(9) 438(9) 442(10) 440(10) Table 2: CIFAR-100 Experiments. Statistics shown are the averages and standard deviations (subscript in brackets) aggregated over 5 seeds. We measure the number of rounds to reach certain accuracy thresh- olds (based on 10-round running averages) and the best accuracy attained within speci\ufb01c rounds (based on 100-round running averages). FedEP and FedSEP re- fer to the stateful EP and stateless stochastic EP. We use I (Scaled Identity Covariance), M (MCMC), L Table 4: Toy Experiments. Statistics shown are the av- (Laplace), and V (NGVI) to refer to different inference erages and standard deviations of Euclidean distances techniques. \u2020One seed does not reach the threshold. between the estimated and target global mean aggre- gated over 200 random samples of client distributions. \u2021Only one seed reaches the threshold. macro-F1 attained by round 1500 (based on 100-round running averages).6 Due to the size of this dataset, the performance at each round is evaluated on a 10K subsample. The evaluation setup is al- most exactly the same as in prior work (Reddi et al., 2020; Al-Shedivat et al., 2021). Due to space we mainly discuss the CIFAR-100 (\u201cCIFAR\u201d) and StackOver\ufb02ow Tag Prediction (\u201cStackOver\ufb02ow\u201d) re- sults in this section and defer the EMNIST-62 (\u201cEMNIST\u201d) results (which are qualitatively similar) to the appendix (Sec. A.3). Euclidean Distance 5.4 \u00d7 10\u22121 \u00b1 4.7 \u00d7 10\u22121 2.6 \u00d7 10\u22121 \u00b1 2.6 \u00d7 10\u22121 1.1 \u00d7 10\u22127 \u00b1 9.8 \u00d7 10\u22128 Method FedAvg FedPA FedEP CIFAR. In Table 2 and Fig. 2 (left, mid), we compare FedAvg, FedPA, and FedEP with various approaches for approximating the clients\u2019 tilted distributions (Sec. 2.2.2). A notable observation is the switch from FedAvg to FedPA/FedEP at the 400th round, where observe signi\ufb01cant increases in performance. Somewhat surprisingly, we \ufb01nd that scaled identity is a simple yet strong base- line. (We conduct further experiments in Sec. 3.3 to analyze this phenomena in greater detail). We next experiment with stochastic EP (FedSEP, Sec. 2.2.4), a stateless version of FedEP that is more memory-ef\ufb01cient. We \ufb01nd that FedSEP can almost match the performance of full EP despite being much simpler (Fig. 2, right). StackOver\ufb02ow. Experiments on CIFAR study the challenges when scaling FedEP to richly pa- rameterized neural models with millions of parameters. Our StackOver\ufb02ow experiments are on the other hand intended to investigate whether FedEP can scale to regimes with a large number of clients (hundreds of thousands). Under this setup the number of clients is large enough that the average client will likely only ever participate in a single update round, which renders the stateful version of FedEP meaningless. We thus mainly experiment with the stateless version of FedEP.7 Table 3 and Fig. 3 (full \ufb01gure available in the appendix Fig. 5) show the results comparing the same set of approximate client inference techniques. These experiments demonstrate the scalability of EP to a large number of clients even when we assume clients are stateless. 3.3 ANALYSIS AND DISCUSSION The Effectiveness of Scaled Identity. Why does the scaled identity approximation work so well? We investigate this question in the same toy setting as in Sec. 3.1. Fig. 4 (left) compares the scaled- identity EP with FedEP, FedPA, and FedAvg. Unsurprisingly, this restriction leads to worse perfor- mance initially. However, as clients pass messages between each other, scaled-identity EP eventually converges to nearly the same approximation as diagonal EP. The toy experiments demonstrate the effectiveness of scaled identity in terms of the \ufb01nal solution. However, this does not fully explain the benchmark experiments where we observed scaled iden- 6TFF by default considers a threshold-based precision and top-5 recall. Our early experiments found that threshold-based metrics correlate better with loss, and use them in StackOver\ufb02ow experiments. 7This was also due to the practical dif\ufb01culty of storing all the clients\u2019 distributions. 7 FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Loss FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy FedPAFedAvgFedEP (Scaled Identity)FedEP (SG-MCMC)FedEP (Laplace)FedEP (NGVI)Accuracy Published as a conference paper at ICLR 2023 FedPA FedPA FedPA FedPA FedPA FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI) FedAvgFedSEP (Scaled Identity)FedSEP (SG-MCMC)FedSEP (Laplace)FedSEP (NGVI)LossPrecisionRecallMicro-F1Macro-F1 Figure 2: CIFAR-100 Experiments. Left and Middle: loss and accuracy of the server as a function of rounds for FedAvg, FedPA, and (stateful) FedEP with various inference techniques. Right: accuracy as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP. The transitions from FedAvg to FedPA, FedEP, and FedSEP happen at round 400. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. Figure 3: StackOver\ufb02ow Experiments. Curves represent loss, micro-F1, and macro-F1 of the global parameter estimation as a function of rounds for FedAvg, FedPA, and (stateless) FedSEP with various inference tech- niques. The transitions from FedAvg to FedPA and FedSEP happen at round 800. Lines and shaded regions refer to the averages and 2 standard deviations over 5 runs, resp. tity EP to match more involved variants in terms of convergence speed. We hypothesize that as models grow more complex, the gap between scaled identity and other techniques might decrease due to the dif\ufb01culty of obtaining credible estimates of (even diagonal) covariance in high dimen- sional settings. To test this, we revisit the CIFAR-100 task and compare the following two settings: \u201csmall\u201d setting which uses a smaller linear model on the PCA\u2019ed features and has 10.1K parame- ters, and a \u201clarge\u201d setting that uses a linear model on the raw features and has 172.9K parameters. For each"}