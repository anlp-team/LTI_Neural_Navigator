{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Rita_Singh_Rethinking_Voice-Face_Correlation:_A_Geometry_View_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the aim of the study mentioned in the text?", "answer": " The aim of the study is to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without relying on semantic information.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What paradigm is proposed in the study?", "answer": " The study proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What does the study use as a proxy to link the voice and face geometry?", "answer": " The study uses anthropometric measurements (AMs) as a proxy to link the voice and face geometry.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " How is the approach of the study evaluated?", "answer": " The approach is evaluated on a proposed dataset with ground-truth 3D face scans and corresponding voice recordings.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " Which specific parts of the face geometry show significant correlations with voice according to the study?", "answer": " The study finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What are the most commonly used semantic cues in previous works on voice-face matching?", "answer": " The most commonly used semantic cues in previous works on voice-face matching are gender, age, and emotion.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What is the main concern addressed by the study regarding voice-face correlations?", "answer": " The study aims to explore voice-face correlations beyond easily learned semantic biases and questions if reconstructing identity-fidelity 3D face from voice is possible.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " How does the study differentiate itself from previous works in recovering face from voice?", "answer": " The study aims to disable previously used semantics (gender, age, emotion) and focus solely on the voice-face correlation from a pure geometry view.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What is the representation of general 3D facial shape mentioned in the text?", "answer": " General 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}, {"question": " What is the proposed pipeline in the study for voice-AM-face reconstruction?", "answer": " The proposed pipeline first predicts and verifies predictable anthropometric measurements (AMs) from the voice and then utilizes AMs to guide 3D face reconstruction.", "ref_chunk": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}], "doc_text": "3 2 0 2 l u J 6 2 ] V C . s c [ 1 v 8 4 9 3 1 . 7 0 3 2 : v i X r a Rethinking Voice-Face Correlation: A Geometry View Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhiksha Raj1,4 1 Carnegie Mellon University, 2 Max Planck Institute, 3 Microsoft, 4 Mohamed bin Zayed University of Artificial Intelligence ABSTRACT Previous works on voice-face matching and voice-guided face syn- thesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emo- tion. In this paper, we aim to investigate the capability of reconstruct- ing the 3D facial shape from voice from a geometry perspective with- out any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable fa- cial AMs from the voice and uses them to guide 3D face recon- struction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face corre- lation and can serve as a good empirical study for anthropometry science. (a) Voice Production(b) Linear Predictive CodingVoice Code Face Geometry \ud835\udc3b(\ud835\udc67) AM-guided Reconstruction Vocal TrackSpeech Phonatory Module AMs SpeechSpeech(c) Speech-AMs-Face GaussianNoiseLPCFilter VocalTractAir Unit Impulse CCS CONCEPTS \u2022 Computing methodologies \u2192 Appearance and texture represen- tations. KEYWORDS voice, face, vocal tract Figure 1: (a) Human voice production. (b) Linear predictive coding represents the voice by a unit impulse with a set of linear filters which can be interpreted as an estimation of the vocal tract. (c) Our voice-AM-Face pipeline first predicts and verifies predictable anthropometric measurements (AMs) and then uti- lizes AMs to guide 3D face reconstruction. A phonatory module is involved to obtain a better representation for AM prediction. ACM Reference Format: Xiang Li1, Yandong Wen2, Muqiao Yang1, Jinglu Wang3, Rita Singh1, Bhik- sha Raj1,4. 2023. Rethinking Voice-Face Correlation: A Geometry View. In Proceedings of ACM Conference (Conference\u201923). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 The study of face-voice correlation has been extensively investigated in recent years. Previous works on voice-face matching [28, 44, 53], voice-guided face synthesis [9, 16, 19, 54], and voice-guided face modification have indicated a strong correlation between voice and face. The most intuitive and commonly used consensus encoded be- tween voice and face is mainly based on semantics, such as gender, age and emotion. Most prior works aim to learn a semantic corre- spondence between voice and face and conduct crossmodal tasks by leveraging those consensuses. For example, for voice-guided face INTRODUCTION Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201923, July 2023, Ottawa, Canada \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn synthesis, the generated faces have reasonable appearances with proper gender, age and emotion status corresponding to the voice. Those semantic correlations are strong and easy to learn thus domi- nant previous models while a fundamental question we want to cast is, are there any other voice-face correlations except for those coarse semantics? Is reconstructing identity-fidelity 3D face from voice pos- sible? In this paper, we aim to explore the voice-face correlations in a geometry view after constraining all those easily learned semantic biases. There are several previous works investigating recovering face from voice. Most of them are from a 2D perspective [16, 19, 54], which utilize Generative Adversarial Network (GAN) [14, 26] to generate faces with voice as the condition. However, face recovering from voice is ill-posed. [29] found that the recovery mainly focuses on some semantics of the speaker. For example, attributes such as ethnicity has weak or no function while gender and age tend to be recovered. Since those models mainly rely on semantics, the results are not identity-fidelity which means generated faces can look very different from the original ones. In addition, for a 2D face image, identity-unrelated factors like expressions, hairs, glasses, illumina- tion, background, etc., are also involved in the recovery process leading to noisy and unstable outcomes. Different from 2D images, general 3D facial shape is represented by the 3D coordinates of a number of points on its surface called vertices [4] which inherently Conference\u201923, July 2023, Ottawa, Canada excludes the identity-unrelated factors. Moreover, since the topology of 3D facial shape is predefined and consistent across different faces, we can easily measure the reconstruction accuracy with distances between the predicted vertices and their ground truths. Similar to our target, one recent work [47] attempts to recover 3D faces from voice while, due to the lack of ground-truth 3D face scans, they first generate 2D face images from voice and then reconstruct 3D faces guided by an off-the-shelf 3D face reconstruction model. The noise enrolled in the 2D-to-3D face reconstruction makes the result unconvincing. For example, any expression in the 2D face from the first stage will force the reconstructed 3D face to have the same expression. In this way, we consider the face is still determined by the first-stage 2D face image. In our method, we aim to disable all previously used semantics, e.g., gender, age and emotion, and focus on the voice-face correlation from a pure geometry view. Before introducing our method, let"}