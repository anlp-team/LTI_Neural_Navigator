{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Improving_Cascaded_Unsupervised_Speech_Translation_with_Denoising_Back-translation_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the focus of the proposed work described in the text?,answer: The focus is on improving cascaded unsupervised speech translation with denoising back-translation.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What is the main challenge faced by most speech translation models?,answer: Most models heavily rely on parallel data, which is hard to collect especially for low-resource languages.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What is the purpose of building a cascaded speech translation system without leveraging paired data?,answer: The purpose is to overcome the challenge of limited parallel data by using fully unpaired data to train unsupervised systems.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What is denoising back-translation (DBT) and how does it contribute to the unsupervised neural machine translation (UNMT) system?,answer: DBT is a novel approach that increases the BLEU score by 0.7\u20130.9 in all three translation directions within the UNMT system.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " Why is unlabelled data preferred over parallel data in speech translation systems?,answer: Unlabelled data is easier to obtain regardless of modalities compared to parallel data.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What is the purpose of normalizing the output of the UASR in the cascaded system?,answer: The purpose is to simplify the pipeline and reduce inference time by feeding normalized text into the UNMT.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What issue does the denoising back-translation method aim to address in unsupervised speech translation?,answer: It aims to tackle error propagation issues in a fully unsupervised manner within the neural machine translation system.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " What are some recent developments in end-to-end speech-to-text translation and speech-to-speech translation systems?,answer: Recent developments include direct S2TT and direct S2ST systems that aim to solve error propagation and inference latency problems.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " How does the proposed work contribute to the field of unsupervised speech translation compared to previous supervised methods?,answer: The work yields comparable results to some early supervised methods, showing promise in unsupervised speech translation.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}, {"question": " Where can the results of the unsupervised speech translation be observed?,answer: The results can be observed on an established website provided in the text.", "ref_chunk": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}], "doc_text": "3 2 0 2 y a M 2 1 ] L C . s c [ 1 v 5 5 4 7 0 . 5 0 3 2 : v i X r a Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation Yu-Kuan Fu1\u2217, Liang-Hsuan Tseng1\u2217, Jiatong Shi2, Chen-An Li1, Tsu-Yuan Hsu1, Shinji Watanabe2, Hung-yi Lee1 1College of Electrical Engineering and Computer Science, National Taiwan University 2Language Technologies Institute, Carnegie Mellon University 1{r11942083,r11921067,b08902123,b08201047,hungyilee}@ntu.edu.tw 2{jiatongs@cs.cmu.edu,shinjiw@cmu.edu} Abstract Most of the speech translation models heav- ily rely on parallel data, which is hard to col- lect especially for low-resource languages. To tackle this issue, we propose to build a cas- caded speech translation system without lever- aging any kind of paired data. We use fully unpaired data to train our unsupervised sys- tems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early super- vised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed de- noising back-translation (DBT), a novel ap- proach to building robust unsupervised neural machine translation (UNMT). DBT success- fully increases the BLEU score by 0.7\u20130.9 in all three translation directions. Moreover, we simpli\ufb01ed the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website 1. 1 Introduction Speech translation (ST) aims to convert speech from one language to another, allowing seamless communication between individuals speaking in different languages. Conventional speech-to-text translation (S2TT) system is accomplished by con- catenating automatic speech recognition (ASR) and text-to-text machine translation (MT) (Ney, 1999) modules. Meanwhile, the cascaded speech-to- speech translation (S2ST) system further appends a text-to-speech (TTS) synthesis module after the S2TT system (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). Recently, direct S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems emerge to solve the \u2217Equal Contribution 1 https://anonymous-acl2023.github.io/us2s-demo/ error propagation and inference latency problem of the cascaded systems. Some direct S2TT systems have shown comparable results or even outperform the cascaded S2TT systems (Wang et al., 2021; Bentivogli et al., 2021). Most of the ST systems are trained on parallel data, which is extremely limited, especially for low- resource languages. This situation strongly hinders the performance of direct ST systems. Although cascaded systems could overcome this issue by collecting data for each component separately, they still face the challenge of domain mismatch caused by variations in data distribution across different corpora. Compared to parallel data, unlabelled data is much easier to obtain regardless of modalities. The \ufb01rst unsupervised speech-to-text translation (US2TT) aligned spoken words with written words and then applied unsupervised word-by-word trans- lation (Chung et al., 2018, 2019b). Moreover, with the recent progress in unsupervised automatic speech recognition (UASR) (Baevski et al., 2021), unsupervised neural machine translation (UNMT) (Lample et al., 2017; Lample and Conneau, 2019; Song et al., 2019), and unsupervised text-to-speech (UTTS) synthesis (Ni et al., 2022; Liu et al., 2022b), Wang et al. (2022) built an unsupervised speech-to- speech translation (US2ST) system. Besides build- ing cascaded US2ST, they also generated pseudo labels for training direct US2TT systems. Their work might be considered concurrent with ours, mainly focusing on techniques to conduct simple and effective US2ST systems. Although the idea of cascaded US2ST is simple, directly concatenating UASR, UNMT, and UTTS might suffer from severe error propagation prob- lems. For example, UNMT is trained on clean text, and small perturbations may greatly affect the translation results (Belinkov and Bisk, 2017). To tackle the issue, research on robust NMT has been widely investigated (Di Gangi et al., 2019; Sperber 1 et al., 2017; Sun et al., 2020); however, improv- ing the robustness of UNMT is rarely studied. In this paper, we proposed denoising back-translation (DBT), a novel method to build a robust UNMT system. DBT combines the idea of denoising auto- encoding and back-translation (BT), dealing with error propagation issues in a fully unsupervised fashion. Brie\ufb02y speaking, the pseudo text of DBT is generated from text with some noise, and the model should learn to reconstruct the clean text from the pseudo text. According to our results, this method substantially increases the quality of the cascaded unsupervised speech translation system. Another issue with cascaded systems is the high inference latency. To address this, we integrated two parts of our cascaded system. First, the output of the UASR is normalized (stripped of punctuation marks and cases). Then, a text detokenizer is used to reconstruct the unnormalized text and feed it into the UNMT. By \ufb01ne-tuning or continually training the UNMT with normalized source language text, the model is able to translate normalized source text into unnormalized target text. While there may be some degradation in performance, this method simpli\ufb01es the pipeline of the cascaded system and signi\ufb01cantly reduces inference time. We evaluate our cascaded US2ST system on CVSS (Jia et al., 2022), a multilingual S2ST cor- pus; and CoVoST 2 (Wang et al., 2020b), a multi- lingual ST corpus of which CVSS built on top. We demonstrate that our US2ST could yield reason- able results across multiple translation directions, some of which are even better than the previous su- pervised approach2. Moreover, the proposed DBT method can help improve the performance by mit- igating error propagation and domain mismatch problems. 2 Related works 2.1 ST Traditional S2TT system is composed of ASR and MT (Ney, 1999), and S2ST system further append a TTS model after the MT model (Lavie et al., 1997; Wahlster, 2000; Nakamura et al., 2006). However, cascaded systems might suffer from error propaga- tion and inference latency. Recent develpments in end-to-end S2TT (B\u00e9rard et al., 2016; Weiss et al., 2017) and S2ST (Jia et al., 2019, 2021) systems have been proposed to address these issues. 2All data are public, and we will release the code, so the results will be easy to reproduce. 2 The main"}