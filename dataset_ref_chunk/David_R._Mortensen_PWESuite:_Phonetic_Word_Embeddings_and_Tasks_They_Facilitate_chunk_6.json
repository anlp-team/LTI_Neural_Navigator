{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/David_R._Mortensen_PWESuite:_Phonetic_Word_Embeddings_and_Tasks_They_Facilitate_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What do the results in Figure 5 show regarding the relationship between dimensionality and task performance?", "answer": " The results show that neither too small nor too large a dimensionality is useful for the proposed tasks, and there is little interaction between task type and dimensionality.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " Based on the study, how does the model ranking vary across dimensions?", "answer": " Model ranking based on each task is very similar across dimensions, with Spearman and Pearson correlations of 0.61 and 0.79, respectively.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " How does changing the training data size affect the individual tasks?", "answer": " Similarly to changing the dimensionality, the individual tasks react to changing the training data size without an effect of the task variable.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " What is the role of phonological features, particularly articulatory features, in phonology according to the text?", "answer": " Phonological features, especially articulatory features, play a strong role in phonology by capturing the similarity between sounds.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " What is the origin of the widely used articulatory feature set mentioned in the text?", "answer": " The articulatory feature set employed by PanPhon originates in the Sound Pattern of English by Chomsky and Halle (1968).", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " What are some applications that benefit from phonetic word embeddings mentioned in the text?", "answer": " Applications include cognate/loanword detection, multilingual named entity recognition, keyphrase extraction, spelling correction, phonotactic learning, and more.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " How can phonetic word embeddings help in spoken language understanding?", "answer": " Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " What is one of the limitations mentioned in the text regarding the training of models?", "answer": " One limitation is that the models train on phonemic transcriptions, which cannot capture finer-grained phonetic distinctions.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " What is the proposed future work mentioned in the text after establishing the standardized evaluation suite?", "answer": " The proposed future work includes enlarging the pool of languages and including more tasks.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}, {"question": " How do phonological word embeddings contribute to linguistic analysis?", "answer": " Phonological word embeddings serve as a tool to study what phonological and phonetic features are encoded by speakers for linguistic analysis.", "ref_chunk": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}], "doc_text": "choice of dimensionality, keeping all other things equal, affects individual task performance. The results in Figure 5 (top) show that neither too small d=8Art. Distance d=8Art. Features d=36Characters Figure 4: T-SNE projection of articulatory dis- tance and embedding spaces from the metric learn- ing models with articulatory or character features. Each point corresponds to one English word. Dif- ferently coloured clusters were selected in the ar- ticulatory distance space (left) and highlighted in other spaces. d is the average distance within the clusters normalized with average distance between points (unitless). Articulatory Features (center) re- sult in tighter clusters than Characters (right). nor too large a dimensionality is useful for the pro- posed tasks. Furthermore, there is little interaction between the task type and dimensionality. As a re- sult, model ranking based on each task is very sim- ilar across dimensions, with Spearman and Pear- son correlations of 0.61 and 0.79, respectively. A natural question is how data-intensive the pro- posed metric learning method is. For this, we con- strained the training data size and show the results in Figure 5 (bottom). Similarly to changing the di- mensionality, the individual tasks react to changing the training data size without an effect of the task variable. The Spearman and Pearson correlations are 0.64 and 0.65, respectively. 6. Discussion 6.1. The Field of Phonology Phonological features, especially articulatory fea- tures, play a strong role in phonology since Bloom- field (1993) and the work of Prague School lin- guists (Trubetskoy, 1939; Jakobson et al., 1951). The widely used articulatory feature set employed by PanPhon originates in the monumental Sound Pattern of English (Chomsky and Halle, 1968), which assumes a universal set of discrete phono- logical features and that all speech sounds in all languages consist of vectors of these features. The similarity between these feature vectors should capture the similarity between sounds. This po- sition is born out in our results. These features encode a wealth of knowledge gained through decades of linguistic research on how the sound systems of languages behave, both synchronically and diachronically. While there is evidence that 102 Analogy Rhyme Human Sim. Art. Dist. 101 Retrieval 0.75 0.25Score 100 Training data size (k) Cognate 0.50 1.00 Figure 5: Metric Learner performance with varying dimensionality (top) and varying training data size (bottom) with articulatory features. Bands show 95% confidence intervals from t-distribution. phonological features are emergent rather than uni- versal (Mielke, 2008), these results suggest they can nevertheless contribute robustly to computa- tional tasks. Phonetic word embeddings also rep- resent more closely how humans and, in particular, children, interact with language (through sound rather than abstract meaning). Their study may have further applications in the fields of phonetics and phonology. 6.2. Applications Phonetic word embeddings are more niche than their semantic counterparts but there are many applications shown to benefit from them. Cognate/loanword detection (Rama, 2016; Nath et al., 2022b,a). Along with semantic simi- larity, phonetic similarity measured in some latent transformation of articulatory features suggests cognacy or lexical borrowing. Multilingual named entity recognition (Bharad- waj et al., 2016; Chaudhary et al., 2018). Learn- ing word embeddings from PanPhon features enables cross-lingual transfer for named entity recognition since named entities will likely bear pronunciation similarities across languages. Keyphrase extraction (Ray Chowdhury et al., 2019; Fahd Saleh Alotaibi and Gupta, 2022). Keyphrase extraction from Tweets for disaster relief can leverage PanPhon features to take ad- vantage of the tendency for orthographic vari- ants of the same word across different Tweets to share similar pronunciations. Spelling correction (Tan et al., 2020; Zhang et al., 2021). Imbuing word embeddings with pronunciation similarity helps in correcting typing mistakes by substituting words with their pho- netic transcription and similar-sounding words. Another approach is to pretraing a spelling- correction model on phonetic units. Phonotactic learning (Mirea and Bicknell, 2019; Romero and Salamea, 2021). Phonetic informa- tion is a necessary part in deriving phonotactic patterns and vector representations. Multimodal word embeddings (Zhu et al., 2020, 2021). Phonetic and syntactic information can be incorporated into semantic word embeddings. Spoken language understanding (Chen et al., 2018, 2021; Fang et al., 2020). Training with phoneme embeddings can reduce errors from confusing phonetically similar words in automatic speech recognition so that such errors do not propagate to downstream natural language un- derstanding tasks. Language identification (Zhan et al., 2021; Salesky et al., 2021) Phonological features help in distinguishing between languages and their identification. Poetry generation (Talafha and Rekabdar, 2021; Yi et al., 2018) Word sounds and their pronunciations are critical for poetry and incor- poration of this information helps in automatic poetry generation. Linguistic analysis (Hamilton et al., 2016; Ryskina, Maria and Rabinovich, Ella and Berg- Kirkpatrick, Taylor and Mortensen, David R. and Tsvetkov, Yulia, 2020; Francis et al., 2021) Apart from direct applications, there exist many in- vestigations and analyses on what phonological and phonetic features are encoded by speakers. Phonological word embeddings are one tool by which this can be studied. 6.3. Limitations and Ethics As hinted in Section 5.1, we evaluate models that use supervision from some of the tasks during training. Specifically, the metric learning models have an advantage on the articulatory distance task. Nevertheless, the models perform well also on other, more unrelated tasks and we also provide models without this supervision. We also do not make any distinction between training and develop- ment data. This is for a practical reason because some of the methods we use for comparison are not open embeddings and need to see all con- cerned words during training. Another limitation of our work is that we train on phonemic transcriptions, which cannot capture finer grained phonetic distinctions. Phonemic dis- tinctions may be sufficient for applications such as rhyme detection, but not for tasks such as phone recognition or dialectometry. We attempted to be inclusive with the language selection and do not foresee any ethical issues. 7. Future Work After having established the standardized evalua- tion suite, we wish to pursue the following: enlarging the pool of languages, \u2022 including more tasks"}