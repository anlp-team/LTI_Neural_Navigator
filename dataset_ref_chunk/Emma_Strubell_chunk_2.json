{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Emma_Strubell_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are Large Language Models (LLMs) primarily trained on?", "answer": " Minimally processed web text", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What social biases can text generated by LLMs inadvertently perpetuate?", "answer": " Stereotypes towards marginalized groups like the LGBTQIA+ community", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " How do the authors of the first paper analyze bias in the text generated by an LLM?", "answer": " Using regard score", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What method based on SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs?", "answer": " Post-hoc method based on chain-of-thought prompting", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What is the focus of the work on making scalable meta learning practical?", "answer": " Introducing SAMA to combine advances in implicit differentiation algorithms and systems", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " How does SAMA reduce computational burden in meta learning programs?", "answer": " By avoiding explicit computation of second-order gradient information", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What drawback is addressed by the proposed regularizer in the paper on self-training for unsupervised domain adaptation?", "answer": " Erroneous pseudo labels arising from confirmation biases", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What is the term used to describe the discrepancy between computational throughput improvements and wall-clock inference latency?", "answer": " Framework tax", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What phenomenon is observed to be growing as hardware speed increases over time?", "answer": " The framework tax disparity", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}, {"question": " What key challenge is addressed by the authors in combining partial annotation with self-training to reduce annotation cost?", "answer": " Determining which sub-structures to select to label", "ref_chunk": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}], "doc_text": "social and environmental implications in the development of future-generation NLP models.\", ['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']] ['Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models', '2023', ['arXiv.org', 'ArXiv'], 'Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.', ['Harnoor Dhingra', 'Preetiha Jayashanker', 'Sayali S. Moghe', 'Emma Strubell']] ['Making Scalable Meta Learning Practical', '2023', ['arXiv.org', 'ArXiv'], 'Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.', ['Sang Keun Choe', 'Sanket Vaibhav Mehta', 'Hwijeen Ahn', 'W. Neiswanger', 'Pengtao Xie', 'Emma Strubell', 'Eric P. Xing']] ['Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints', '2023', ['arXiv.org', 'ArXiv'], 'Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.', ['Rajshekhar Das', 'Jonathan M Francis', 'Sanket Vaibhav Mehta', 'Jean Oh', 'Emma Strubell', 'Jose Moura']] ['The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\\\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.', ['Jared Fernandez', 'Jacob Kahn', 'Clara Na', 'Yonatan Bisk', 'Emma Strubell']] ['Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training', '2023', ['Conference on Empirical Methods in Natural Language Processing', 'Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], \"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\", ['Zhisong Zhang', 'Emma Strubell', 'E. Hovy']]"}