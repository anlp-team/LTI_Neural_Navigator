{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Active_Retrieval_Augmented_Generation_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What does the text suggest about the impact of unnecessary retrieval?,answer: It can introduce noise and impede the original generation process.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " According to the text, what percentage range of sentences leads to good performance when triggering retrieval?,answer: 40%-80%", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " How does the performance of FLARE compare when using different masking thresholds?,answer: Performances vary based on the masking threshold.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " What is the conclusion regarding the effectiveness of implicit and explicit query formulation methods in FLARE?,answer: Both methods are similarly effective in reflecting information needs.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " What has been studied in both text and code generation tasks in relation to retrieval and refinement?,answer: Iterative and adaptive retrieval and refinement.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " How does FLARE differ from other methods in terms of generation and retrieval strategies?,answer: FLARE differs in the granularity of generation and retrieval strategies.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " What are some examples of browser-enhanced LMs mentioned in the text?,answer: WebGPT and WebCPM.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " What is proposed in the framework discussed in the text to aid long-form generation?,answer: An active retrieval augmented generation framework.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " What is one limitation mentioned in the text regarding the effectiveness of FLARE?,answer: FLARE did not provide significant gains in the case of Wizard of Wikipedia and ELI5 datasets.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}, {"question": " How does the text suggest that the issue of interleaving generation and retrieval can be potentially alleviated?,answer: With special architectural designs that independently encode retrieved documents and input/generation.", "ref_chunk": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}], "doc_text": "indicating that unnecessary retrieval can introduce noise and impede the original gen- eration process. We found triggering retrieval for 40%-80% of sentences usually leads to a good per- formance across tasks/datasets. Effectiveness of different query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking \u03b2 EM F1 Prec. Rec. 0.0 0.2 0.4 0.6 0.488 0.498 0.510 0.506 0.576 0.588 0.597 0.593 0.571 0.582 0.591 0.586 0.605 0.616 0.627 0.622 Table 5: Performance of FLARE with respect to the masking threshold \u03b2 on 2WikiMultihopQA. ASQA-hint EM D-F1 R-L DR WikiAsp UniEval E-F1 R-L Implicit 45.7 36.9 37.7 37.3 Explicit 46.2 36.7 37.7 37.2 53.4 53.4 18.8 27.7 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds \u03b2. Retrieving directly with the complete sentence (\u03b2 = 0) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with browser to enhance factuality using reinforcement learning or supervised train- ing where multiple queries can be triggered before generation. FLARE is built on text-based retrievers but can be combined with a browser to potentially improve retrieval quality. 8 Conclusion To aid long-form generation with retrieval aug- mentation, we propose an active retrieval aug- mented generation framework that decides when and what to retrieve during generation. We imple- ment this framework with forward-looking active retrieval that iteratively uses the upcoming sentence to retrieve relevant information if it contains low- confidence tokens and regenerates the next sen- tence. Experimental results on 4 tasks/datasets demonstrate the effectiveness of our methods. Fu- ture directions include better strategies for active retrieval and developing efficient LM architectures for active information integration. 9 Limitations We also conduct experiments on Wizard of Wikipedia (Dinan et al., 2019) and ELI5 (Fan et al., 2019), and found that FLARE did not provide sig- nificant gains. Wizard of Wikipedia is a knowledge- intensive dialogue generation dataset where the out- put is relatively short (\u223c20 tokens on average) so retrieving multiple disparate pieces of information might not be necessary. ELI5 (Fan et al., 2019) is a long-form QA dataset requiring in-depth an- swers to open-ended questions. Due to issues men- tioned in Krishna et al. (2021) such as difficulties of grounding generation in retrieval and evalua- tion, both single-time retrieval and FLARE did not provide significant gains over not using retrieval. From an engineering perspective, interleaving gen- eration and retrieval with a naive implementation increases both overheads and the cost of generation. LMs need to be activated multiple times (once for each retrieval) and a caching-free implementation also requires recomputing the previous activation each time after retrieval. This issue can be poten- tially alleviated with special architectural designs that encode the retrieved documents Dqt and the input/generation (x/y<t) independently. Acknowledgements This work was supported in part by a grant from the Singapore Defence Science and Technology Agency and the IBM PhD Fellowship. We thank Chunting Zhou, Amanda Bertsch, Uri Alon, Hi- roaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo Schick, Kaixin Ma, Shuyan Zhou, and Songwei Ge for their insightful discussions and help with the experiments. References Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Si- monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Bal- timore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1870\u20131879. Association for Computational Linguistics. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya,"}