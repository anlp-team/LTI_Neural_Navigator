{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Maarten_Sap_Value_Kaleidoscope:_Engaging_AI_with_Pluralistic_Human_Values,_Rights,_and_Duties_chunk_28.txt", "num_qa_pairs": 10, "qa_list": [{"question": " Is there a formal mechanism to extend/augment/build on the dataset mentioned?", "answer": " As of now, there is no formal mechanism, but interested parties can reach out to the authors.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Were users of the Delphi user demo informed about the recording of their queries for research purposes?", "answer": " Yes, users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Does the dataset relate to other ethically protected subjects?", "answer": " No, the dataset does not relate to other ethically protected subjects.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Were ethical review applications/reviews/approvals obtained for datasets related to people?", "answer": " Yes, ethical review applications/reviews/approvals were obtained for datasets related to people.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Are there community norms for data collected from human communications?", "answer": " Yes, there are community norms for data collected from human communications.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Could this dataset expose people to harm or legal action?", "answer": " No, the dataset does not directly relate to people, so it does not expose them to harm or legal action.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Does the dataset unfairly advantage or disadvantage a particular social group?", "answer": " No, the dataset does not directly relate to people, so it does not unfairly advantage or disadvantage any social group.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Were people provided with privacy guarantees for the dataset?", "answer": " No, the dataset does not directly relate to people, so no privacy guarantees were provided.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Does the dataset comply with the EU General Data Protection Regulation (GDPR)?", "answer": " Yes, the dataset complies with GDPR and other standards due to the lack of personally identifiable information.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}, {"question": " Does the dataset contain sensitive or confidential information?", "answer": " No, the dataset does not contain sensitive or confidential information, but may contain inappropriate or offensive text.", "ref_chunk": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}], "doc_text": "is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those con- tributions. What is the process for communicating/dis- tributing these contributions to users? As of now, there is no formal mechanism to extend/aug- ment/build on this dataset, but anyone interested should reach out to the authors. N.7 Legal & Ethical Considerations If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, pho- tos, interactions, transactions, etc.) Users of the Delphi user demo explicitly agreed that their queries could be recorded and used for research purposes, and the rest of the data was machine-generated. If it relates to other ethically protected subjects, have ap- propriate obligations been met? (e.g., medical data might include information collected from animals) It does not relate to other ethically protected subjects. If it relates to people, were there any ethical review ap- plications/reviews/approvals? (e.g. Institutional Review Board applications) If it relates to people, were they told what the dataset would be used for and did they con- sent? What community norms exist for data collected from human communications? If consent was obtained, how? Were the people provided with any mechanism to revoke their consent in the future or for certain uses? Data does not relate directly to people. If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm? Data does not relate directly to people. If it relates to people, does it unfairly advantage or dis- advantage a particular social group? In what ways? How was this mitigated? Data does not relate directly to people. If it relates to people, were they provided with privacy guarantees? If so, what guarantees and how are these en- sured? Data does not relate directly to people. Does the dataset comply with the EU General Data Pro- tection Regulation (GDPR)? Does it comply with any other standards, such as the US Equal Employment Op- portunity Act? Especially because the data does not relate to people or have personally identifiable information, it does comply with these laws. Does the dataset contain information that might be con- sidered sensitive or confidential? (e.g., personally identi- fying information) Does the dataset contain information that might be considered inappropriate or offensive? No, the dataset does not contain sensitive or confidential information (like personally identifiable information). The dataset does potentially contain inappropriate or offensive text, especially in the demo-sourced situations, and we ad- vise that the dataset is not for all eyes before providing ac- cess. While we did not want to completely remove inappro- priate or offensive situations so that the model could perform well in surfacing relevant values, rights, and duties in these cases, we did attempt to ensure that the generated data does not include inappropriate or offensive content via manual in- spection and toxicity filters."}