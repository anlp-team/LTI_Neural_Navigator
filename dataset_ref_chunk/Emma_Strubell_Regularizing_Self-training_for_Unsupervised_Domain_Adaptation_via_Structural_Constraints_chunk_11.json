{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Emma_Strubell_Regularizing_Self-training_for_Unsupervised_Domain_Adaptation_via_Structural_Constraints_chunk_11.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the default threshold set for all experiments in the text?", "answer": " 0.90", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " How does the number of valid regions change as the threshold decreases?", "answer": " The number of valid regions will increase at the expense of region-label consistency with ground-truth.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What happens to the performance beyond a certain point (\u03c4p = 0.90) in the text?", "answer": " The performance deteriorates.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " According to Table 9 in the text, what happens to the mean Intersection over Union (mIoU) with an increase in threshold?", "answer": " The mIoU increases with an increase in threshold up to a certain point (\u03c4p = 0.90), beyond which the performance deteriorates.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What is DACS and PAC in the context of the text?", "answer": " DACS refers to a base method, while PAC is a visual comparison between DACS and the ground-truth under GTA\u2192Cityscapes settings.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What is the purpose of the algorithm Unsupervised domain adaptation via PAC-UDA in the text?", "answer": " The algorithm aims to adapt target-domain parameters using a pseudo-label and target training dataset, along with specific parameters and objectives.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What is the Peak prominence threshold used in the algorithm in the text?", "answer": " The Peak prominence threshold is denoted as \u03b4peak.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What is the purpose of the Objectness constraint loss weight (\u03b1obj) in the algorithm in the text?", "answer": " The weight \u03b1obj is used to control the effect of the objectness-constraint on the target-domain performance.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " What are the inputs required for the algorithm in the text to perform unsupervised domain adaptation?", "answer": " The inputs include a pseudo-label, target training dataset with depth, initial model parameters, histogram bins, peak prominence threshold, RGB-segments, spatial dimensions of the depth map, region-label threshold, objectness constraint loss weight, and number of training iterations.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}, {"question": " How does the algorithm in the text compute valid regions and region labels?", "answer": " The algorithm computes valid regions and region labels based on a threshold on majority-voting based region-label and region-wise frequency of pseudo-label classes.", "ref_chunk": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}], "doc_text": "more reliably than the base method (DACS). target-domain performance. At the same, time the number of such valid object-regions is likely to be small, which, may reduce the overall effect of the objectness-constraint on target-domain performance. As one decreases the thresh- old, the number of valid-regions will increase at the expense of region-label consistency with ground-truth. Thus, evalu- ating the performance over a range of values is crucial. Indeed, we observe in Table 9 that the mIoU increases with increase in threshold upto a certain point (\u03c4p = 0.90), beyond which the performance deteriorates. We, thus, set 0.90 as our default threshold for all our experiments. C. Additional Visualisations In Figure 5, we provide additional qualitative compari- son between DACS+PAC, DACS and the ground-truth un- der GTA\u2192Cityscapes settings. 14 Algorithm 1 Unsupervised domain adaptation via PAC-UDA i )}Nt Input: Pseudo-label (\u02dcy); Target training dataset with depth (Dt i, ht depth = {(xt i, \u02dcyt i=1 ); Initial model parameters (\u03b80 = {\u03c80, \u03c60}); Number of histogram bins (b); Peak prominence threshold (\u03b4peak); Number of RGB-segments (ks); Spatial dimensions of depth map (H \u00d7 W ); Region-label threshold (\u03c4p); Objectness constraint loss weight (\u03b1obj); Number of training iterations (Ttrain) Output: Target-domain adapted parameters (\u03b8\u2217 = {\u03c8\u2217, \u03c6\u2217}) 1: for ttr \u2190 1 to Ttrain do {(xt i, ht 2: Compute Luda 3: Lobj = 0 4: for i \u2190 1 to N B i )}N B i=1 \u223c Dt h i, yt (cid:46) Randomly sample a training batch from target-domain (cid:46) Self-training based adaptation objective (see Section 3) (cid:46) Initialise objectness-constraint t t do 5: 6: 7: 8: Initialize V d = {} Hist (cid:0){him}HW FindPeaks(F d; \u03b4peak) \u2192 {\u00b5k}kd for k \u2190 1 to kd do (cid:46) Empty list of depth-segments (cid:46) Histogram of depth values (HOD) (cid:46) Cluster-center assignment using HOD m=1; b(cid:1) \u2192 F d 9: 10: 11: k=1 k = {m|m \u2208 {1, . . . , HW }, |hm \u2212 \u00b5k| < |hm \u2212 \u00b5k(cid:48)| \u2200k(cid:48) (cid:54)= k} V d V d.append(V d k ) (cid:46) Depth segments (cid:46) Depth-segment list update 12: 13: 14: 15: 16: 17: end for Initialize V s = {} SLIC(xi; ks) \u2192 {Lk}ks for k \u2190 1 to ks do (cid:46) Empty list of RGB-segments (cid:46) RGB-segment labelling using SLIC [1] k=1 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: V s k = {m|m \u2208 {1, . . . , HW }, label(m) = Lk} V s.append(V s k ) end for Initialize V = {} Initialize k = 0 for i(cid:48) \u2190 1 to ks do for j(cid:48) \u2190 1 to kd do k \u2190 k + 1 Vk = {m|m \u2208 V s V.append(Vk) i(cid:48) , m \u2208 V d j(cid:48)} end for (cid:46) RGB-segments (cid:46) RGB-segment list update (cid:46) Empty list of object-regions (cid:46) region-index (cid:46) Region-index update (cid:46) Unique object-region assignment (cid:46) Object-region list update 30: 31: 32: 33: 34: 35: end for Fk = Histogram({\u02dcyt Initialize U = {} Initialize L = {} for k \u2190 1 to K (cid:48) do im}m\u2208Vk ) \u2200k = {1, . . . , K (cid:48)} (cid:46) Region-wise frequency of pseudo-label classes (cid:46) Empty list of valid regions (cid:46) Empty list of valid region labels 36: if then max c (cid:80) c Fk[c] Fk[c] \u2265 \u03c4p (cid:46) Threshold on majority-voting based region-label 37: 38: 39: 40: Uk = Vk U.append(Uk) Lk = arg max L.append(Lk) c Fk[c] (cid:46) Valid region assignment (cid:46) Valid-region list update (cid:46) Region-label assignment (cid:46) Valid-region label list update end if 41: 42: 43: end for Using U and L, compute Lt Lobj = Lobj + Lt 44: 45: 46: obj,i end for Lpac = Luda + \u03b1obj \u2217 Lt N B t \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b7\u2207Lpac obj 47: 48: end for obj,i 15 (cid:46) Objectness constraint, Eqn. . 7 (cid:46) Overall PAC-UDA objective (cid:46) Parameter update"}