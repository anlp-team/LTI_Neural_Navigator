{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_3D_Semantic_Segmentation_in_the_Wild:_Learning_Generalized_Models_for_Adverse-Condition_Point_Clouds_chunk_12.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some of the methods evaluated in the text for domain adaptation?,        answer: Baseline Dropout, Perturbation PolarMix, MMD, PCL, PointDR, ADDA, Ent-Min, Self-training, CoSMix    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " Which method performs the best over the domain generalized segmentation task SemanticKITTI\u2192SemanticSTF?,        answer: PointDR    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " What is the class-wise IoU (%) on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target for the PointDR method?,        answer: SynLiDAR\u2192SemanticSTF: 32.7    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " What is the mIoU (%) for PointDR using the baseline drop-out, perturbation, flipping, and jittering data augmentation techniques?,        answer: 26.9    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " How does the performance of PointDR vary with different contrastive loss weight \u03bbcl?,        answer: \u03bbcl 0.0: 24.4, 0.05: 28.2, 0.10: 28.6, 0.15: 27.3, 1.0: 25.1    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " What happens when the momentum updated weight m is too large for the PointDR models?,        answer: The memory bank updates too slowly to capture the latest and representative feature embeddings, leading to a clear segmentation performance drop.    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " How does the mIoU (%) change for PointDR models with different momentum updated weight m for the memory bank B?,        answer: m 0.98: 28.1, 0.99: 28.6, 0.999: 26.1    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " In which scenario did the state-of-the-art domain adaptation methods show a performance comparison for dense fog?,        answer: SemanticKITTI\u2192SemanticSTF adaptation for dense fog    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " What is the class-level IoU (%) performance for the UDA methods in the setting of adaptation to individual conditions for SemanticKITTI\u2192SemanticSTF adaptation?,        answer: 68.0    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}, {"question": " Among Source-only, ADDA, Ent-Min, Self-training, and CoSMix methods, which one performs the best for adaptation to light fog in SemanticKITTI\u2192SemanticSTF?,        answer: CoSMix    ", "ref_chunk": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}], "doc_text": "k n u r t . a r r e t SemanticKITTI\u2192SemanticSTF(snow) Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 49.5 58.5 73.6 66.5 59.4 64.0 66.2 0.0 0.0 0.0 3.4 0.0 0.0 0.0 0.3 30.5 0.0 9.3 4.7 0.0 10.4 0.5 5.4 5.5 3.5 0.0 8.2 0.0 11.6 13.2 1.1 5.8 14.7 0.7 16.7 10.8 5.2 19.8 32.4 30.5 9.2 21.3 23.9 20.4 34.4 30.1 32.8 31.6 33.0 SynLiDAR\u2192SemanticSTF(snow) - - - - - - - - - - - - 42.1 41.9 45.7 55.3 50.8 38.9 43.0 14.9 18.0 10.9 3.6 16.9 15.2 15.2 0.0 2.5 0.1 0.1 0.2 2.3 1.7 71.5 76.4 80.6 77.8 68.4 79.6 76.8 26.7 30.5 32.8 36.1 24.4 35.1 30.3 29.3 31.8 45.2 34.2 36.6 41.3 36.1 24.0 32.7 12.8 12.6 24.1 11.2 27.6 17.8 19.8 20.0 25.1 24.1 23.1 22.2 12.9 1.9 20.9 2.6 15.4 4.1 11.7 1.7 20.1 2.4 19.1 3.0 13.8 3.4 Table 10. Class-wise IoU on domain generalization with SemanticKITTI or SynLiDAR as the source and validation set of snow in SemanticSTF as the target. \u2019-\u2019 represents no samples captured in snow in the validation set of SemanticSTF. Baseline Dropout [39] Perturbation PolarMix [50] MMD [26] PCL [56] PointDR (Ours) 24.6 35.9 27.1 53.4 20.8 30.7 34.2 2.7 2.8 2.4 2.3 2.7 1.1 4.0 1.5 3.7 6.8 4.1 6.0 4.4 7.4 2.4 3.0 6.8 6.0 4.8 6.2 7.5 0.0 0.0 0.2 1.2 0.2 0.3 0.1 32.2 21.9 31.0 27.9 31.3 34.6 36.2 - - - - - - - - - - - - 0.4 10.0 4.8 1.9 0.5 1.7 12.0 18.3 22.8 19.7 21.5 21.0 22.0 22.7 0.0 0.0 0.0 0.3 0.1 0.3 0.0 33.3 33.2 26.3 45.2 29.6 37.8 48.8 13.8 14.8 12.4 20.8 12.2 12.6 19.9 15.7 17.1 14.0 21.7 15.0 16.4 19.9 14.9 16.8 22.0 18.8 16.6 14.2 18.9 18.1 16.5 16.4 16.5 21.8 19.9 17.0 Method Baseline drop-out perturbation flipping jittering All PointDR mIoU 24.4 25.7 25.9 25.2 26.9 26.1 28.6 Table 11. Comparison of data augmentation techniques and the proposed PointDR. PointDR performs clearly the best over domain generalized segmentation task SemanticKITTI\u2192SemanticSTF. \u03bbcl mIoU 0.0 24.4 0.05 28.2 0.10 28.6 0.15 27.3 1.0 25.1 Table 12. Performance of PointDR models with different contrastive loss weight \u03bbcl in Eq. 2 in the paper. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop. m 0.98 0.99 0.999 mIoU 28.1 28.6 26.1 Table 13. Performance of PointDR models with different momentum updated weight m for the memory bank B. B. Domain adaptation B.1. Implementation details In Tables 4 and 5 of the submitted paper, we examine state-of-the-art UDA methods over the proposed normal-to-adverse UDA scenario. Specifically, we selected typical UDA methods from the popular synthetic-to-real UDA benchmark [38, 51] as the baseline methods as described in Section 5.2 of the paper. We adopt MinkowskiNet [7] as the segmentation model as in synthetic-to-real UDA. When implementing ADDA [46], entropy minimization [47], and self-training [65], we follow the same implementation and training configurations as the synthetic-to-real UDA [51] and leverage TorchSparse library [42]] (with version 1.1.0) based on PyTorch [32] library. While for CoSMix [38], we use the officially released codes based on MinkowskiEngine with default training parameters for the adaptation. We report mIoU of the covered classes for individual adverse weather conditions in Table 5. B.2. Detailed class-level results In Tables 14, 15, 16, and 17 below, we present the class-level IoU performance for the UDA methods that are examined in the setting of adaptation to individual conditions in Table 5 of the paper. 14 e l o p 30.8 28.2 24.4 29.8 30.0 30.1 30.0 10.1 15.7 19.0 10.5 11.3 14.7 20.7 . f a r t 10.1 7.0 9.5 10.1 11.4 26.8 14.1 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t 68.0 68.0 74.8 70.9 74.2 Table 14. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for dense fog. \u2019-\u2019 represents no samples captured in dense fog in the validation set of SemanticSTF. Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 56.4 63.4 68.0 68.2 76.5 - - - - - - - - 10.1 14.3 4.9 24.4 27.0 0.0 0.0 0.0 0.0 0.0 0.6 2.1 1.9 5.4 4.7 15.4 8.0 7.6 4.8 0.0 0.0 38.7 0.0 0.0 0.0 0.6 0.1 0.0 0.3 0.5 22.8 25.6 39.4 31.3 29.9 0.0 0.0 0.0 0.0 1.8 63.6 60.6 68.8 65.9 62.1 36.6 45.4 50.5 46.7 48.0 62.8 64.8 61.0 59.2 62.6 29.4 30.4 28.3 31.6 37.3 53.5 52.6 63.3 55.4 59.6 Methods r a c e l c . i b e l c . t m k c u r t . v - h t o . s r e p t s l c . i b t s l c . t m d a o r . i k r a p . w e d i s . g - h t o . d l i u b e c n e f . t e g e v k n u r t . a r r e t Source-only ADDA [46] Ent-Min [47] Self-training [65] CoSMix [38] 68.3 69.4 73.4 73.2 70.3 Table 15. Comparison of state-of-the-art domain adaptation methods on SemanticKITTI\u2192SemanticSTF adaptation for light fog. 55.1 61.4 67.1 69.3 74.9 0.0 0.0 0.0"}