{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_19.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of the 2-pass cascaded encoder described in the text?", "answer": " To run a 2nd-pass beam search and improve accuracy of long-tail named entities.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " According to the text, what is the relationship between classical and E2E approaches in speech recognition?", "answer": " Competition between classical and E2E approaches is reflected in benchmarks, with E2E models gaining momentum.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " What is the word error rate reported for the best classical hybrid systems on the Librispeech task?", "answer": " Around 2.3% (test-clean) and 4.9% (test-other) word error rate.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " How do E2E models perform in low-resource conditions according to the text?", "answer": " E2E models do not scale well to low-resource conditions.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " Why is further research needed for E2E modeling, according to the text?", "answer": " To take full advantage of the benefits of E2E modeling, especially in conditions where E2E models are not a perfect match.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " What is a challenge mentioned in the text regarding rare events in ASR?", "answer": " Rare events like rare words in ASR still provide a challenge.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " What is a disadvantage of E2E models mentioned in the text?", "answer": " E2E models involve a loss in modularity, which might impact the explainability and reusability of models.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " What is one advantage of E2E models mentioned in the text?", "answer": " E2E models are trained from data without relying on secondary knowledge sources.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " What potential solution is suggested for exploiting text-only resources in E2E model training?", "answer": " Exploring solutions beyond training data generation using TTS.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}, {"question": " According to the text, what is an important guiding principle of ASR research and development?", "answer": " Performance, boosted by benchmark tasks and international evaluation campaigns.", "ref_chunk": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}], "doc_text": "2-pass cascaded encoder to run a 2nd-pass beam search [89]; and, a neural LM re-scorer to help improve accuracy long-tail named entities. This model is the best ASR system that Google has released to date, both in terms of quality and latency. Fig. 10. E2E ASR performance improvement in the Librispeech task. amount of unlabeled in-domain speech data (e.g., Libri-light 60K hours [322]). Relationship to Classical ASR Speech recognition research has always been pushed by international evaluation campaigns (e.g. as lead by NIST) and corresponding benchmark tasks. The competition between classical and E2E approaches is nicely reflected in the widely used Librispeech [317] and Switchboard [316] tasks, showing that E2E models gain momentum. As shown in Figure 10, on Librispeech, the current best-published classical hybrid systems range around 2.3% (test-clean) and 4.9% (test-other) word error rate [323], [222], while there already are a number of E2E systems providing similar performance [224], [205], [320], [206], with some E2E systems clearly outperforming former state-of-the-art results with word error rates down to 1.8% (test-clean) and 3.7% (test-other) [324] with similar results reported in [45], [97]. Merging insights from classical HMM-based and monotonic RNN-T provided similarly well results with a limited training budget [124]. Finally, when trained on Switchboard 300h, the current best result, obtained with an E2E system [180] is 5.4% compared to 6.6% word error rate for the best hybrid system result [325] on the HUB5\u201900 Switchboard test set, in Figure 9 X. AREAS FOR FUTURE WORK Currently, E2E models dominate the academic debate on ASR. However, at least partly, this is not (yet?) reflected in the corresponding commercial deployment of E2E ASR architectures. E2E models are not yet the perfect match for all ASR conditions and further research is needed to take full advantage of the benefits of E2E modeling. E2E models seem to perform really well when training data is abundant, while not scaling well to low-resource conditions. Similarly, domain change requires a flexible exchange of lan- guage models, which is natural for classical ASR models based on a separation of acoustic and language models. Ongoing research on the use of external language models in E2E models and internal language model estimation already is promising, but can be expected to see further improvements. Top E2E ASR systems usually require orders of magnitude more training epochs than comparable classical ASR systems, and further research into efficient and robust optimization and training schedules is needed. The high level of integration of E2E models also involves a loss in modularity, which might support the explainability and reusability of models. Also, more efficient training schedules might take advantage of modularity. One assumed advantage of E2E models is that everything is trained from data and secondary knowledge sources (e.g. pronunciation lexica and phoneme sets) are avoided. However, rare events, like rare This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 19 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 words in ASR still provide a challenge, which needs further research. With the missing separation of acoustic and language mod- els, the question arises of how to exploit text-only resources in E2E model training - do we foresee solutions beyond training data generation using TTS? We note that a number of recent works have explored approaches to combine speech and text modalities by attempting to implicitly or explicitly map them into a shared space [159], [335], [336], [337], [338], [339], [340], [341]. Furthermore, high-performance E2E solutions exist for both discriminative problems like ASR, as well as generative problems like TTS, how can both be exploited jointly to support semi-supervised training based on text-only and/or audio-only data on top of transcribed speech audio [28], [342]? recognition; multilingual ASR; adaptation to new application domains, and speakers; etc.), which we do not cover due to space limitations. ACKNOWLEDGMENT The authors would like to thank Julian Dierkes, Yifan Peng, Zolt\u00b4an T\u00a8uske, Albert Zeyer, and Wei Zhou for their help on refining our manuscript. REFERENCES [1] T. Bayes, \u201cAn Essay Towards Solving a Problem in the Doctrine of Chances,\u201d Philosophical Transactions of the Royal Society of London, vol. 53, pp. 370\u2013418, 1763. [2] F. Jelinek, Statistical Methods for Speech Recognition. Cambridge, MA: MIT Press, 1997. For AED architectures, we observe a length bias, which complicates the decoding process. Although many heuristics are known to tackle length bias in AED, we are still missing a well-founded explanation for it, as well as a corresponding remedy of the original model. [3] L. R. Rabiner, \u201cA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,\u201d Proc. of the IEEE, vol. 77, no. 2, pp. 257\u2013286, Feb. 1989. [4] H. A. Bourlard and N. Morgan, Connectionist Speech Recognition: a Hybrid Approach. Norwell, MA: Kluwer Academic Publishers, 1993. [5] F. Seide, G. Li, and D. Yu, \u201cConversational Speech Transcription Using Context-Dependent Deep Neural Networks,\u201d in Proc. Interspeech, Florence, Italy, Aug. 2011, pp. 437\u2013440. Other open research problems include speaker adaptation and robustness to recording conditions, especially in mismatch situations. The E2E principle also provides a promising candi- date to solve multichannel ASR by providing an E2E solution jointly tackling the source separation, speaker diarization and speech recognition problem [343], [26]. Finally, we need to investigate, if E2E is a suitable guiding principle, and how different E2E ASR models relate to each other as well as to classical ASR approaches. The most important guiding principle of ASR research and development has been performance, and ASR has been boosted strongly by widely used benchmark tasks and international evaluation campaigns. With the current diversity of classical and E2E models, we also need to resolve the question of what con- stitutes state-of-the-art in ASR today, and can we expect a common state-of-the-art ASR architecture in the future? [6] V. Fontaine, C. Ris, and H. Leich, \u201cNonlinear Discriminant Analysis for Improved"}