{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_UNSSOR:_Unsupervised_Neural_Speech_Separation_by_Leveraging_Over-determined_Training_Mixtures_chunk_13.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the main difference observed between the filter lengths of UNSSOR and iRAS?", "answer": " The best filter length for UNSSOR is different from that of iRAS.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " According to the text, which method shows a higher performance: UNSSOR or iRAS?", "answer": " The best performance of UNSSOR is higher than that of iRAS.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " In Fig. 6(a), what can be observed about the performance when setting K to 5 and 25 compared to 20?", "answer": " Setting K to 5 and 25 produces worse performance than setting it to 20.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " Why would using a very long filter for time-domain Wiener filtering prevent separation?", "answer": " A very long filter would have a large degrees of freedom to fit the mixture well, potentially hindering separation.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " What is the benefit of using FCP over time-domain Wiener filtering in terms of computational expense?", "answer": " FCP is less computationally-expensive as it requires inverting a smaller matrix compared to time-domain Wiener filtering.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " Why is it important to tune the filter length as mentioned in the text?", "answer": " The filter length is an important hyper-parameter that affects the performance of the separation.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " According to the text, what contributes to the effectiveness of the proposed system?", "answer": " The strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism contribute to the effectiveness of the proposed system.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " How does UNSSOR perform with TCN-DenseUNet compared to TF-GridNet?", "answer": " UNSSOR works to some extent with TCN-DenseUNet, but the results are not as good as those obtained by using TF-GridNet.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " What are the characteristics of the DPRNN architecture used in the experiments?", "answer": " DPRNN has a window size of 4 ms, a hop size of 1 ms, 6 layers, 256 bases, 128 bottleneck dimension, and ReLU activation.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}, {"question": " What is the spatial embedding dimension set to in the six-channel case as detailed in the text?", "answer": " The spatial embedding dimension is set to 360 in the six-channel case.", "ref_chunk": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}], "doc_text": "1) \u00d7 8 + 32)/1000 \u00d7 8000) so that they can result in the same filter length in time. From the figures, we observe that the best filter length (in seconds) is different for UNSSOR and iRAS, and the best performance of UNSSOR is higher than that of iRAS. 19 9 128 13 384 25K (=I+1+0) in UNSSOR 8 256 4 17 10 5 6 1472 1024 2 512 (a) 0 16SDR (dB) M in iRAS (filter future 64 samples) 1280 12 20 768 14 M in iRAS (filter future 64 samples) 384 9 128 7.8 13 17 1536 13.0SDR (dB) 1024 25K (=I+1+1) in UNSSOR 2.6 512 5 256 10.4 0.0 1280 5.2 (b) 21 768 Figure 6: Averaged SDR (dB) results of UNSSOR and iRAS using various filter taps in cases of using (a) 6-channel input and loss; and (b) 1-channel input and 6-channel loss on SMS-WSJ. Vertically-corresponded M and K mean that the filter lengths in time are the same. Best viewed in color. We point out that using a very long filter (i.e., a large M ) for time-domain Wiener filtering would prevent separation, since, in that case, the filter would have a large degrees of freedom to filter \u02c6z(c) to fit yp very well and obtain a small LiRAS (see (13)), even though \u02c6z(c) is not a good separation result. From Fig. 6(a), it can be observed that a very large M (e.g., 1472) does not yield good separation; and in addition, a very small M (e.g., 128) is also not good, as the linear filter could be just too short to fit the mixture yp well. Similar trend can also be observed in the results of UNSSOR. For example, in Fig. 6(a), setting K to 5 and 25 produces worse performance than to 20. We can see that the filter length is an important hyper-parameter to tune. We emphasize that, to compute the closed-form solution of time-domain Wiener filtering (see (13)), we need to invert a big M \u00d7 M matrix for each mixture, while in FCP (see (6)), we only need to invert a much smaller K \u00d7 K matrix for each of the F frequencies. Using FCP is clearly less computationally-expensive, given that the time complexity of matrix inversion is typically O(n3). This also indicates that if the same amount of computation is required for linear filtering, FCP can use a much longer filter (in time) than time-domain Wiener filtering. K UNSSOR\u2019s effectiveness when used with other DNN architectures We observe that the effectiveness of the proposed system comes from both the strong modelling capabilities of TF-GridNet and the contributions of the UNSSOR mechanism itself. Without using UNSSOR to deal with the ill-posed problem, the modelling capability of strong DNNs cannot be unleashed to separate speakers; and without using a strong DNN, the patterns in speech cannot be modelled well to realize good separation. We expect UNSSOR to work with many DNN architectures, as long as the architecture is reasonably strong and can effectively deal with reverberation. To validate this, we experiment UNSSOR with DNN arachitectures with lower modelling capability. We select two representative separation models from the literature, TCN-DenseUNet [74] and DPRNN [75]. We replace TF-GridNet with the TCN-DenseUNet described in [74], and train the network using the same training configurations. TCN-DenseUNet [74] contains a temporal convolution network sandwiched by a UNet with DenseNet blocks. It is a reasonably strong separation model, which is fully convolutional and shares many similarities with many contemporary DNN architectures [79\u201383]. According to [23], it is worse than TF-GridNet in supervised separation tasks. We provide the unsupervised separation results in Table 9, which are obtained by using six-channel input and loss. We observe that UNSSOR works to some extent with TCN-DenseUNet, and the results are not as good as the ones in Table 1 obtained by using TF-GridNet. The DPRNN architecture [75] in our experiments has a window size of 4 ms and a hop size of 1 ms. It has 6 layers. The number of bases is 256. The bottleneck dimension is 128. The number of hidden units in each BLSTM in each direction is 128. We apply ReLU as the encoder non-linearity and as the non-linearity for embedding masking. The chunk size is set to 64 and the chunk overlap is 50%. To leverage spatial information for model training, we follow the strategy proposed in [84] (see its Fig. 2 to get the idea), where spectral embeddings are learned together with spatial embeddings and 20 Table 9: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using TCN-DenseUNet [74] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 11.1 11.1 11.2 10.7 10.7 10.8 9.7 9.7 9.8 2.92 2.92 2.93 0.770 0.770 0.773 4a PIT (supervised) 14.6 13.9 13.4 3.58 0.878 Table 10: Averaged results of 2-speaker separation on SMS-WSJ (6-channel input and loss), obtained by using DPRNN [75] architecture. Val. set Test set Row Systems I J Loss SDR (dB) SDR (dB) SI-SDR (dB) PESQ eSTOI 0a Mixture 0.1 0.1 0.0 1.87 0.603 19 0 LMC+ISMS 2a 2b UNSSOR + Corr. based freq. align. 19 0 LMC+ISMS 19 0 LMC+ISMS 2c UNSSOR UNSSOR + Oracle freq. align. 9.2 9.2 9.3 8.9 8.9 9.0 8.0 8.0 8.1 2.68 2.68 2.68 0.724 0.724 0.727 4a PIT (supervised) 12.3 11.7 11.3 3.00 0.820 DNN-estimated masks are used to mask spectral embeddings. In the six-channel case, the spatial embedding dimension is set to 360, following [84]. Differently from the Fig. 2 of [84], we do not use microphone-pair-wise Conv1D layers to obtain spatial embeddings. Instead, we obtain them by using a Conv1D layer with P (= 6) input channels and 360 output channels. We first use the DPRNN to obtain intermediate separation results"}