{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of introducing a blank token \u27e8b\u27e9 for alignment in E2E models such as RNN-T and CTC?", "answer": " The purpose is to marginalize across all alignments during optimization.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " According to the text, where is most of the power of the E2E model located?", "answer": " Most of the power is in the encoder.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " How can the decoder in transducer models be simplified based on research findings?", "answer": " It can be replaced with a simple embedding lookup table that attends to only a few previous tokens.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " What task can extended decoder architectures enable according to research findings?", "answer": " They can enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " Why is endpointing important in streaming speech recognition systems?", "answer": " Endpointing is important so that the ASR result can be finalized and sent for appropriate action.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " How have streaming RNN-T models approached endpointing?", "answer": " They have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " What algorithm is required for the efficient computation of the training criterion and its gradient in E2E models?", "answer": " The forward-backward algorithm is required.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " What does the training criterion for AED models lack in comparison to other models?", "answer": " The training criterion for AED models does not have a latent variable A for explicit alignment.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " How is the training of E2E models different from classical hidden Markov models for ASR?", "answer": " E2E models provide mechanisms to solve the underlying sequence alignment problem, either explicitly or implicitly, while classical HMMs use explicit alignments only.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}, {"question": " What technique is used during training where the ground truth history is used as a label context?", "answer": " A teacher-forcing technique is used.", "ref_chunk": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}], "doc_text": "(which is equivalent to maximizing the total conditional log-likelihood). they do not assume conditional A. Alignment in Training E2E models such as RNN-T and CTC introduce an addi- tional blank token \u27e8b\u27e9 for alignment. Therefore optimization implies marginalizing across all alignments, as follows: On the decoder side, research for transducer models has shown that a large LSTM decoder can be replaced with a sim- ple embedding lookup table, that attends to only a few previous tokens from the model [47], [104], [105], [106], [107]. This demonstrates that most of the power of the E2E model is in the encoder, which has been a consistent theme of both E2E as well as classical hybrid HMM models. However, improved decoder modeling may also be effective depending on the specific downstream task. Research has shown that extended decoder architectures enable pre-training and adaptation of the decoder using extensive text-only data, leading to accuracy gains [108], [109]. For example, one approach separates RNN- T\u2019s prediction network into separate blank and vocabulary prediction (LM) components, where the LM component can be trained with text data [108]. In addition, in line with the growing interest in large language models in recent years, research has also begun on solving multiple tasks, including speech recognition, using only an auto-regressive, GPT-style decoder [110], [111]. D. Integrated Endpointing An important characteristic of streaming speech recognition systems is that they must endpoint quickly, so that the ASR result can be finalized and sent to the server for the appro- priate action to be performed. Endpointing is typically done with an external voice-activity detector. Since endpointing is both an acoustic and language model decision, recent works in streaming RNN-T models [112], [113] have investigated predicting a microphone closing token \u27e8eos\u27e9 at the end of the utterance \u2013 e.g., \u201cWhat\u2019s the weather \u27e8eos\u27e9\u201d. Following the notation from Section III, this is done by including an \u27e8eos\u27e9 token as part of the set of class labels C and encouraging the model to predict this token to terminate decoding. These models have shown improved latency and WER trade-off by having the endpointing decision predicted as part of the model. Furthermore, [114], [115] explored using the CTC blank symbol for endpoint detection. V. TRAINING E2E MODELS In general, training of E2E models follows deep learn- ing schemes [116], [117], with specific consideration of the sequential structure and the latent alignment problem to be handled in ASR. E2E ASR models may be trained end-to- end, notwithstanding potential elaborate training schedules Lex = \u2212 N (cid:88) (cid:88) log P (Cn, An|Xn) n=1 An This requires the forward-backward algorithm [118], [119] for efficient computation of the training criterion and its gradient, with minor modifications for CTC, RNN-T, and RNA models, as well as classical (full-sum) hybrid ANN/HMMs correspond- ing to the differences in alignments defined in each of these models. In comparison, AED models are based on implicit alignment modeling approaches, and the training criterion does not have a latent variable A for explicit alignment as: Lim = \u2212 N (cid:88) log P (Cn|Xn) n=1 We refer the interested reader to the individual papers for further details on the training algorithms [13], [14], [15], [16], [46], [48], [53], [71], [120]. As shown in Section III-A, in both explicit and implicit alignment cases, P (C|X) is factorized with respect to input time t and output position i, respectively, and the factorized distribution is conditioned on the label context ci\u22121 , except for CTC. For example, in the AED case: 1 log P (C|X) = (cid:80)L ). During training, we use a teacher-forcing technique where the ground truth history is used as a label context. i=1 log P (ci|X, ci\u22121 1 As part of the training procedure, all E2E as well as classical hidden Markov models for ASR provide mechanisms to solve the underlying sequence alignment problem - either explicitly via corresponding latent variables, as in CTC, RNN-T or RNA, and also hybrid ANN/HMM, or implicitly, as in AED models. Also, the distinction between speech and silence needs to be considered, which may be handled explicitly by introducing silence as a latent label (hybrid ANN/HMM), or implicitly by not labeling silence at all, as currently is the standard in virtually all E2E models. E2E models also may take advantage of hierarchical training schedules. These schedules may comprise several separate training passes and explicit, initially generated alignments that are kept fixed for some Viterbi-style [121], [122], [123] train- ing epochs before re-enabling E2E-style full-sum training that marginalizes over all possible alignments. Such an alternative approach is employed by Zeyer et al. [52], where an initial full-sum RNN-T model is used to generate an alignment and continue with framewise cross-entropy training. This greatly simplifies the training process by replacing the summation over all possible alignments in Eq. (4) by a single term cor- responding to the alignment sequence generated. Recently, a This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 similar procedure has been introduced in [124] also employing E2E models, only. In this work, CTC is used to initialize the training and to generate an initial alignment, followed by intermediate Viterbi-style RNN-T training and final full-sum fine tuning, which improved convergence compared to full- sum-only training approaches. It is interesting to note that in contrast to the RNN-T and RNA label-topologies, CTC does not require alignments with single label emissions per label position. However, training CTC models eventually does lead to single label emissions per hypothesized label. An analysis of this property of CTC training which is usually called peaky behavior can be found in [125] and references therein. Laptev et al. [126] even introduces a CTC variant without non-blank loop transitions. B. Training with External Language Models E2E ASR models generally are normalized on"}