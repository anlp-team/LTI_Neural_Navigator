{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_KD-DLGAN:_Data_Limited_Image_Generation_via_Knowledge_Distillation_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of AGKD and CGKD as mentioned in the text?", "answer": " AGKD and CGKD aim to improve the generation performance by distilling and preserving knowledge from CLIP.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " How does combining AGKD and CGKD affect performance according to the text?", "answer": " Combining AGKD and CGKD leads to the best performance.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What does the KD-DLGAN method complement, based on the text?", "answer": " KD-DLGAN complements the state-of-the-art data-limited generation methods.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What task does the text mention exploring KD-DLGAN in besides generation?", "answer": " The text mentions exploring KD-DLGAN in tasks such as image translation and editing.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " Who funded the study mentioned in the text?", "answer": " The study is funded by the Ministry of Education Singapore and Singapore Telecommunications Limited.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What conference is referenced for the Unsupervised multi-target domain adaptation through knowledge distillation?", "answer": " The Winter Conference on Applications of Computer Vision.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What is the topic of the paper by Ruizhe Cheng et al. mentioned in the text?", "answer": " The paper discusses data-efficient zero-shot learning with self-distillation.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " Which paper discussed model compression for knowledge distillation?", "answer": " The paper by Cristian Bucilua, Rich Caruana, and Alexandru Niculescu-Mizil.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What method is proposed for data-free knowledge distillation for object detection?", "answer": " Data-free knowledge distillation for object detection is proposed by Akshay Chawla et al.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}, {"question": " What does the paper by Geoffrey Hinton et al. focus on distilling?", "answer": " The paper focuses on distilling the knowledge in a neural network.", "ref_chunk": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}], "doc_text": "over\ufb01tting by forcing harder learning tasks and distilling more general knowledge from CLIP. CGKD improves the generation diversity by distilling and preserving the diverse image-text correlation within CLIP. Extensive experiments show that both AGKD and CGKD can improve the gen- eration performance and combining them leads to the best performance. We also show that KD-DLGAN complements the state-of-the-art data-limited generation methods consis- tently. Moving forward, we will explore KD-DLGAN in more tasks such as image translation and editing. Acknowledgement This study is funded by the Ministry of Education Sin- gapore, under the Tier-1 scheme with a project number RG94/20, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Arti\ufb01cial Intelligence Lab for Enter- prises (SCALE@NTU). References [1] Unsupervised multi-target domain adaptation through In Proceedings of the IEEE/CVF knowledge distillation. Winter Conference on Applications of Computer Vision, pages 1339\u20131347, 2021. 2 [2] Alex Andonian, Shixing Chen, and Raffay Hamid. Robust cross-modal representation learning with progressive self- In Proceedings of the IEEE/CVF Conference distillation. on Computer Vision and Pattern Recognition (CVPR), pages 16430\u201316441, June 2022. 1, 3 [3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. In Interna- Wasserstein generative adversarial networks. tional conference on machine learning, pages 214\u2013223. PMLR, 2017. 2 [4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? Advances in neural information processing systems, 27, 2014. 2 [5] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high \ufb01delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 5, 6 [6] Cristian Bucilua, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535\u2013541, 2006. 2 [7] Akshay Chawla, Hongxu Yin, Pavlo Molchanov, and Jose Alvarez. Data-free knowledge distillation for object detec- tion. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3289\u20133298, 2021. 2 [8] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Man- mohan Chandraker. Learning ef\ufb01cient object detection mod- els with knowledge distillation. Advances in neural informa- tion processing systems, 30, 2017. 2 [9] Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, and Joseph E. Gonzalez. Data-ef\ufb01cient language-supervised In Proceedings of zero-shot learning with self-distillation. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 3119\u20133124, June 2021. 1, 3 [10] Kaiwen Cui, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Fangneng Zhan, and Shijian Lu. Genco: generative co- training for generative adversarial networks with limited In Proceedings of the AAAI Conference on Arti\ufb01cial data. Intelligence, volume 36, pages 499\u2013507, 2022. 2 [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009. 5, 6 [12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 1, 2 [13] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Improved training of Dumoulin, and Aaron Courville. wasserstein gans. arXiv preprint arXiv:1704.00028, 2017. 2 [14] Ishaan Gulrajani, Colin Raffel, and Luke Metz. Towards gan benchmarks which require generalization. arXiv preprint arXiv:2001.03653, 2020. 2 [15] Saurabh Gupta, Judy Hoffman, and Jitendra Malik. Cross modal distillation for supervision transfer. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 2827\u20132836, 2016. 2 [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in neural information processing systems, pages 6626\u20136637, 2017. 5 [17] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distill- arXiv preprint ing the knowledge in a neural network. arXiv:1503.02531, 2(7), 2015. 2, 8 [18] Jiaxing Huang, Kaiwen Cui, Dayan Guan, Aoran Xiao, Fangneng Zhan, Shijian Lu, Shengcai Liao, and Eric Xing. Masked generative adversarial networks are data-ef\ufb01cient generation learners. In Advances in Neural Information Pro- cessing Systems. 2 [19] Liming Jiang, Bo Dai, Wayne Wu, and Chen Change Loy. Deceive d: Adaptive pseudo augmentation for gan training with limited data. Advances in Neural Information Process- ing Systems, 34:21655\u201321667, 2021. 2, 5, 6 [20] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 2 [21] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Training generative arXiv preprint Jaakko Lehtinen, and Timo Aila. adversarial networks with limited data. arXiv:2006.06676, 2020. 2, 5, 6 [22] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- In Proceedings of the ing the image quality of stylegan. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110\u20138119, 2020. 5 [23] Ali Koksal and Shijian Lu. Rf-gan: A light and recon\ufb01g- urable network for unpaired image-to-image translation. In Proceedings of the Asian Conference on Computer Vision, 2020. 2 [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5 [25] Nupur Kumari, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Ensembling off-the-shelf models for gan training. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 10651\u201310662, June 2022. 2, 8 [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training for uni- \ufb01ed vision-language understanding and generation. arXiv preprint arXiv:2201.12086, 2022. 8 [27] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, and Antonio Torralba. Diverse image generation via self- In Proceedings of the IEEE/CVF Con- conditioned gans. ference on Computer Vision and Pattern Recognition, pages 14286\u201314295, 2020. 2 [28] Yifan Liu, Ke Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang. Structured knowledge distillation for In Proceedings of the IEEE/CVF semantic segmentation. Conference on Computer Vision and Pattern Recognition, pages 2604\u20132613, 2019. 2 [29] Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan Zhang, and Weiming Hu. Open- vocabulary one-stage detection with hierarchical visual- In Proceedings of the language knowledge distillation."}