{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_The_Multimodal_Information_Based_Speech_Processing_(Misp)_2022_Challenge:_Audio-Visual_Diarization_And_Recognition_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are the metrics provided in Table 1 for evaluating the speaker diarization systems?", "answer": " The metrics are false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " Why does the VSD system outperform the ASD system in terms of MISS, SPKERR, and DER?", "answer": " The visual modality of the VSD system is not disturbed by the acoustic environment unlike the ASD system, which results in better performance.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " What is mentioned as a potential reason for the high false alarm rate in the VSD system?", "answer": " The high false alarm rate in the VSD system is potentially due to the lip movement in the silent segments.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " What is the advantage of combining the audio and visual modalities in the AVSD system?", "answer": " Combining the audio and visual modalities in the AVSD system yields the best performance, as it overcomes the individual weaknesses of each modality.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " How many experiments are designed for the diarization and recognition system according to Table 2?", "answer": " Six experiments are designed for the diarization and recognition system.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " What impact does the high MISS and SPKERR rate have on the ASD+ASR system?", "answer": " The high MISS and SPKERR rate in the ASD+ASR system results in a large number of deletion errors of target speakers and insertion errors of interfering speakers.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " How does the visual modality of the speaker diarization module dominate the performance in the VSD+ASR system?", "answer": " In the VSD+ASR system, the visual modality of the speaker diarization module dominates the performance by reducing substitution errors and improving the whole system performance.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " What does incorporating audio modality information to modify video modality in AVSD lead to?", "answer": " Incorporating audio modality information to modify video modality in AVSD significantly improves the results compared to VSD, and the AVDR system results are also improved.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " How does the TV background noise pose a challenge in the far-field audio system?", "answer": " The TV background noise may cover the voice of the target speakers and contain the voice of irrelevant speakers, interfering with speaker diarization and speech recognition.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}, {"question": " What difficulties are pointed out for challenge participants in the text?", "answer": " The text points out potential difficulties such as far-field video quality, indistinguishable speakers, and the impact of audio and visual modalities.", "ref_chunk": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}], "doc_text": "For the far-\ufb01eld video in Sessionk, we \ufb01rst segment the whole video according to Tstart j and Tdur j j 4.1. Baseline Results Table 1 shows the false alarm (FA) rate, missed detection (MISS) rate, speaker error (SPKERR) rate, and the DER for the audio-only speaker diarization systems (ASD), the visual-only speaker diariza- tion system (VSD) and the audio-visual speaker diarization system (AVSD), where the latter is the baseline system of the AVSD track. For the ASD system, we use the VBx method [33]. For the VSD sys- tem, we use the result from the visual encoder module as described in Section 3.1. The ASD system has poor results, most likely due to the loud TV background noises and high speaker overlap ratios, result- ing in high MISS and SPKERR rates. Because the visual modality is not disturbed by the acoustic environment, the VSD system out- performs the ASD system in terms of MISS, SPKERR, and DER. However, VSD system has a high FA rate, potentially due to the lip movement in the silent segments. Combining the audio and visual modalities in the AVSD system yields the best performance, showing that both modalities can be combined to overcome their individual weaknesses. As shown in Table 2, we design 6 experiments for diarization and recognition system. The \ufb01rst two experiments are the speech recognition modules with the oracle speaker (OS) diarization re- sults. The other experiments are the combinations of speaker di- arization module and speech recognition module, e.g., ASD+ASR, VSD+ASR, VSD+AVSR, and AVSD+AVSR, where the latter is the baseline system of the AVDR track. For the ASD+ASR system, the high MISS and SPKERR rate results in a large number of deletion errors of target speakers. In addition, the high SPKERR rate leads to insertion errors of interfering speakers. Comparing the ASD+ASR system and the VSD+ASR system indicates that visual modality of speaker diarization module dominates the performance of the whole In contrast to the VSD+ASR diarization and recognition system. j Authorized licensed use limited to: TU Delft Library. Downloaded on August 24,2023 at 10:38:09 UTC from IEEE Xplore. Restrictions apply. VSD AVSD Lip ROI-SPK 1 60 50 Lip ROI-SPK 2 ) 40 T=0.18 T=0.36 T=0.92 T=1.38 T=1.64 T=1.98 T=2.28 T=2.52 T=2.88 % R E D ( 30 20 Far-field Audio 10 GT ASD 0 VSD 200 ~ 300 300 ~ 400 400 ~ 500 500 ~ 600 AVSD Average number of Lip ROIs pixels GT AVSD+ASR (cid:12562)(cid:7661)(cid:8455)(cid:13425) (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:8475)(cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) (cid:10366)(cid:8144) * * * * (cid:13834)(cid:15266)(cid:13834)(cid:24484)(cid:7467) * (cid:11669)(cid:23270)(cid:17797) (cid:24484)(cid:17159)(cid:18642)(cid:9059) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 2. The DER comparison between the VSD and AVSD systems for different pixel values of Lip ROIS in the conversations AVSD+AVSR (cid:12562)(cid:7661)(cid:11860)(cid:13559) (cid:7436)(cid:13926)(cid:7520)(cid:7438)(cid:18150)(cid:24404) * * (cid:24484)(cid:7467) (cid:24484)(cid:7777)(cid:8944)(cid:9059) Fig. 4. Another example in a session with the comparison of results from different systems Lip ROI-SPK 1 Lip ROI-SPK 2 T=0.16 T=1.23 T=2.47 T=3.39 T=4.18 T=4.67 T=5.22 T=5.73 T=6.43 for SPK 1. Because AVSD incorporates audio modality informa- tion to modify video modality, the results are signi\ufb01cantly improved compared with VSD, and AVDR system results are also improved. Far-field Audio 4.2.2. TV Background Noise GT ASD VSD AVSD GT (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:16366)(cid:19904)(cid:9500) (cid:12562)(cid:11058)(cid:7487)(cid:12710)(cid:7639) (cid:12562)(cid:10911)(cid:8974)(cid:7487)(cid:12710) ASD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * VSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) ((cid:11002)) (cid:8969)(cid:20390)(cid:11523) * * ((cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467)) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) ((cid:11002)) * * * * (cid:12562)(cid:11533)(cid:13852) * * ((cid:12620)(cid:13883)(cid:9000)) AVSD+AVSR (cid:7425)(cid:7565)(cid:7434)(cid:9692)(cid:7573) (cid:8969)(cid:20390)(cid:11523)(cid:24484)(cid:7467) (cid:8969)(cid:20390)(cid:11523)(cid:8944)(cid:18150)(cid:24404) * * * * (cid:12562)(cid:11533)(cid:13852) * * Fig. 3. An example in a session with the comparison of results from different systems system, the visual modality in speech recognition module of the VSD+AVSR system provides distinguishable information that re- duces substitution errors, which improves the whole system perfor- mance. In all experiments, it is the combination of the audio and vi- sual modalities in both modules that yields the best system: AVDR. SPK 1 SPK 2 Overlap Silence Since the TV is closer to the far-\ufb01eld microphone array, loud TV noise may cover the voice of the target speakers in the far-\ufb01eld au- dio. At the same time, due to the diversity of TV broadcast content, the audio may contain the voice of irrelevant speakers, which may interfere with the speaker diarization, and speech recognition. As shown in Fig. 3, in the fourth segment utterance, because actors on TV are talking loudly, noise received by the microphone completely covers the voice of the target speaker, making the AVDR system un- able to recognize the speech content. Besides, in the last segment, due to the in\ufb02uence of TV background noise, ASD system wrongly assigns the segment of SPK1 to SPK2. Although the effect of AVDR system is better than that of single mode system, the TV background noise is also a big challenge in MISP2022. 4.2.3. Indistinguishable Speakers 4.2. Analyses of dif\ufb01culties In order to let challenge participants solve problems better, we point out the potential dif\ufb01culties in this challenge. Meanwhile, we discuss the performance of different module combinations to further explore the impact of audio and visual modalities. 4.2.1. Far-\ufb01eld Video Quality Due to the long distance between cameras and speakers, far-\ufb01eld video will result in a greatly reduced proportion of each speaker\u2019s lip ROI in the total image, especially in the scenes with more speakers. At the same time, lamplight, position, angle, occlusion, and other environmental factors may lead to the reduction of video quality. We explore how the number of lip ROIs pixels affects the performance of the VSD and AVSD systems, as shown in Fig. 2. It is found that as the average number of pixels decreases, the DER rises sharply. This will also affect the subsequent speech recognition task. According to the example in Fig. 3, it can be seen that dim-light and far distance lead to low quality of the far-\ufb01eld lip ROIs, making lip movements detection wrong or missing. There are lots of over- lapping segment false detections and speaker confusion in the VSD results. In fact, according to the ground truth (GT), only one speaker (SPK 1) is talking all the time. For the module of AVSR using VSD"}