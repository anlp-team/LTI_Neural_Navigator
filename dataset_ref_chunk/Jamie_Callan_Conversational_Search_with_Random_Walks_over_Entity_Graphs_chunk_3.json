{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Jamie_Callan_Conversational_Search_with_Random_Walks_over_Entity_Graphs_chunk_3.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the motivation behind concatenating the query vector with the passage entity matrix?", "answer": " The motivation is that relevant documents would contain similar entities contained in the query, so it is important that the query also makes part of the entity matrix.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What does the parameter \ud835\udefe control in Equation (4)?", "answer": " The parameter \ud835\udefe controls the weight balance between the entities in the query vector and the entities in the top passages matrix.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " How is the unrolled expression obtained from Equation (4) represented?", "answer": " The unrolled expression is represented as the product of the query vector and the top passages entity matrix with weights determined by \ud835\udefe.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What is the purpose of weighting the entity graph edges?", "answer": " The purpose is to design a more informative, conversation-specific weighting scheme using passage rank scores to signal the presence of entities in passages and the query.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " How are the scores of each passage entity of CP computed?", "answer": " The scores of each passage entity of CP are computed based on the full-text retrieval ranker scores, RS.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What is the weighting scheme for the entities in the query vector CQ?", "answer": " The original multi-hot binary encoding is used as the weighting scheme for the entities in the query vector CQ.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What method is used to calculate the entity centrality scores in the entity graph?", "answer": " Eigenvector methods are used as an implementation of random walks to estimate entity centrality scores.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " How are the EC scores of the top passages entities calculated?", "answer": " The EC scores are computed as a combination of the graph structure, damping factor, and the centrality scores of entity i.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What is the scoring vector in the reranking step based on?", "answer": " The scoring vector is based on the dot product between EC scores and the entity-passage matrix CP.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}, {"question": " What is the purpose of the linear interpolation scoring system mentioned in Equation (10)?", "answer": " The purpose is to balance the original scores from the full-text retrieval ranker with the entity centrality scores to improve the ranking of passages.", "ref_chunk": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}], "doc_text": "occurrence matrix of the conver- sation entities CQP, as the concatenation of vector CQ with matrix CP, CQP = (cid:2) \ud835\udefe \u00b7 CQ (1 \u2212 \ud835\udefe) \u00b7 CP (cid:3)\ud835\udc47 . The choice of concatenating the query vector with the passage entity matrix was motivated by the idea that relevant documents would contain similar entities contained in the query, thus it is important that the query also makes part of the entity matrix. Eq. (4) introduces a linear combination parameter \ud835\udefe. The \ud835\udefe pa- rameter controls the weight balance between the entities in the query vector and the entities in the top passages matrix. Motivated by linear interpolation schemes such as the Jelinek and Mercer [16] smoothing, this parameter allows flexibility to weight the query and passages entities differently and observe how their contribution affects the results. In our experimental results we tune \ud835\udefe to obtain the optimal weight to be given to the entities in the query vector, or the top passages matrix. By expanding Equation (4) we get the unrolled expression: CQP = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \ud835\udefe \u00b7 \ud835\udc5e\ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5e\ud835\udc52\ud835\udc5b \uf8ef \uf8f0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (1 \u2212 \ud835\udefe) \u00b7 \ud835\udc5d1 \ud835\udc521 \uf8ee \uf8ef ... \uf8ef \uf8ef \uf8ef \ud835\udc5d1 \uf8ef \ud835\udc52\ud835\udc5b \uf8f0 . . . . . . . . . \ud835\udc5d\ud835\udc58 \ud835\udc521 ... \ud835\udc5d\ud835\udc58 \ud835\udc52\ud835\udc5b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \ud835\udc47 . Finally, the entity graph, Eq. (6), is given by the application of the dot product over the occurrence matrix G = CQP \u00b7 CQP \ud835\udc47 , G \u2208 R \ud835\udc5b\u00d7\ud835\udc5b . 3.2 Weighting the Entity Graph Edges The weighting scheme used in the previous subsection is obtained by signaling the presence of entities in passages, and query. A more informative, conversation-specific, weighting scheme can be further designed with the passage rank scores. In this weighting scheme, (1) (2) (3) (4) (5) (6) ICTIR \u201923, July 23, 2023, Taipei, Taiwan the values of CP correspond to the full-text retrieval ranker scores, \ud835\udc45\ud835\udc46. Hence, the score of each passage entity of CP is given by: \ud835\udc50\ud835\udc5d\ud835\udc52 = \ud835\udc45\ud835\udc46 (\ud835\udc5d\ud835\udc52 ) \u2200\ud835\udc52 \u2208 \ud835\udc38 \u2227 \u2200\ud835\udc5d \u2208 \ud835\udc43 (7) Using the Equation (7) weights in Equation (6) is equivalent to setting all the values of each column to the full-text retrieval ranker score of the corresponding passage. The weight given to the entities in the query vector CQ is the original multi-hot binary encoding. The model uses this graph edge weighting scheme to maintain a strong signal from the query entities. Moreover, this formulation allows for entity occurrences in higher-ranked passages to have more influence than entity occurrences in lower-ranked passages. 3.3 Calculating the Entity Graph Centrality The entity graph represents the entities related to the current con- versation turn and how they are used in the query and top-ranked passages. The next step is to calculate the entity centrality (EC) scores that indicate how well each entity represents the conversa- tion turn context. The EC scores can be estimated with random walk methods. We focus on eigenvector methods as an implementation of ran- dom walks to estimate centrality [2, 4], as they can be imple- mented efficiently through a power-iteration with convergence in \ud835\udc42 (\ud835\udc38\ud835\udc51\ud835\udc54\ud835\udc52\ud835\udc60 \u00d7 \ud835\udc3c\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60). Moreover, we choose a particular use case of the eigenvector centrality [3] with a teleportation variation. The EC vector of the top passages entities is computed as 1 |\ud835\udc38| where \ud835\udefc is the damping factor and each dimension \ud835\udc56 of EC contains the centrality score of entity \ud835\udc56. EC(\ud835\udc61 ) = (1 \u2212 \ud835\udefc) \u00b7 + \ud835\udefc \u00b7 G \u00b7 EC(\ud835\udc61 \u22121) (8) Over both datasets the best results were achieved by setting the dampening factor to 0.99, virtually eliminating the teleportation factor introduced by Eq. (8), as our task relies on small connected graphs that require a small amount of dampening. We keep the dampening factor, ever so slightly, for the sake of guaranteed con- vergence of the power-iteration algorithm [20]. 4 RERANKING WITH ENTITY CENTRALITIES Formally, the score of each top passage is obtained by computing the dot product between EC scores, and the entity-passage matrix CP. S = EC \ud835\udc47 \u00b7 CP, S \u2208 [0, 1]1\u00d7\ud835\udc58 (9) Eq. (9) results in a scoring vector for all of the full-text retrieval passages in matrix CP, now conditioned on entity information. With the score vector defined in Eq. (9) we can perform a rerank- ing step based on the entity centralities of the passage. We refer to this scoring system as \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66. A straightforward extension to \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 is to fuse the entity centrality ranking, with the full-text retrieval ranking. Motivated by Jelinek and Mercer [16], we balance the original scores derived from the full-text retrieval ranker with the entity centrality scores. The linear interpolation scoring is formalized below for any passage \ud835\udc58 in the ranking: \ud835\udc5d\ud835\udc58 = (1 \u2212 \ud835\udeff) \u00b7 S \ud835\udc58 + \ud835\udeff \u00b7 \ud835\udc45\ud835\udc46\ud835\udc58 (10) ICTIR \u201923, July 23, 2023, Taipei, Taiwan Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, and Jamie Callan Table 1: Retrieval baselines compared with the averages for the 5-Fold CV Entity Centrality re-ranking. Statistically significant improvements are denoted with \u2020, and non-inferiority with **, for \ud835\udc5d < 0.05 with a margin of 0.01, over the BERT baseline. CAsT 2019 CAsT 2020 Method nDCG@1 nDCG@3 P@1 P@3 MRR nDCG@1 nDCG@3 P@1 P@3 MRR BM25 LMD RM3 BERT ERNIE E-BERT \ud835\udc38\ud835\udc36\ud835\udc4f\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc5f \ud835\udc66 \ud835\udc38\ud835\udc36\ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc38\ud835\udc36\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f 0.4152 0.3974 0.4099 0.5689 0.5626 0.5270 0.6074 0.6320\u2020 0.6334\u2020 0.3858 0.4026 0.4133 0.5703 0.5617 0.5205 0.5839** 0.6164\u2020 0.6102\u2020 0.6012 0.5838 0.6069 0.7803 0.7514 0.7283 0.8035 0.8439\u2020 0.8439\u2020 Term based approaches 0.7157 0.5568 0.6984 0.5896 0.7158 0.6031 0.7476 0.8604 Entity based approaches 0.8435 0.7245 0.8229 0.6802 0.8707 0.7534 0.8869** 0.7746** 0.8871** 0.7649 0.2528 0.3257 0.3013 0.5244 0.5243 0.4006 0.4812 0.5088 0.5104 0.2536 0.2930 0.2808 0.4976 0.4865 0.3786 0.4950 0.5092** 0.5084** 0.3798 0.4952 0.4519 0.6923 0.6971 0.5673 0.6635 0.6779 0.6779 0.3798 0.4167 0.4135 0.6538 0.6394 0.5208 0.6554 0.6779** 0.6731** 0.5241 0.6024 0.5690"}