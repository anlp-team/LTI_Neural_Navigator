{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Alexander_I._Rudnicky_Structured_Dialogue_Discourse_Parsing_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " According to the text, why does the same phenomenon of overfitting not happen under the UAS setting of STAC/MOL?", "answer": " The speculated reason is that STAC has a much larger linguistic diversity, thereby alleviating the model overfitting issue.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " How does the text explain the performance drop of the parser when the dialogue becomes longer?", "answer": " The parser models the overall dialogue structure using tree distributions, which lowers the burden of predicting long-range links.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " What is highlighted as the benefit of global structured learning and inference in the text?", "answer": " The benefit is the length robustness of the parser, especially when the dialogue becomes longer.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " What observation is made about low-resource relations in the text?", "answer": " Both parsers struggle to predict low-resource relations, marking an important direction for future work.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " How does the removal of speaker and turn information affect the performance of the parser according to the text?", "answer": " The performance drop of the parser is less than that of the best baseline, demonstrating the robustness of the parser.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " What are the three types of discourse parsing formalisms mentioned in the text?", "answer": " RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Lascarides and Asher, 2008; Asher et al., 2016).", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " What is the ultimate goal of the induced structure in the text?", "answer": " The induced structure is used to directly decode the labeled tree structure.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " From the encoding side, what method is proposed for dialogue discourse parsing?", "answer": " A structurally-encoded adjacency matrix followed by the matrix-tree theorem is proposed.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " What algorithm is applied for maximum spanning tree induction in the text?", "answer": " The modified CLE algorithm is applied for maximum spanning tree induction.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}, {"question": " According to the text, where does the proposed method for dialogue discourse parsing achieve state-of-the-art performance?", "answer": " The proposed method achieves state-of-the-art performance on two benchmark datasets.", "ref_chunk": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}], "doc_text": "pretrained language model as Struct-Aware and Hierarchical (Liu and Chen, 2021) both utilize the same or comparable pretrained model. Cross-domain We shift gear to the cross-domain setting where the parser is trained on one dataset and tested on the other (Liu and Chen, 2021). We can see that our parser is the best under the LAS setting, substantially outperforming the best can- didates by 5.1 on STAC/MOL and 4.8 points on MOL/STAC. However, the best-performing model under the UAS setting is the oldest model (Afan- tenos et al., 2015; Perret et al., 2016). This can be explained by the inclination of a large pretrained model to overfit on the training domain, which was corroborated by Liu and Chen (2021) as well. Read- ers might wonder why the same phenomenon does not happen under the UAS setting of STAC/MOL, and the speculated reason is STAC has a much larger linguistic diversity (Liu and Chen, 2021), thereby alleviating the model overfitting issue. In other words, we might want to train the dialogue discourse parser on a linguistically diverse dataset if the goal is domain generalization. 5.5 Additional Analyses Dialogue Length Robustness We hypothesize that our parser is likely to perform better when the dialogue becomes longer, and the reason is that our parser models the overall dialogue structure using tree distributions. This lowers the burden of the parser to predict long-range links. We focus on the in-domain setting and plot the results in Figure 5. As we can see, the performance of our parser drops less than baselines when the dialogue Ours 0.20.40.60.8127121722273237F1 ScoreDialogue Length Deep-Seq. Struct-Aware Figure 5: Parsing performance w.r.t dialogue lengths. As we can see, the performance difference is larger when the dialogue becomes longer, demonstrating the length robustness of our parser. becomes longer, highlighting the benefit of global structured learning and inference. Relation Performance Breakdown In order to know what kinds of relations benefit the most from our proposed parser, we count the number of cor- rect relation predictions and plot them in Figure 6 and 7.5 The baseline parser we compare with is the Hierarchical model (Liu and Chen, 2021) as it can be viewed as the non-structured version of our parser with the same pretrained model backbone. We can see that our parser outperforms the base- line on certain relations like Comment and QA pair on STAC and QA pair and Clarification Question on Molweni. However, there is still a large room for improvement as demonstrated by the gap be- tween our parser and the ground truth. Another observation is that both parsers struggle to predict low-resource relations, marking an important direc- tion for future work. 5Note that this implies the link predictions of these correct relations are also correct. Ground Truth 050100150200250300350ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationstac Hierarchical Ours Figure 6: STAC relation performance breakdown. Ground Truth Hierarchical Ours 020040060080010001200ContinuationQuestion-answer_pairContrastQ-ElabExplanationCommentBackgroundResultCorrectionParallelAlternationConditionalClarification_questionAcknowledgementElaborationNarrationmolweni Figure 7: Molweni relation performance breakdown. Speaker and Turn Feature Robustness We ex- periment with removing speaker and turn informa- tion used in baselines. The performance drop (LAS of STAC) of our parser (59.6 \u2192 54.4) is less than that of the best baseline (Struct-Aware) (57.3 \u2192 47.8), demonstrating the robustness of our parser. 6 Related Work Discourse Parsing As discussed in the Introduc- tion section, there are three types of discourse parsing formalisms: RST (Mann and Thompson, 1988), PDTB (Prasad et al., 2008), and SDRT (Las- carides and Asher, 2008; Asher et al., 2016). For the first two tasks, there are transition-based (Li et al., 2014; Braud et al., 2017; Yu et al., 2018) and CKY-based methods (Joty et al., 2015; Li et al., 2016; Liu and Lapata, 2017) in the literature. In this work, we assume that the EDUs are already given. In practice, there are papers working on seg- menting EDUs (Subba and Di Eugenio, 2007; Li et al., 2018) before feeding them to the discourse parser. Dialogue Disentanglement Clustering utter- ances in a conversation into threads is studied exten- sively by previous work (Shen et al., 2006; Elsner and Charniak, 2008; Wang and Oard, 2009; Elsner and Charniak, 2011; Jiang et al., 2018; Kummer- feld et al., 2019; Zhu et al., 2020; Li et al., 2020b; Yu and Joty, 2020). They predict the reply-to links independently and run a connected component al- gorithm to construct the threads. This is similar to the UAS setting in this work. Structured Learning Algorithms Natural lan- guage is highly structured suggesting that the in- troduction of structural bias will facilitate learning. Previous work have studied dependency-tree like structures extensively (Koo et al., 2007; McDonald et al., 2005; McDonald and Satta, 2007; Niculae et al., 2018; Paulus et al., 2020). Several works propose to incorporate such inductive bias into in- termediate layers of modern NLP models (Kim et al., 2017; Chen et al., 2017; Liu and Lapata, 2018; Choi et al., 2018). In our work, the induced structure is not only implicitly learned, it is also used to directly decode the labeled tree structure, which is our ultimate goal. Dependency Parsing Our work can also be viewed as extending token-level dependency pars- ing (Mel\u2019cuk et al., 1988; Koo et al., 2007; Smith and Eisner, 2008; Koo and Collins, 2010; Chen and Manning, 2014; Dozat and Manning, 2017; Qi et al., 2018; Choi and Palmer, 2011) to utterance- level. Another important difference is that our tree is labeled, which means we have to additionally predict the type of tree edges. 7 Conclusion In this paper, we propose a principled method for di- alogue discourse parsing. From the encoding side, we introduce a structurally-encoded adjacency ma- trix followed by the matrix-tree theorem, which is used to holistically model all utterances as a tree. From the decoding side, we apply the mod- ified CLE algorithm for maximum spanning tree induction. Our method achieves state-of-the-art performance on two benchmark datasets. We also benchmark the cross-domain parser performance, and find our parser performs the best in the most- commonly used and harder LAS setting. We be- lieve that the techniques described in this work pave the"}