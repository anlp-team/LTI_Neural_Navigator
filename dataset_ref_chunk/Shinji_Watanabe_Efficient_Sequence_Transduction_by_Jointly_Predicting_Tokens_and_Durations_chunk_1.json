{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_Efficient_Sequence_Transduction_by_Jointly_Predicting_Tokens_and_Durations_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What does the Token-and-Duration Transducer (TDT) architecture do?", "answer": " The TDT architecture jointly predicts a token and its duration during sequence-to-sequence tasks.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " How is the Token-and-Duration Transducer (TDT) model faster than conventional Transducers?", "answer": " TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than Transducers that process the encoder output frame by frame.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What are some of the improvements made to the original Transducer models?", "answer": " Improvements include the replacement of LSTM encoders with Transformers, Contextnet, and Conformers, as well as exploring different decoders like stateless decoders and Echo State Networks.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What is the primary contribution of the TDT model according to the text?", "answer": " The TDT model introduces a novel architecture that jointly predicts tokens and durations, achieving better accuracy and faster inference in various sequence transduction tasks.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What toolkits are mentioned in the text that have efficient implementations for various speech recognition models?", "answer": " ESPNet, NeMo, Espresso, and SpeechBrain are some of the toolkits mentioned with efficient implementations for speech recognition models.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What is the purpose of the loss function FastEmit in the context of Transducers?", "answer": " FastEmit introduces biases in the gradient update of the transducer loss to reduce latency during inference.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " How do TDT models in Speech Intent Classification tasks compare to conventional Transducers?", "answer": " TDT models improve the intent accuracy by up to over 1% (absolute) compared to conventional Transducers, while also running up to 1.28X faster.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What is the benefit of the TDT model predicting token durations during inference?", "answer": " The predicted token duration can direct the model decoding algorithm to skip frames during inference, leading to faster computation.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " What does LRNNT(y|x) represent according to the text?", "answer": " LRNNT(y|x) represents the log-probability of an audio utterance x with corresponding text y, requiring summing over all possible ways to augment the text sequence to match the audio.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}, {"question": " How is the TDT model open-sourced according to the text?", "answer": " The TDT model implementation will be open-sourced with the NeMo toolkit.", "ref_chunk": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}], "doc_text": "3 2 0 2 y a M 9 2 ] S A . s s e e [ 2 v 5 9 7 6 0 . 4 0 3 2 : v i X r a Efficient Sequence Transduction by Jointly Predicting Tokens and Durations Hainan Xu 1 Fei Jia 1 Somshubra Majumdar 1 He Huang 1 Shinji Watanabe 2 Boris Ginsburg 1 Abstract introduces a novel Token-and- This paper Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conven- tional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently nor- malized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted dura- tion output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better ac- curacy and up to 2.82X faster inference than con- ventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with con- ventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent ac- curacy by up to over 1% (absolute) over conven- tional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https: //github.com/NVIDIA/NeMo) toolkit. 1. Introduction encoder and decoder (AED) models (Chorowski et al., 2015; Chan et al., 2016), Connectionist Temporal Classification (CTC) (Graves et al., 2006), and Transducers (Graves, 2012). Those models are commonly used in academia and industry, and there exist open-source toolkits with efficient implemen- tation for those methods, including ESPNet (Watanabe et al., 2018), NeMo (Kuchaiev et al., 2019), Espresso (Wang et al., 2019), SpeechBrain (Ravanelli et al., 2021) etc. This paper focuses on Transducer models. There have been a significant number of works that improve different aspects of the original Transducer (Graves, 2012). For example, the original LSTM encoder of transducer models has been replaced with Transformers (Tian et al., 2019; Yeh et al., 2019; Zhang et al., 2020), Contextnet (Han et al., 2020) and Conformers (Gulati et al., 2020). Decoders for transducers are well-investigated as well, e.g. (Ghodsi et al., 2020) used stateless decoders instead LSTM decoders; (Shrivastava et al., 2021) proposed Echo State Networks and showed that a decoder with random parameters could perform as well as a well-trained decoder. The loss function of Transducers has also been an active research area. FastEmit (Yu et al., 2021) introduces biases in the gradient update of the transducer loss to reduce latency. Multi-blank Transducers (Xu et al., 2022) introduce a generalized Transducer architecture and loss function with big blank symbols that cover multiple frames of the input. RNN-Ts have achieved impressive accuracy in speech tasks, but the auto-regressive decoding makes their inference com- putationally costly. To alleviate this issue, we propose a new Transducer architecture that jointly predicts a token and its duration. The predicted token duration can direct the model decoding algorithm to skip frames during inference. We call it a TDT (Token-and-Duration Transducer) model. The primary contributions of this paper are: Over the past years, automatic speech recognition (ASR) models have undergone shifts from conventional hybrid models (Jelinek, 1998; Woodland et al., 1994; Povey et al., 2011) to end-to-end ASR models, including attention-based 1NVIDIA, USA 2Carnegie Mellon University, PA, USA. Corre- spondence to: Hainan Xu <hainanx@nvidia.com>. Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). 1. A novel Token-and-Duration Transducer (TDT) archi- tecture that jointly predicts a token and its duration. 2. An extension of the forward-backward algorithm to derive the analytical solution of the gradients of the TDT model. We also derive gradients of pre-softmax logits for the token prediction inspired by Transducer function-merging (Li et al., 2019). 3. TDT models achieve better accuracy and significant 1 Efficient Sequence Transduction by Jointly Predicting Tokens and Durations blank symbol \u00d8; a text sequence could be augmented by adding an arbitrary number of blanks between any adjacent tokens. During training, we maximize the log-probability log PRNNT(y|x) for an audio utterance x with corresponding text y, which requires summing over all possible ways to augment the text sequence to match the audio: LRNNT(y|x) = log PRNNT(y|x) = log (cid:88) Pframe-level(\u03c0|x), \u03c0:B\u22121(\u03c0)=y where \u03c0 represents an augmented sequence (including \u00d8), B(.) is the operation to augment a sequence by adding blanks, and B\u22121 is the inverse of the operation B, which removes all the blanks in the sequence. Figure 1. From top to bottom: alignments generated with con- ventional RNNT, TDT models with config [0-8], and the corre- sponding spectrogram. Each unit in the T axis of the alignment corresponds to 4 frames in the spectrogram due to subsampling. Note, TDT model learns to skip frames. Long skips are not fre- quently used in the audio where speech is present, but for the 4 relatively silent segments in the audio, where conventional RNN- T\u2019s alignment shows mostly horizontal lines, the TDT model uses long durations to skip the majority of frames. Computing PRNNT(y|x) using its definition is intractable since it needs to sum over exponentially many possible aug- mented sequences. In practice, the probability can be effi- ciently computed with the forward variables \u03b1(t, u) or back- ward variables \u03b2(t, u), which are calculated recursively: \u03b1(t, u) = \u03b1(t \u2212 1, u)P (\u00d8|t \u2212 1, u) + \u03b1(t, u \u2212 1)P (yu|t, u \u2212 1) \u03b2(t, u) = \u03b2(t + 1, u)P (\u00d8|t, u) + \u03b2(t, u + 1)P (yu+1|t, u). inference speed-up compared to original RNN-Ts for 3 different tasks \u2013 speech recognition, speech translation, and spoken language understanding. 4. TDT-based ASR models are more robust to noise than"}