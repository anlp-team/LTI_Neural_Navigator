{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/T._Mitamura_Hierarchical_Event_Grounding_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What does Table 2 show regarding the performance of bi-encoder and cross-encoder on multilingual and crosslingual event linking?", "answer": " Table 2 shows the strict accuracy (Top Min) of cross-encoder compared to bi-encoder Recall@min for various tasks.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " In Table 3, what does Multilingual R@min refer to?", "answer": " Multilingual R@min refers to the strict accuracy of the bi-encoder under Top Min conditions.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " Which system outperforms the baseline on strict accuracy and achieves comparable performance on macro/micro F1 in the crosslingual task?", "answer": " System (d) is the only hierarchy-aware system that outperforms the baseline across all metrics.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What is the main difference in performance between bi-encoders and cross-encoders across tasks?", "answer": " The large performance gap of cross-encoders between the two tasks confirms that the crosslingual setting is more challenging.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " How do cross-encoders compare to bi-encoders in terms of performance on multilingual tasks?", "answer": " Cross-encoders enhance bi-encoder performance on the test set in multilingual tasks.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What approach does Table 3 present for hierarchical relation extraction?", "answer": " Table 3 presents the hierarchical relation extraction results of a set-based approach using the retrieved candidates by the best performing bi-encoder.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What is the performance of the proposed method on assigning rankings to true parents for events within hierarchies?", "answer": " The proposed method demonstrates high rankings for true parents on both tasks, showing its capability in aiding humans to discover new hierarchical relations.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What datasets are used to evaluate the performance of the two hierarchy-aware linking systems in Table 4?", "answer": " The Wikinews dataset is used to evaluate the performance of the baseline and the two hierarchy-aware linking systems.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What task is presented in the paper discussed in the Conclusion & Future Work section?", "answer": " The paper presents the task of hierarchical event grounding using a multilingual dataset with Wikipedia and Wikidata.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}, {"question": " What are some potential future directions mentioned in the Conclusion & Future Work section?", "answer": " Some potential future directions include adapting encoders to include hierarchy directly and exploring hierarchical relation extraction on standard datasets.", "ref_chunk": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}], "doc_text": "28.0 22.1 / 28.8 22.3 / 28.0 21.6 / 28.1 25.7 / 34.3 23.6 / 29.2 24.0 / 28.9 23.4 / 29.4 27.3 / 33.1 Table 2: Bi-encoder and Cross-encoder performance on multilingual and crosslingual event linking (dev/test). Strict Acc (Top Min) refers to the cross-encoder strict accuracy under Top Min, which is directly comparable to the bi-encoder Recall@min. R@1 R@4 R@8 R@16 Bi-encoder Cross-encoder Multilingual Crosslingual 46.0 / 45.1 69.0 / 72.6 76.6 / 81.3 79.6 / 84.6 52.0 / 37.4 78.3 / 60.5 86.2 / 75.6 90.8 / 83.9 Methods Multilingual R@min Strict Acc Macro F1 Micro F1 Table 3: Hierarchical relation extraction results (dev/test) with the top-4 retrieval predictions by the best performing bi-encoder. (a) Baseline (c) + HJL Crosslingual 68.6 67.4 51.7 55.8 67.2 65.3 62.0 62.7 that are paired with hierarchy-aware bi-encoders outperform the baseline on strict accuracy and attain better or compa- rable performance on macro/micro F1. On the crosslingual task, (d) is the only hierarchy-aware system that outperforms the baseline across all metrics. All the models attain better results with Top Min accuracy and the relative performance differences between them remain similar to that of normal accuracy. Similar to the bi-encoder, the large performance gap of cross-encoders between the two tasks con\ufb01rms that the crosslingual setting is more challenging. 7.3 Bi-encoder vs. Cross-encoder We further investigate whether the cross-encoder could make improvements on its bi-encoder across all con\ufb01gura- tions. As discussed in \u00a76.1, by comparing the strict accu- racy of cross-encoders under the Top Min condition with the Recall@min of associated bi-encoders, we \ufb01nd that cross- encoders further enhance bi-encoder performance on the test set in multilingual tasks while underperforms in other cases. For closer inspection into the performance of systems on each language, we report the per-language bi- and cross- encoder results in Table 5 and Table 6 in Appendix D.2. 7.4 Hierarchy Discovery Table 3 presents the hierarchical relation extraction results of our proposed set-based approach using the retrieved candi- dates by the best performance bi-encoder ((b) in Table 2). On both tasks, the proposed method is able to assign high rank- ings to true parents for events within hierarchies, demon- strating its capability in aiding humans to discover new hi- erarchical relations on a set of previously-unseen events. (a) Baseline (d) + HP + HJL 51.2 53.7 15.3 21.1 29.8 37.6 Table 4: Bi-encoder and cross-encoder performance on mul- tilingual & crosslingual event linking on Wikinews Dataset 7.5 Wikinews As shown in Table 4, applying our baseline and two of the hierarchy-aware linking systems ((c) in multilingual and (d) in crosslingual) on the Wikinews dataset results in a similar performance to that on Wikipedia mentions, which demon- strates that our methods could generalize well on the news domain. 8 Conclusion & Future Work In this paper, we present the task of hierarchical event grounding, for which we compile a multilingual dataset with Wikipedia and Wikidata. We propose a hierarchy-loss based methodology that improves upon a standard retrieve and re- rank baseline. Our experiments demonstrate the effective- ness of our approaches to model hierarchies among events in both multilingual and crosslingual settings. Additionally, we show promising results for zero-shot hierarchical rela- tion extraction using the trained event linker. Some potential directions for future work include adapting encoders to di- rectly include hierarchy and further exploring hierarchical relation extraction on standard datasets. Acknowledgments This material is based on research sponsored by the Air Force Research Laboratory under agreement number 30.0 35.7 FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies or endorsements, either expressed or im- plied, of the Air Force Research Laboratory or the U.S. Gov- ernment. References Bordes, A.; Weston, J.; Collobert, R.; and Bengio, Y. 2011. Learning Structured Embeddings of Knowledge Bases. In Proceedings of the Twenty-Fifth National Conference on Arti\ufb01cial Intelligence, 301\u2013306. Menlo Park, Calif.: AAAI Press. Botha, J. A.; Shan, Z.; and Gillick, D. 2020. Entity Link- ing in 100 Languages. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Process- ing (EMNLP), 7833\u20137845. Online: Association for Compu- tational Linguistics. Chandu, K. R.; Bisk, Y.; and Black, A. W. 2021. Ground- ing \u2018Grounding\u2019 in NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 4283\u20134305. Online: Association for Computational Linguistics. Chen, T.; Chen, Y.; and Van Durme, B. 2020. Hierarchical Entity Typing via Multi-level Learning to Rank. In Proceed- ings of the 58th Annual Meeting of the Association for Com- putational Linguistics, 8465\u20138475. Online: Association for Computational Linguistics. Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzm\u00b4an, F.; Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020. Unsupervised Cross-lingual Rep- In Proceedings of the 58th resentation Learning at Scale. Annual Meeting of the Association for Computational Lin- guistics, 8440\u20138451. Online: Association for Computational Linguistics. Du, X.; Zhang, Z.; Li, S.; Yu, P.; Wang, H.; Lai, T.; Lin, X.; Wang, Z.; Liu, I.; Zhou, B.; Wen, H.; Li, M.; Hannan, D.; Lei, J.; Kim, H.; Dror, R.; Wang, H.; Regan, M.; Zeng, Q.; Lyu, Q.; Yu, C.; Edwards, C.; Jin, X.; Jiao, Y.; Kazeminejad, G.; Wang, Z.; Callison-Burch, C.; Bansal, M.; Vondrick, C.; Han, J.; Roth, D.; Chang, S.-F.; Palmer, M.; and Ji, H. 2022. RESIN-11: Schema-guided Event Prediction for 11 News- worthy Scenarios. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies: Sys- tem Demonstrations, 54\u201363. Hybrid: Seattle, Washington + Online: Association for Computational Linguistics. Glava\u02c7s, G.; \u02c7Snajder, J.; Moens, M.-F.; and Kordjamshidi, P. 2014. HiEve: A Corpus for Extracting Event Hierarchies In Proceedings of the Ninth Interna- from News Stories. tional Conference on Language Resources and Evaluation (LREC\u201914), 3678\u20133683. Reykjavik, Iceland: European Lan- guage Resources Association (ELRA). Han, R.; Hsu, I.-H.; Sun, J.; Baylon, J.; Ning, Q.; Roth, D.; and Peng, N. 2021. ESTER:"}