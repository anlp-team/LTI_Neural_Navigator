{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Fernando_Diaz_Fairness_Through_Domain_Awareness:_Mitigating_Popularity_Bias_For_Music_Discovery_chunk_3.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the methodology used by PinSage to construct neighborhoods?", "answer": " PinSage uses random walks to select the most relevant neighbors.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What is one key difference between PinSage and LightGCN?", "answer": " PinSage learns representations of items but not users, while LightGCN learns both user and item embeddings simultaneously.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What is one limitation with working on music recommendation according to the text?", "answer": " The scarcity of up-to-date, publicly available feature-based datasets.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " Why is it important to augment datasets for music recommendation?", "answer": " To implement domain-aware fairness measures and alleviate reproducibility issues.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What are some features included in the augmented datasets mentioned in the text?", "answer": " Sonic features, genre features, track name features, and image features.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " How is the task of performing recommendation described in the text?", "answer": " As link prediction on an undirected bipartite graph.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What is the goal of link prediction in the context of recommendation?", "answer": " To predict whether two song nodes share a common parent playlist.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " How is popularity defined in the methodology presented in the text?", "answer": " Through a combination of logarithmic smoothing and binning.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What problem does using binning without logarithmic smoothing cause in the dataset distributions?", "answer": " Uneven distribution of items in the bins due to the dataset nature.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}, {"question": " What is the purpose of the logarithmic smoothing in defining popularity?", "answer": " To solve scaling issues caused by the extremes of the long-tail distribution.", "ref_chunk": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}], "doc_text": "node, PinSage trains on a randomly sampled subset of the graph. In order to construct neighborhoods, PinSage uses \ud835\udc58 random walks to select the top \ud835\udc5a most relevant neighbors to use as the neighbor set. However, it is important to note that PinSage learns representations of items but not users. Meanwhile, LightGCN [34], is a method that learns both user and item embeddings simultaneously. Since its proposal in 2020, it is still considered state of the art. 3 Methodology In this section we detail the dataset augmentation procedure and architecture of our domain-aware, individually fair music recom- mendation system. First, we introduce our datasets in Section 3.1. Then, following the problem setting in Section 3.2, we reformulate popularity bias in Section 3.3 and introduce our domain-aware, individually fair music recommender system in Section 3.4. 3.1 Dataset Augmentation Procedure One of the limitations with working on music recommendation is the scarcity of up-to-date, publicly available feature-based datasets. This is because the datasets which are available are often purely interaction-based, meaning that they lack the necessary track-level features to implement domain-aware fairness measures. Thus, one of the preliminary steps of our work was the extensive augmenta- tion of two publicly available datasets: LastFM [46] and the Million Playlist Dataset [16]. The augmentation and release of these two complementary datasets is an important contribution because it paves the way for further work in domain-aware music recommen- dation and alleviates the reproducibility issues often posed by the use of music datasets. Although we are limited by the number of publicly available music datasets which are compatible with our feature augmentation procedure, we believe that in selecting these two datasets, we highlight the benefits of our methodology on a broad range of settings related to music recommendation. First, these datasets encompass two important levels of recommendation: playlist (MPD) and user (LFM) based. Second, they showcase two different methods of user feedback data: implicit and explicit. MPD consists of user generated playlists meaning that its interactions consist of songs which are explicitly pronounced as relevant due to the explicit nature of a user selecting the song for their playlist. Meanwhile, LFM contains user/song interactions that are gathered by aggregating all the songs that a user clicked on (even if they did not necessarily finish or enjoy the content). Thus, these implicit interactions have no guarantee of relevance, making the dataset more prone to noise. And, particularly in the cold start setup (see Conference\u201917, July 2017, Washington, DC, USA Section 4.1), this can significantly increase the difficulty of making predictions because implicit interactions are less indicative of a user\u2019s latent taste and less homogeneous in nature than that of a unified playlist. We augment both of our datasets to include a rich set of features scraped from Spotify API [1]. To achieve this, we draw on a large body of work from the music information retrieval community (MIR) [27, 30]. We will publicly release the constructed datasets, the construction code, along with the code for using various feature sets, in our repository upon the publication of this paper. The details of the augmented features are as follows. (1) Sonic features. Spotify has a series of 9 proprietary features which are used to define the audio elements associated with a track. They are danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. Each of these features is a continuous scalar value. In order to normalize the scales, we apply 10 leveled binning to the values. (2) Genre features. We identify the primary artist associated with each collect all the genre tags associated with them. For the emebddings, we select the top 20 and convert them to a one-hot encoding. (3) Track Name features. For each song in the dataset, we extract the song title and pass it through a pre-trained lan- guage transformer model, BERT [19], into an embedding of dimension 512. (4) Image features. For each song in the dataset we extract the associated album artwork. We pass this image through a pre-trained convolutional neural network, ResNet50 [33], to generate an embedding of dimension 1024. 3.2 Problem Setting The task of performing recommendation can be seen as link pre- diction an undirected bipartite graph. We denote such undirected bipartite graph as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38). The note set \ud835\udc49 = \ud835\udc47 \u222a \ud835\udc43 consists of a set containing song (or track) nodes, \ud835\udc47 , and playlist (or user) nodes, \ud835\udc43 (or \ud835\udc48 ). The edge set \ud835\udc38 are defined between a playlist \ud835\udc5d\ud835\udc58 (or user \ud835\udc62\ud835\udc58 ) and a song \ud835\udc61\ud835\udc56 if \ud835\udc61\ud835\udc56 is contained in \ud835\udc5d\ud835\udc58 (or listened to by \ud835\udc62\ud835\udc58 ). Following this setting, our goal (link prediction) is to predict whether any two song nodes \ud835\udc61\ud835\udc56, \ud835\udc61 \ud835\udc57 \u2208 \ud835\udc47 share a common parent playlist \ud835\udc5d. 3.3 Reformulating Popularity Bias 3.3.1 Defining Popularity As mentioned in Section 2.1, there is no true consensus within the community on how to define popularity. Here, we present a methodology which we believe allows for both the granularity and expressiveness necessary to highlight differ- ences among various mitigation methods. Broadly, our method con- sists of important steps (1) logarithmic smoothing and (2) binning. In doing so, we combine the best of each methodology. Applying a logarithmic transformation to the raw values, solves the scaling issues that are caused by the extremes of the long-tail distribution. Meanwhile, binning allows us to provide aggregate statistics that highlight large scale patterns in the recommendations. And, while there are many methods which apply binning [3, 20, 54], with- out the logarithmic smoothing, due to the nature of our datasets\u2019 Conference\u201917, July 2017, Washington, DC, USA Figure 2: Binning procedure for popularity definition. We show the breakdown of the bin locations for both dataset using our method as compared with the classic long tail model [45]. We can see that our logarithmic smoothing and increased bin count allow for a more granular visualization of popularity between various item groups. distributions the amount of items in the bins would be unevenly distributed,"}