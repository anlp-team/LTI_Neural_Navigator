{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Rita_Singh_Imprecise_Label_Learning:_A_Unified_Framework_for_Learning_with_Various_Imprecise_Label_Configurations_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the focus of the paper mentioned in the text?", "answer": " The paper focuses on formulating a different view on training models with imprecise label information.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " How does the paper propose to treat imprecise label information?", "answer": " The paper proposes to treat imprecise label information as the information that imposes a deterministic or statistical restriction on the actual applicable true labels.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What is the latent variable in the model described in the text?", "answer": " The inaccessible full and precise labels Y are treated as a latent variable in the model.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What common approach is used to deal with maximizing the logarithm of an expectation in the model?", "answer": " The common approach used is expectation-maximization (EM).", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " How does the proposed framework in the paper accommodate different types of imprecise label scenarios?", "answer": " The proposed framework is largely agnostic to the various nature of label imprecision, with the imprecise label affecting the computation of the posterior P (Y |X, I; \u03b8t).", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What is the main advantage of the unified framework proposed in the paper?", "answer": " The unified framework can serve as a solution towards a unified view for learning with any imprecise labels.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What is the significance of the proposed unified framework in the context of learning with imprecise labels?", "answer": " The proposed unified framework outperforms previous methods for dealing with single imprecise labels and demonstrates robustness and effectiveness for mixed label settings.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What is the objective of partial label learning (PLL) as mentioned in the text?", "answer": " The objective of partial label learning is to learn with a candidate label set where the ground truth label is concealed in the set.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What method is mentioned in the text for partial label learning that employs class prototypes to enhance label disambiguation?", "answer": " PiCO (Wang et al., 2022a) is the method mentioned that employs class prototypes for label disambiguation.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}, {"question": " What is the approach proposed in the paper for learning with noisy labels?", "answer": " The proposed approach enables the learning of a noise model for noisy labels.", "ref_chunk": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}], "doc_text": "refinement (Lv et al., 2020; Arachie & Huang, 2021), average over the given labels (H\u00fcllermeier & Cheng, 2015; Lv et al., 2023), etc.), to train the model, which inevitably accumulates error during training, and reduces the generalization performance. In this paper, we formulate the problem from a different view: rather than taking the imprecise label information provided as a potentially noisy or incomplete attempt at assigning labels to instances, we treat it generically as the information that imposes a deterministic or statistical restriction of the actual applicable true labels. We then train the model over the distribution of all possible labeling entailed by the given imprecise information. More specifically, for a dataset with samples X and imprecise label information I, we treat the inaccessible full and precise labels Y as a latent variable. The model is then trained to maximize the likelihood of the provided information I. Since the likelihood computed over the joint probability P (X, I; \u03b8) = (cid:80) Y P (X, I, Y ; \u03b8) must marginalize out Y , the actual information I provided could permit a potentially exponential number of labeling. To deal with the resulting challenge of maximizing the logarithm of an expectation, we use the common approach of expectation-maximization (EM) (Dempster et al., 1977), where the E-step computes the expectation of P (X, I, Y ; \u03b8) given the posterior of current belief P (Y |X, I; \u03b8t) and the M-step maximizes the tight variational lower bound over P (X, I; \u03b8). The overall framework is thus largely agnostic to the various nature of label imprecision, with the imprecise label only affecting the manner in which the posterior P (Y |X, I; \u03b8t) is computed. In fact, current approaches designed for various imprecise label scenarios can be treated as specific instances of our framework. Thus, our approach can serve as a solution towards a unified view for learning with any imprecise labels. While there exist earlier attempts on generalized or EM solutions for different (other) imprecise supervisions or fuzzy observations (Den\u0153ux, 2011; H\u00fcllermeier, 2014; Quost & Denoeux, 2016; Van Rooyen & Williamson, 2017; Zhang et al., 2020), they usually require additional assumptions 2 Preprint LinearHead\ud835\udc88 EMAEncoder \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udcd0\ud835\udc2c(\ud835\udc31) MLPHead\ud835\udc21 \ud835\udcd0\ud835\udc98(\ud835\udc99) \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc95 Encoder\ud835\udc87 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc8d)\ud835\udcd0\ud835\udc94(\ud835\udc99\ud835\udc96)\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc94\ud835\udc96\ud835\udc91 \ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc96\ud835\udc8f\ud835\udc94\ud835\udc96\ud835\udc91 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc98(\ud835\udc99\ud835\udc96) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc6a\ud835\udc90\ud835\udc8f\ud835\udc94\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udcdb\ud835\udc6a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 LinearHead\ud835\udc88 Encoder\ud835\udc87 NoiseModel \ud835\udcdb\ud835\udc74\ud835\udc7a\ud835\udc6c\ud835\udc8f\ud835\udc90\ud835\udc8a\ud835\udc94\ud835\udc86 \ud835\udcdb\ud835\udc6c\ud835\udc8f\ud835\udc95\ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) Encoder\ud835\udc87 \ud835\udcdb\ud835\udc70\ud835\udc73\ud835\udc73 LinearHead\ud835\udc88 \ud835\udcd0\ud835\udc94(\ud835\udc99)\ud835\udcd0\ud835\udc98(\ud835\udc99) EM (a) Partial Label (b) Semi-Supervised (c) Noisy Label (d) Imprecise Label Figure 2: Baseline model pipelines for various imprecise label configurations. (a) PiCO (Wang et al., 2022a) for partial label learning. (b) FixMatch (Sohn et al., 2020) for semi-supervised learning. (c) SOP (Liu et al., 2022) for noisy label learning. (d) The proposed unified framework. It accommodates any imprecise label configurations and also mixed imprecise labels with an EM formulation. and approximations on the imprecise information for learnablility (Campagner, 2021; 2023), thus presenting limited scalability on practical settings (Quost & Denoeux, 2016). On the contrary, the unified framework we propose subsumes all of these and naturally extends to the more practical \u201cmixed\u201d style of data, where different types of imprecise labels coexist. Moreover, for noisy labels, our framework inherently enables the learning of a noise model, as we will show in Section 3.2. Through comprehensive experiments, we demonstrate that the proposed imprecise label learning (ILL) framework not only outperforms previous methods for dealing with single imprecise labels, but also presents robustness and effectiveness for mixed label settings, leveraging the full potential to more realistic and challenging scenarios. Our contributions are summarized as follows: We propose an EM framework towards the unification of learning from any imprecise labels. \u2022 We establish state-of-the-art (SOTA) performance with the proposed method on partial label learning, semi-supervised learning, and noisy label learning, demonstrating our method\u2019s robustness in more diverse, complex label noise scenarios. To the best of our knowledge, our work is the first to show the robustness and effectiveness of a single unified method for handling the mixture of various imprecise labels. 2 RELATED WORK We revisit the relevant work, especially the state-of-the-art popular baselines for learning with individual imprecise label configurations. Let X denote the input space, and Y = [C] := {1, . . . , C} represent the label space with C distinct labels. A fully annotated training dataset of size N is represented as D = {(xi, yi)}i\u2208[N ]. Learning with imprecise labels involves approximating the mapping function f \u25e6 g : X \u2192 Y from a training dataset where the true label y is not fully revealed from the annotation process. Here f is the backbone for feature extraction, g refers to the classifier built on top of the features, and the output from f \u25e6 g is the predicted probability p(y|x; \u03b8), where \u03b8 is the learnable parameter for f \u25e6 g. In this study, we primarily consider three imprecise label configurations (as illustrated in Fig. 1) and their corresponding representative learning paradigms (as shown in Fig. 2), namely partial label learning, semi-supervised learning, and noisy label learning. A more comprehensive related work, including other forms of imprecision, is provided in Appendix B. Partial label learning (PLL). PLL aims to learn with a candidate label set s \u2282 Y, where the ground truth label y \u2208 Y is concealed in s. The training data for partial labels thus becomes DPLL = {(xi, si)}i\u2208[N ]. The prior arts in PLL can be roughly divided into identification-based for label disambiguation (Zhang & Yu, 2015; Gong et al., 2017; Xu et al., 2019; Wu et al., 2023b) or average-based for utilizing all candidate labels equally (H\u00fcllermeier & Beringer, 2006; Cour et al., 2011; Lv et al., 2023). PiCO (Wang et al., 2022a) is a recent contrastive method that employs class prototypes to enhance label disambiguation (as shown in Fig. 2(a)). It optimizes the cross-entropy (CE)1 loss between the prediction of the augmented training sample Aw(x) and the disambiguated labels \u02c6s. The class prototypes are updated from the features associated with the same pseudo-targets. A contrastive loss, based on MOCO (He et al., 2020), is employed to better"}