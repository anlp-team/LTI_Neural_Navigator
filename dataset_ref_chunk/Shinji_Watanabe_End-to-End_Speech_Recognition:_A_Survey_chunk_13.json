{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_End-to-End_Speech_Recognition:_A_Survey_chunk_13.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some examples of non-autoregressive models mentioned in the text?", "answer": " Examples include Imputer, Mask-CTC, Insertion-based modeling, CIF, and other variants.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " What real-time factor was achieved by CTC greedy search and its variants using an Intel Xeon Silver 4114 CPU?", "answer": " 0.06 real-time factor (RTF)", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " What is the major difference between frame synchronous beam search and label synchronous beam search?", "answer": " The major difference is whether they perform hypothesis pruning for every input frame or every output token.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " In label synchronous beam search, what hypothesis is also added during the pruning process?", "answer": " The hypothesis that reaches the end of an utterance (predicts the end of sentence symbol \u27e8eos\u27e9) is added.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " What does the greedy search algorithm not consider compared to the beam search algorithm?", "answer": " The greedy search algorithm does not consider alternate hypotheses in a sequence.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " Why does the label synchronous beam search require heuristics to limit the output sequence length?", "answer": " To avoid extremely long/short output sequences which can result in large deletion and insertion errors.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " How are the minimum and maximum output lengths determined in the heuristic approach mentioned in the text?", "answer": " The thresholds are determined proportionally to the input frame length |X| with tunable parameters \u03c1min and \u03c1max.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " What additional score related to the output length is mentioned as a heuristic approach?", "answer": " A length penalty and a coverage term are mentioned.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " Why is block-wise processing important for implicit alignment modeling approaches?", "answer": " It can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block-wise streaming decoding.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}, {"question": " What is the purpose of model fusion during decoding according to the text?", "answer": " Model fusion during decoding is similar to the classical HMM-based beam search.", "ref_chunk": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}], "doc_text": "the frames is parallelized [190], [230]. For example, the non-autoregressive models, including Im- puter [231], Mask-CTC [230], Insertion-based modeling [232], Continuous integrate-and-fire (CIF) [233] and other variants [234], [235] have been actively studied as an alternative non- autoregressive model to CTC. [235] shows that CTC greedy search and its variants achieve 0.06 real-time factor (RTF)7 by using Intel(R) Xeon(R) Silver 4114 CPU, 2.20GHz. The paper also shows that the degradation of the non-autoregressive models from the attention/RNN-T methods with beam search is not extremely large (19.7% with self-conditioned CTC [234] versus 18.5 and 18.9% with AED and RNN-T, respectively). The greedy search algorithm is also used as approximate decoding for both implicit and explicit alignment modeling approaches, including AED, RNA, CTC, and RNN-T, as follows: There are two major beam search categories: 1) frame synchronous beam search and 2) label synchronous beam search. The major difference between them is whether it performs hypothesis pruning for every input frame t or every output token i. The following sections describe these two algorithms in more detail. C. Label Synchronous Beam Search Suppose we have a set of partial hypotheses up to (i \u2212 1)th token \u02dcC1:i\u22121. A set of all possible partial hypotheses up to ith token C1:i is expanded from \u02dcC1:i\u22121 as follows: C1:i = {( \u02dcC1:i\u22121, ci = c)}c\u2208U (7) The number of hypotheses |C1:i| would be | \u02dcC1:i\u22121| \u00d7 |U|, at most. The beam search algorithm prunes the low probability score hypotheses from C1:i and only keeps a certain number (beam size \u2206) of hypotheses at i among C1:i. This pruning step is represented as follows: \u02dcC1:i = NBESTC1:i\u2208C1:i P (C1:i|X), where | \u02dcC1:i| = \u2206 (8) Note that NBEST(\u00b7) is an operation to extract top \u2206 hypothe- ses in terms of the probability score P (C1:i|X) computed from an end-to-end neural network, or a fusion of multiple scores described in Section VII-B. In the label synchronous beam search, the length of the out- put sequence (N ) is unknown. Therefore, during this pruning process, we also add the hypothesis that reaches the end of an utterance (i.e., predict the end of sentence symbol \u27e8eos\u27e9) to a set of hypotheses \u02dcC in Eq. (6) as a promising hypothesis. \u02c6ci = arg max ci P (ci| \u02c6C1:i\u22121, X) for i = 1, . . . , N \u02c6at = arg max at P (at| \u02c6A1:t\u22121, X) for t = 1, . . . , T The greedy search algorithm does not consider alternate hypotheses in a sequence compared with the beam search algorithm described below. However, it is known that the degradation of the greedy search algorithm is not very large trained in [16], [46], especially when the model matched conditions8. is well 7 The ratio of the actual decoding time to the duration of the input speech. 8 On the other hand, in the AED models, increasing the search space does not consistently improve the speech recognition performance [77], [236] \u2013 a fact also observed in neural machine translation [237]. The label synchronous beam search does not explicitly depend on the alignment information; thus, it is often used in implicit alignment modeling approaches, including AED. Due to this nature, sequence hypotheses of the same length might cover a completely different number of encoder frames, unlike the frame synchronous beam search, as pointed out by [40]. As a result, we observe that the scores of very short and long segment hypotheses often become the same range, and the beam search wrongly selects such hypotheses. [86] shows an example of such extreme cases, resulting in large deletion and insertion errors for short and long-segment hypotheses, respectively. Thus, the label synchronous beam search requires heuristics to limit the output sequence length to avoid ex- tremely long/short output sequences. Usually, the minimum and maximum length thresholds are determined proportionally This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ This article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2023.3328283 to the input frame length |X| with tunable parameters \u03c1min and \u03c1max as Lmin = \u230a\u03c1min|X|\u230b, Lmax = \u230a\u03c1max|X|\u230b. Although these are quite intuitive ways to control the length of a hypothesis, the minimum and maximum output lengths depend on the token unit or type of script in each language. Another heuristic is to provide an additional score related to the output length or attention weights \u2013 e.g., a length penalty, and a coverage term [77], [238]. The end-point detection [239] is also used to estimate the hypothesis length automatically. [236] redefines the implicit length model of the attention decoder to take into account beam search, resulting in consistent behavior without degradation for increasing beam sizes. Note that there are several studies on applying label syn- chronous beam search to explicit alignment modeling ap- proaches. For example, label synchronous beam search al- gorithms for CTC are realized by marginalizing all possible alignments for each label hypothesis [13]. [240] extends CIF [233] to produce label-level encoder representation and realizes label synchronous beam search in RNN-T. E. Block-wise Decoding Another beam search implementation uses a fixed-length block unit for the input feature. In this block processing, we can use the future context inside the block by using the non- causal encoder network based on the BLSTM, output-delayed unidirectional LSTM, or transformer (and its variants). This future context information avoids the degradation of the fully causal network. In this setup, the chunk size becomes the trade-off of controlling latency and accuracy. This technique is used in both RNN-T [100], [250], [251] and AED [61], [252], [253], [254]. Block-wise processing is especially important for implicit alignment modeling approaches, including AED, since it can provide block-wise monotonic alignment constraint between the input feature and output label, and realize block- wise streaming decoding. F. Model Fusion during Decoding Similar to the classical HMM-based beam search,"}