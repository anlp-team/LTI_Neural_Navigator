{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_It\u2019s_MBR_All_the_Way_Down:_Modern_Generation_Techniques_Through_the_Lens_of_Minimum_Bayes_Risk_chunk_6.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some of the applications of Minimum Bayes Risk (MBR) decoding in the field of natural language processing during the 1990s and early 2000s?,        answer: Some applications include syntactical parsing, automatic speech recognition, and statistical machine translation.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What were the inductive biases relied upon for many NLP tasks during the early applications of MBR?,        answer: Graph structures such as parse trees or translation lattices/hypergraphs.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " In contrast to later MBR work, what did early MBR works use as hypothesis and evidence spaces?,        answer: Graphical models such as parse trees or translation lattices/hypergraphs.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What approach did early MBR work rely on for exact MBR decoding?,        answer: Dynamic programming algorithms.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " Apart from translation tasks, what other tasks have demonstrated the efficacy of MBR?,        answer: Question answering.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " How has MBR resurfaced in recent years as a decision rule for text-generation models?,        answer: As a way to move past beam search, which has known pathologies.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What is the main concept behind Minimum Bayes Risk (MBR) decoding?,        answer: Sampling a set from a distribution and choosing an output to minimize risk according to that set.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What has declined in popularity, but the underlying concept remains and has taken many surface forms?,        answer: Minimum Bayes Risk decoding.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What are some modern methods that have recontextualized the concept of MBR, according to the text?,        answer: From self-consistency to range voting to output ensembles.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}, {"question": " What is crucial in understanding why modern techniques are effective, according to the text?,        answer: Recognizing the connections between modern techniques and older work.    ", "ref_chunk": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}], "doc_text": "1990s and early 2000s, finding applications in syntactical pars- ing (Goodman, 1996; Sima\u2019an, 2003), automatic speech recognition (Stolcke et al., 1997; Goel and Byrne, 2000), and statistical machine translation (Kumar and Byrne, 2004; Tromble et al., 2008; Ku- mar et al., 2009). Many NLP tasks during this time relied upon graph structures as inductive biases (i.e. parse trees or translation lattices/hypergraphs). As such, early MBR works often used these graphical models as hypothesis and evidence spaces. Work on lattice MBR (Tromble et al., 2008), for instance, treated the set of all hypotheses encoded in a word lattice, of which there are exponentially many, as both evidence and hypothesis sets. This is in con- trast to most later MBR work, which operates on a relatively small list of text outputs obtained from a neural model. As a result, early work relied on rather involved dynamic programming algorithms for exact MBR decoding and were restricted to token-factorizable metrics such as BLEU and edit distance. Later work additionally demonstrated the efficacy of MBR for question answering (Duan, 2013) and for joining statistical and neural ap- proaches to translation (Stahlberg et al., 2017). Recent usage to move past In an effort beam search, which has well-known pathologies (Stahlberg and Byrne, 2019), MBR has in re- cent years resurfaced as a decision rule for text- generation models (Eikema and Aziz, 2020). As discussed earlier in \u00a73, several lines of work have sprung up investigating the properties of MBR in modern neural text generation setups. Notably, however, most of these works have focused on ap- plications of the method to neural machine transla- tion, with only a few very recent works studying its applications in other text generation tasks (Shi et al., 2022; Wiher et al., 2022; Suzgun et al., 2023). Outside of these areas, the method has largely been applied in shared task papers (e.g. Manakul Mentions of methods by year 2005 mbr decoding 0.005 0.010 2010 bayes risk decoding minimum bayes risk 2020Year 0.025Percentage of papers that mention mbr 2000 0.000 2015 0.020 0.015 Figure 1: The use of MBR (by name) peaked in the mid-2010s. This graph shows the percentage of ACL Anthology papers that mention several MBR-related phrases by year, from 2000 to 2022. et al. (2023); Yan et al. (2022); Barzdins and Gosko (2016)), as it provides a reliable boost in perfor- mance. The fraction of papers in the ACL Anthol- ogy that reference MBR (at least by this name) has declined from its peak around 2009 (Figure 1). 7 Conclusion Minimum Bayes Risk decoding has declined in popularity, but the underlying concept of sam- pling a set from a distribution and choosing an output to minimize risk according to that set has remained. This concept now takes many surface forms\u2013 from self-consistency to range voting to output ensembles\u2013 and current research in these areas rarely draws connections to MBR. While re- discovery is a key part of science, so is recontex- tualizing new methods within a broader research narrative. This can often reveal new insights or cast findings in a different light. For instance, the empirical benefits of self-consistency can be justi- fied through an MBR framing; work on extensions to self-consistency has rediscovered other proper- ties of MBR; and work on ensembling has raised questions about how to weight mixtures of models that can be reasoned about within the framework of noisy estimates of global probability distributions. The adoption of newer terms for MBR-like meth- ods may be a type of terminology drift. Related phenomena have been studied in the philosophy of science literature, including pressures to coin new terms (Dyke, 1992; Merton, 1957), potential negative consequences of divergent terminology (Calvert, 1956; Samigullina et al., 2020), and de- creased citation of older methods in NLP (Singh et al., 2023). For a more involved discussion of the literature on term coining and possible connections, see Appendix B. Language is not static, so some degree of ter- minology drift in scientific literature is unavoid- able. However, recognizing the connections be- tween modern techniques and older work is crucial to understanding why such methods are effective. We must not forget the lessons of the past as we search for the methods of the future. Acknowledgments We would like to thank Jason Eisner and Patrick Fernandes for useful early discussions about this work, and Saujas Vaduguru, Daniel Fried, and Shuyan Zhou for feedback on this draft. This work was supported in part by grants from the Singapore Defence Science and Technology the Air Force Re- Agency, 3M \u2014 M*Modal, search Laboratory (AFRL), and the National Sci- ence Foundation Graduate Research Fellowship Program under Grant No. DGE2140739. Any opinions, findings, and conclusions or recommen- dations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors. References Chantal Amrhein and Rico Sennrich. 2022. Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for In Proceedings of the 2nd Conference COMET. of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1125\u20131141, Online only. Association for Computational Linguistics. Guntis Barzdins and Didzis Gosko. 2016. RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR pars- ing accuracy. In Proceedings of the 10th Interna- tional Workshop on Semantic Evaluation (SemEval- 2016), pages 1143\u20131147, San Diego, California. As- sociation for Computational Linguistics. Daniel Bernoulli. 1738. Specimen theoriae novae de mensura sortis. Commentarii academiae scientiarum imperialis Petropolitanae, 5:175\u2013192. Peter J. Bickel and Kjell A. Doksum. 1977. Mathe- matical Statistic: Basic Ideas and Selected Topics. Holden-Day Inc., Oakland, CA. Ond\u02c7rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, An- tonio Jimeno Yepes, Philipp Koehn, Varvara Lo- gacheva, Christof Monz, Matteo Negri, Aur\u00e9lie N\u00e9v\u00e9ol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 conference on machine translation. In Proceedings"}