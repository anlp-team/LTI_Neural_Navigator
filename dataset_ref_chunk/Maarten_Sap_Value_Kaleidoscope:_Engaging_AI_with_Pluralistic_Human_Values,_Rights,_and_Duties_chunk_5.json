{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Maarten_Sap_Value_Kaleidoscope:_Engaging_AI_with_Pluralistic_Human_Values,_Rights,_and_Duties_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the focus of the system mentioned in the text?,        answer: Modeling diverse values    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What advantage does the decision system KALEIDODEC have according to the text?,        answer: Interpretable and steerable    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " How does the system KALEIDODEC perform in a zero-shot evaluation on COMMONSENSENORMBANK?,        answer: Performs at least as well as the majority class baseline    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What improvement does the +label calibration provide in the SBIC and SocialChem datasets?,        answer: About 5% and 15% accuracy improvement, respectively    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " In what way is entropy used as an indicator in decision variability?,        answer: Higher entropy indicates higher variability in decisions    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What does the output entropy of KALEIDODEC predict in the MoralChoice and SocialChem datasets?,        answer: Ambiguity in MoralChoice and controversialness in SocialChem    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What advantage does the model KALEIDO have over GPT-4 in terms of generating values?,        answer: Controllability, allowing the generation of more or fewer values    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " How does KALEIDO differ from GPT-4 in terms of valence labels?,        answer: KALEIDO generates scalar valence scores while GPT-4 provides textual labels    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What can users do with KALEIDO by trading precision for recall?,        answer: Generate either more or fewer values    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}, {"question": " What is one of the strengths of the approach mentioned in the text in dealing with situation variations?,        answer: Signal can be contextualized and dependent on relevant values    ", "ref_chunk": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}], "doc_text": "al. 2023), which contains crowdsourced ethical judgments across several different frameworks, fit- ting templates with values, rights, or duties that loosely cor- respond to the frameworks (see Appendix L). Subset KALEIDO ChatGPT Random Justice Deont. Virtue Util. Comm. 17.5 / 13.3 19.8 / 15.1 33.1 / 22.2 76.5 / 66.6 71.5 / 64.7 17.6 / 13.4 20.6 / 13.8 24.9 / 22.0 59.4 / 55.1 80.3 / 68.8 6.3 / 6.3 6.3 / 6.3 8.2 / 8.2 50.0 / 50.0 50.0 / 50.0 Average 43.7 / 36.4 40.6 / 34.6 24.2 / 24.2 Table 4: ETHICS few-shot performance. First/second num- ber of each entry is performance on the test/hard test sets respectively. KALEIDO is zero-shot, ChatGPT is few-shot. Results are in Table 4. On all five tasks, our model per- forms well over the random baseline. On all tasks but Com- monsense, our model matches or exceeds (Justice, Deont., Virtue, Util.) ChatGPT\u2019s performance, while only having 3B parameters. Despite having only been trained to predict val- ues, rights, and duties, our model meaningfully generalizes to other frameworks. 5.4 Interpretable Decision System and Zero-Shot on COMMONSENSENORMBANK While the focus of the system is on modeling diverse values and not on making judgments, it can be easily extended to output the valence of an action V (a): V (a) = (cid:88) R(v|a) \u00d7 V (v|a) v\u2208V RD where v \u2208 V RD are the generated values, rights, and duties from KALEIDOSYS, R(v|a) is the relevance of v given the action, and V (v|a) is the valence of v given the action. We will denote this decision system KALEIDODEC. This system has the advantage of being interpretable, en- abling direct inspection of how values linearly contribute to the outcome. It is also steerable, as users can easily assign a weight of zero to values they do not wish to take into con- sideration. Zero-shot COMMONSENSENORMBANK performance We evaluate this system in a zero-shot manner on the four subportions of moral acceptability segment of COMMON- SENSENORMBANK (Jiang et al. 2022) (See Table 5). In all cases, the system performs at least as well as the majority class baseline, and much (\u226525%) better on ETHICS and Moral Stories12. 12For these two datasets, there is no \u201cneutral\u201d (i.e., lacks valence) class, so the \u201ceither\u201d valence is zeroed out. Model KALEIDODEC +label calibration (improvement) SBIC ETH. MoSt 64.4 69.3 (+4.9) 77.9 78.0 (+0.1) 75.4 76.2 (+0.8) SoCh 48.2 63.0 (+14.8) Majority class Random Delphi (SFT) 63.1 33.3 82.9 51.6 50.0 86.2 50.0 50.0 86.5 46.7 33.3 78.0 Table 5: Zero-shot Performance on COMMONSENSENORM- BANK: Moral Acceptability. We observe that the classes are not well calibrated to the dataset statistics. To remedy this, we fit a lightweight logistic regression. For SBIC and SocialChem it improves accuracy by about 5% and 15% respectively, suggesting that while the model is not initially well-calibrated to the datasets, relevant information can be linearly extracted. While KALEIDODEC achieves non-trivial zero-shot performance, it unsurprisingly performs worse than supervised baselines such as Delphi. 5.5 Entropy as an Indicator of Decision Variability 0.4 7.5Density 2.5 0.2 Threshold: 0.42MoralChoice - Entropy vs Ambiguity Accuracy: 0.81, F1: 0.81 0.8 Low Ambiguity 5.0 0.0 1.0 0.6 0.0 High Ambiguity 0 0.4 High Controversialness 1.0Entropy (nats) 0.6 1 Accuracy: 0.70, F1: 0.68 Low Controversialness 2Density 0.0 0.8 0.2 Threshold: 0.74SocialChem - Entropy vs Controversialness Figure 3: The output entropy of KALEIDODEC is predictive of ambiguity in MoralChoice and controversialness in So- cialChem. A threshold is chosen to maximize F1-score. When values support different decisions, it may be an in- dicator that the final judgment one may come to is highly de- pendent on which value is prioritized. Because of this, when KALEIDODEC output has high entropy, we hypothesize that this may indicate higher variability in the distribution of de- cisions. To test this, we explore two datasets with variability indicators. MORALCHOICE (Scherrer et al. 2023) contains 687 low-ambiguity and 680 high-ambiguity moral scenar- ios. SOCIALCHEM (Forbes et al. 2021) is a corpus of social Paremeter Sweep: RougeLsum 0.2 60 0.00 0 0.00 Same as GPT-4 (7.0) 0.25 40 0.6Precision 0.75Recall 0.75Recall 0.4 # of Values, Rights, Duties 0.25 20 0.50 0.50 Figure 4: By sweeping KALEIDOSYS\u2019s parameters, we are able to trade precision (w.r.t. to GPT-4) with recall, and out- put many more (or fewer) values, rights, and duties. Figure 5: KALEIDO is sensitive to subtle changes in inputs, changing relevance and valence scores accordingly. norms where, among other things, crowdworkers annotated for \u201dWhat portion of people probably agree that [action] is [good / bad]?\u201d. We take those marked as \u2265 99% to have low controversialness, and those marked as \u226450% as having high controversialness. We run the corresponding scenarios through KALEIDODEC and measure the entropy (Figure 3). We find that the entropy is predictive of these classes. In line with our hypothesis, the higher the entropy, the more likely a situation is to be ambiguous or controversial, even though the model was not trained to predict these things explicitly. 6 Discussion Strengths Over Teacher Model Although our model per- forms strongly against the teacher in value generation, it also boasts several other advantages. It is controllable, allowing users to generate either more or fewer values than GPT-4 by trading precision for recall (see Figure 4). Additionally, while GPT-4 provides only textual labels for valence, our model generates scalar valence and relevance scores. Lastly, our model, dataset, and code are openly accessible, enabling scientific review that is crucial for accountability and im- provement. KALEIDO is Sensitive to Situation Variations One of the strengths of our approach is that the signal can be con- textualized and dependent on the relevant values. For exam- ple, consider three variations of a situation: \u201dLeticia kisses Marco,\u201d \u201dLeticia kisses Marco when he doesn\u2019t agree,\u201d and \u201dLeticia kisses Marco when he is sick\u201d (see Figure 5). In all three situations, affection and consent are relevant values, as reflected by their relevance scores. However, the valence changes: consent can either support or oppose the action in the"}