{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_Prompt2Model:_Generating_Deployable_Models_from_Natural_Language_Instructions_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the name of the framework proposed in the text?", "answer": " Prompt2Model", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " How does Prompt2Model generate task-specific models?", "answer": " Using only natural language prompts", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What kind of models does Prompt2Model deliver?", "answer": " Small yet accurate models", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What can the generated datasets of Prompt2Model be used to estimate?", "answer": " Real-world performance", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What are some potential research questions inspired by Prompt2Model?", "answer": " How much data to generate for model training, how diverse it should be, and how to effectively mix retrieved and generated datasets", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What is one of the limitations mentioned regarding the experiments conducted with Prompt2Model?", "answer": " Use of the paid and closed-source gpt-3.5-turbo API", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " Why is it mentioned that Prompt2Model struggles with languages other than English?", "answer": " Limited ability to support processing languages other than English", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What ethical implications are discussed in the text regarding Prompt2Model?", "answer": " Possibility of generating toxic, offensive, or inaccurate synthetic data", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " What is the motivation behind the work on Prompt2Model?", "answer": " To increase accessibility of NLP models to people outside the NLP community", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}, {"question": " Who supported the work on Prompt2Model according to the text?", "answer": " NEC Research Laboratories", "ref_chunk": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}], "doc_text": "erated data shows strong correlation to the true performance on two of the three datasets. 6 Discussion and Conclusion We propose Prompt2Model, a framework that automatically constructs task-specific models us- ing only natural language prompts. Our proof- of-concept experiments show that, despite us- ing a similar easy-to-use interface as LLMs, Prompt2Model delivers small yet accurate mod- els and its generated datasets can be used to esti- mate real-world performance. Besides our refer- ence implementation providing a ready-to-use tool, Prompt2Model\u2019s extensible design and modular implementation makes it a platform for advanc- ing model distillation, dataset generation, synthetic evaluation, dataset retrieval, and model retrieval. We believe our Prompt2Model framework can inspire various novel research questions. We hope that our platform enables future work that looks more deeply into quality assurance on the generated data and the model. Interesting questions include how much data should we generate for downstream model training and how diverse should it be? How do we effectively mix the retrieved and generated dataset such to achieve complementary strengths (e.g. using dataset generation to focus on the ex- pected inputs to the model that the retrieved dataset fails to cover)? Since users often struggle to articu- 8This set of models consisted of 5 T5-family models, 2 BART-family models, and 1-5 additional retrieved models from the Model Retriever, depending on task. late their needs up front, future extensions should also address the challenge of human-in-the-loop correction \u2013 either by offering potential strategies to help humans iteratively refine prompts, or allow- ing humans to perform post-hoc fixes when the task metadata extraction and generated data do not align with their intentions. We hope to propose explicit challenges and invite the community to contribute novel implementations of various components in our framework. Limitations One of the primary limitations of our system is that our current experiments have all been conducted using the gpt-3.5-turbo API (used for prompt parsing, dataset generation, and model retrieval). This LLM is paid and closed-source, which makes this problematic as a scientific artifact (Rogers et al., 2023). Furthermore, the service provider of this LLM, OpenAI, prohibits the use of their API to create models that may compete with OpenAI, creating potential legal concerns with the use of Prompt2Model in commercial applications. We are exploring the integration of open-source LLMs to avoid our reliance on proprietary APIs. Another limitation of our work is the limited abil- ity of Prompt2Model to support tasks that require processing languages other than English. While we have shown the limitations of our system at sup- porting code generation from Japanese natural lan- guage queries, our system is likely to struggle more with lower-resource languages. We use the unpub- lished gpt-3.5-turbo model for our Dataset Gen- erator in our reference implementation. This model is believed to be similar to GPT-3 (Brown et al., 2020), which was trained on 93% English docu- ments, 1% German documents, 1% French docu- ments, and <5% documents in any other language. Our use of this model may exacerbate existing dis- parities in language technologies between high- resource languages and low-resource languages. One potential limitation is that we have only tested our approach on 3 tasks, each with a single dataset and a single evaluation metric. We justify this decision because our focus is on providing an extensible software system rather than establishing state-of-the-art results on many datasets, but we be- lieve that our results suggest broader applicability. Ethics Statement Any system which makes powerful technology more accessible to the public has ethical implica- tions. Widder et al. (2022) discuss ethical issues with open-source packages in relation to software libraries for deepfaking, including the possibility of enabling malicious actors to use technology that they would otherwise not have the technical skills to leverage. This is also a risk for an AutoML sys- tem such as Prompt2Model; however, we believe this risk is outweighed by the benefits of greater accessibility, especially given that a low barrier to entry for generating harmful data already exists in the form of prompted, web-interface models. While Prompt2Model could, if given harm- ful inputs, generate toxic, offensive, or inaccu- rate synthetic data, this is no more of a risk with Prompt2Model than it is with the underlying prompted model (Bender et al., 2021); indeed, the use of models and supplementary datasets retrieved from Hugging Face may lessen the likelihood of a downstream model replicating harms from the prompted model\u2019s outputs, though more investiga- tion is needed. Like all ML models, the models that Prompt2Model returns can make mistakes, and we aim to be transparent in our documentation about potential limitations of the system. We hope that Prompt2Model will be broadly useful. Our work is motivated by a desire to in- crease the accessibility of NLP models to people who are not in the NLP community but would ben- efit from the community\u2019s innovations; particularly, to people who would use NLP models downstream but may not have the domain-specific knowledge to design their own system. Prompt2Model may also prove useful for early NLP researchers by pro- viding a starting point for intuitions about base- lines for various tasks and enabling the discovery of similarities between a described task and exist- ing work. We open-source Prompt2Model and welcome community contributions. Acknowledgements This work was supported in part by a fellowship from NEC Research Laboratories. We are grateful to Alex Cabrera, Will Epperson, Nelson Liu, Ar- jun Ramani, Zirui Cheng, Zhiyuan Zeng, Tianci Xue, Yanchen Liu, Yi-Hsin Hung and Zhilin Yang for their feedback and guidance. We particularly appreciate Zirui Cheng\u2019s video production support for our demo. References Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ML models in the wild. arXiv preprint arXiv:1906.02569. Emily M. Bender, Timnit Gebru, Angelina McMillan- Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language mod- els be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans- parency, FAccT \u201921, page 610\u2013623, New York, NY,"}