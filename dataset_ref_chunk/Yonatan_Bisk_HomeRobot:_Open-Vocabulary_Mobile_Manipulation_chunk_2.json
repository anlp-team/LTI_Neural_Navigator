{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Yonatan_Bisk_HomeRobot:_Open-Vocabulary_Mobile_Manipulation_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of the HomeRobot library mentioned in the text?", "answer": " The purpose of the HomeRobot library is to support tasks such as manipulation learning, continuous learning, navigation, and object-goal navigation.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What does the HomeRobot OVMM challenge focus on?", "answer": " The HomeRobot OVMM challenge focuses on integrating perception, planning, and action to build general-purpose home assistants.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " How does the performance differ between the heuristic solution and the reinforcement learning solution in object navigation?", "answer": " The RL methods moved to the object more efficiently if an object was visible, while the heuristic planner was better at long-horizon exploration.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What is the role of the DETIC object detector in the comparison between the heuristic and RL policies?", "answer": " The DETIC object detector provides object segmentation for both the heuristic and RL policies in the comparison.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What is Open-Vocabulary Mobile Manipulation defined as in the paper?", "answer": " Open-Vocabulary Mobile Manipulation is defined as a new, crucial task for the robotics community that involves navigating from one location to another carrying a small household object.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What kind of benchmark does the paper propose and how does it aim to compare current baselines?", "answer": " The paper proposes a real-world benchmark in a controlled environment and aims to compare current baselines in simulation and in the real world under different conditions.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What is the main goal of having a real-world benchmark according to the text?", "answer": " The main goal of having a real-world benchmark is to enable benchmarking of individual components and building general-purpose home assistants through holistic problem-solving.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " How does the HomeRobot stack enable the benchmarking of individual components?", "answer": " The HomeRobot stack enables the benchmarking of individual components by providing a full robotics stack with multiple implementations of different sub-modules.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What distinguishes the HomeRobot benchmark from other benchmarks mentioned in the text?", "answer": " The HomeRobot benchmark provides a broadly capable robotics stack for implementing and sharing robotics code, which is not provided by other benchmarks.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}, {"question": " What kind of objects does the Open-Vocabulary Mobile Manipulation task involve interacting with?", "answer": " The Open-Vocabulary Mobile Manipulation task involves interacting with small and manipulable household objects like cups, stuffed toys, or boxes.", "ref_chunk": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}], "doc_text": "real world, and is not restricted to just the OVMM task. Our library also supports a number of sub-tasks, including manipulation learning [24], continuous learning [25], navigation [26], and object-goal navigation [2]. 1https://github.com/facebookresearch/home-robot 2 Room Rearrangement [28] Habitat ObjectNav Challenge [29] [30] TDW-Transport [31] VirtualHome [6] ALFRED [21] Habitat 2.0 HAB [32] ProcTHOR Object Scenes Cats 118 Inst. 118 6 7,599 50 112 308 1,066 84 84 20 20 108 1,633 120 216 15 6 120 105 10,000 Continuous Actions \u2716 \u2714 \u2716 \u2716 \u2716 \u2714 \u2716 Sim2Real \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 Robotics Open Stack Licensing Manipulation \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2716 \u2714 \u2714 \u2713 \u2714 \u2714 \u2714 \u2714 \u2716 \u2716 \u2713 \u2713 \u2713 \u2714 \u2714 RoboTHOR Behavior-1K ManiSkill-2 [33] [34] [35] 75 731 43 50 1,265 5,215 1 2,000 2,000 \u2716 \u2714 \u2714 \u2714 \u2714 \u2713 \u2716 \u2716 \u2716 \u2714 \u2716 \u2713 \u2716 \u2713 \u2714 OVMM + HomeRobot 200 150 7,892 \u2714 \u2714 \u2714 \u2714 \u2714 Table 1: Comparisons of our proposed benchmark with prior work. We provide a large number of environments and unique objects, focusing on manipulable objects, with a continuous action space. Uniquely, we also provide a multi-purpose, real-world robotics stack, with demonstrated sim-to-real capabilities, allowing others to reproduce and deploy their own solutions. Additional nuances in footnote3. \u2713Partial availability \u2716Not available \u2714Capability available In this paper, we use HomeRobot to compare two families of approaches: a heuristic solution, using a motion planner shown to work for real-world object search [2], and a reinforcement learning (RL) solution, which learns how to navigate to objects given depth and predicted object segmentation. We use the open-vocabulary object detector DETIC [27] to provide object segmentation for both the heuristic and RL policies. We observe that while the RL methods moved to the object more efficiently if an object was visible, the heuristic planner was better at long-horizon exploration. We also see a substantial drop in performance when switching from ground-truth segmentation to DETIC segmentation. This highlights the importance of the HomeRobot OVMM challenge, as only through viewing the problem holistically - integrating perception, planning, and action - can we build general-purpose home assistants. To summarize, in this paper, we define Open-Vocabulary Mobile Manipulation as a new, crucial task for the robotics community in Sec. 3. We provide a new simulation environment, with multiple, multi-room interactive environments and a wide range of objects. We implement a robotics library called HomeRobot which provides baseline policies implementing this in both the simulation and the real world. We describe a real-world benchmark in a controlled environment, and show how current baselines perform in simulation and in the real world under different conditions. We plan to initially run this real-world benchmark as a Neurips 2023 competition [23]. 2 Related Work We discuss work related to challenges and reproducibility of robotics research in more detail, but continue the discussion of datasets and simulators in Appendix A. Challenges. There have been several challenges aiming to benchmark robotic systems at different tasks. These challenges provided a great testbed for ranking different systems. However, in most of the challenges (e.g., [36\u201339, 3]), the participants create their own robotic platform making a fair comparison of the algorithms difficult. There are also challenges where the organizers provide the robotic platform to the participants (e.g., [40]). However, changing the task during the periodic evaluations made it difficult to track progress over time. Our aim is to have a real world benchmark using a standard hardware that is sustainable at least for a few years. Reproducibility of robotics research. Standardized robotics benchmarks have been pursued for a long time, often by open-sourcing robot designs or introducing low-cost robots [41\u201349]. However, the environments in which these robots are used vary dramatically, leading to evaluation of components (e.g., object navigation, SLAM) in isolation, instead of as components of a larger system that 3ALFRED uses object masks for interaction. ObjectNav uses scans, not full object meshes. ProcThor scenes are procedurally generated, this has the benefit that the potential number of environments is unbounded. 3 SIM REAL Figure 2: A low-cost home robot performing tasks in both a simulated and a real-world environment. We provide both (1) challenging simulated tasks, wherein a mobile manipulator robot must find and grasp multiple seen and unseen objects, and (2) a corresponding real-world robotics stack to allow others to reproduce this research and evaluation to produce useful home robot assistants. may not benefit from those changes. The HomeRobot stack enables end-to-end benchmarking of individual components by providing a full robotics stack, with multiple implementations of different sub-modules. The simplicity helps move beyond standardized sets of objects (e.g., [50\u201352]) to a common set of robots, objects, and environments. Ours is the only benchmark to provide a broadly capable robotics stack for implementing and sharing robotics code; this is similar to projects like PyRobot [53], which doesn\u2019t also provide a strong simulation benchmark. Real World Benchmarks. RoboTHOR [33] provides a common set of scenes and objects for benchmarking navigation. RB2 [54] ranks different manipulation algorithms in a local setting. TOTO [55] takes a step further by providing a training dataset and running the experiments for the users. However, training and testing happen in the same environments and are limited to tabletop manipulation. Finally, the NIST Task Board [56] is a successful challenge for fine-grained manipulation skills [57], also limited to a tabletop context. Kadian et al. [58] propose the Habitat- PyRobot bridge (HaPy) to allow real-world testing on the locobot robot; their framework is limited to navigation, and doesn\u2019t provide a generally-useful robotics stack with visualizations, debugging, motion planners, tooling, etc. 3 Open-Vocabulary Mobile Manipulation Formally, our from the (start_receptacle) to the (goal_receptacle).\u201d The object is a small and manipulable household object (e.g., a cup, stuffed toy, or box). By contrast, start_receptacle and goal_receptacle are large pieces of furniture, which have surfaces upon which objects can be placed. The robot is placed in an unknown single-floor home environment - such as an apartment - and must, given"}