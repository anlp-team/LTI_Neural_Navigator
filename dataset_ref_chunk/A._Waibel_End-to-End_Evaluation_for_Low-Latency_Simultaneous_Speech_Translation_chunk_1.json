{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/A._Waibel_End-to-End_Evaluation_for_Low-Latency_Simultaneous_Speech_Translation_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the focus of the research in the text?", "answer": " The focus of the research is low-latency speech translation.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " Why is it important to evaluate different approaches to low-latency speech translation?", "answer": " It is important to evaluate different approaches to low-latency speech translation to compare and improve the effectiveness of such systems.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " What is the significance of the proposed framework mentioned in the text?", "answer": " The proposed framework allows for evaluating various aspects of low-latency speech translation in realistic scenarios and comparing different approaches.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " In what type of scenarios is low-latency speech translation particularly important?", "answer": " Low-latency speech translation is particularly important in scenarios like presentations or meetings.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " What are some components involved in the framework overview diagram provided in the text?", "answer": " Some components include Speech processing, Text processing, Website, Mediator, API, Audio Client.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " How does the system allow for a flexible processing of data?", "answer": " The system uses a central mediator that coordinates the interaction of different components and dynamically defines how data is sent to different components for each session.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " What are the main contributions of the paper highlighted in the text?", "answer": " The main contributions are a framework for low-latency speech translation with dynamic latency adjustment, an evaluation setup for assessing low-latency scenarios, and a comprehensive evaluation of different translation approaches and streaming algorithms.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " How does the system handle the processing load in high-load situations?", "answer": " The system minimizes increasing latency in high-load situations by enabling the middleware to skip intermediate processing steps and combining multiple input messages.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " What is the purpose of the central mediator in the system architecture?", "answer": " The central mediator coordinates the interaction of different components and forwards data between the user, API, and processing components.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}, {"question": " What type of system is enabled for flexible processing based on the existing streaming framework Kafka?", "answer": " Each component in the system, such as the middleware and backend, enables flexible processing with the help of the streaming framework Kafka.", "ref_chunk": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}], "doc_text": "3 2 0 2 t c O 3 2 ] L C . s c [ 2 v 5 1 4 3 0 . 8 0 3 2 : v i X r a End-to-End Evaluation for Low-Latency Simultaneous Speech Translation Christian Huber1, Tu Anh Dinh1, Carlos Mullov1, Ngoc Quan Pham1, Thai Binh Nguyen1, Fabian Retkowski1, Stefan Constantin1, Enes Yavuz Ugan1, Danni Liu1, Zhaolin Li1, Sai Koneru1, Jan Niehues1 and Alexander Waibel1,2 1Karlsruhe Institute of Technology, Karlsruhe, Germany firstname.lastname@kit.edu 2Carnegie Mellon University, Pittsburgh PA, USA alexander.waibel@cmu.edu Abstract The challenge of low-latency speech transla- tion has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmen- tation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this frame- work. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state- of-the-art cascaded as well as end-to-end sys- tems. Finally, the framework allows to automat- ically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. 1 Introduction In many applications scenarios for speech transla- tion, the quality of the translations is not the only important metric, but it is also essential to provide the translation with a low latency. This is for exam- ple the case in translations of presentations or meet- ings. Therefore, we observe an increasing interest in the field of low-latency speech translations, as shown by numerous published techniques and the organization of a dedicated shared task as part of the International Conference on Spoken Language Translations (IWSLT) (Agrawal et al., 2023). Speech processingSpeech Translation System \u2026 Text processing WebsiteMediatorAPI Audio Client Figure 1: Framework overview However, the current evaluation only considers a limited number of aspects or techniques. In con- trast, for an overall evaluation of different archi- tectures (end-to-end and cascaded) and presenta- tion style (revision and fixed) a general evaluation framework is needed. This should also consider the computational latency as well as the ability to process several sessions in parallel. Motivated by this, we present a new framework to apply and evaluate low-latency, simultaneous speech translation. Thereby we focus on a frame- work that can evaluate the different approaches in as realistic conditions as possible. The system is able to simulate different load conditions as well as compare systems using different design choices. Finally, we also provide a web interface1 to present the low-latency model outputs to the user. The main contributions of our paper are: A framework2 for low-latency speech transla- tion with dynamic latency adjustment An evaluation setup that allows for assessing the quality and latency of a low-latency sce- nario in an end-to-end fashion In order to enable further progress in the field as well as a wide adoption of the technique a frame- work to evaluate different approaches is essential. 1https://lecture-translator.kit.edu 2https://git.scc.kit.edu/isl/lt-middleware/ ltpipeline A comprehensive evaluation of different trans- lation approaches and streaming algorithms In the next section, we describe the overall ar- chitecture of the framework. The two following sections explain the streaming algorithms for the speech and text processing components. After that, we illustrate how we evaluate our framework and then how the experimental setup looks like. In Sec- tion 7 we present the results. Then, we review the related work. At the end we describe the limitations and conclude our work. 2 Dynamic Framework for low-latency speech translation Motivated by previous work (Cho et al., 2013), we use a central mediator that coordinates the inter- action of the different components (see Figure 1). The user sends data to an API component which then sends the data to the mediator. The media- tor forwards all arriving data to the corresponding component(s), e.g., the audio signal from the user to the speech processing component, the resulting transcripts to the text processing component and the output (through the API) to the user. In order to allow a flexible processing, for each session a graph dynamically defines how the data is sent to the dif- ferent components. We process different requests at each component using the existing streaming framework Kafka3. Each component consists of a middleware and a backend with the processing separated into three steps: 1) Input processing: The middleware imple- ments the streaming algorithms and can be run on the CPU. It uses the state of the current ses- sion to generate requests to the backend. Other approaches (Niehues et al., 2018) repeatedly send requests to the backend for all input messages. This can result in increasing latency if the backend is not able to keep up in high-load situations. In or- der to minimize this, we enable the middleware to skip intermediate processing steps. This is done by combining multiple input messages by concatenat- ing audio or text. Several middleware workers can be run in parallel. We achieve the locality of the state by sticky queues, where a message from the same session is always sent to the same middleware worker. 2) Backend request: The backend contains the hosted models. It processes the requests without 3https://kafka.apache.org [M1, M2, M3]S2S3 = \u2018Hello my name is Christian\u2019H3 = \u2018Hello my name is Christian Huber\u2019Model forward [M1, M2]S1S2 = \u2018\u2018Hello my name is\u2019S1 = common_prefix(H1, H0 = \u2018\u2019) = \u2018\u2019H2 = \u2018Hello my name is Christian Koo\u2019Model forward Decoder[M1]S0 = \u2018\u2019H1 = \u2018Hello my name is Kris\u2019Input [M] : Audio or TextStable output [S]Model forwardModel output [H] Encoder Figure 2: Stability detection additional state information, is flexible to run on any"}