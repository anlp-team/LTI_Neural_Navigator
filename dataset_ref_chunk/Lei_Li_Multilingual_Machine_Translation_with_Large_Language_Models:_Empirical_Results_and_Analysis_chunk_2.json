{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Lei_Li_Multilingual_Machine_Translation_with_Large_Language_Models:_Empirical_Results_and_Analysis_chunk_2.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What are some of the most representative language models mentioned in the text?", "answer": " GPT-4 and ChatGPT", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " What is in-context learning and why is it important for language models?", "answer": " In-context learning enables language models to learn target tasks based on prompts without updating parameters. It is important as it helps models generate better outputs in NLP tasks.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " How is the final prompt constructed in in-context learning?", "answer": " The final prompt is constructed by wrapping exemplars with a template and concatenating them together.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " In inference, how does a large language model generate output with the guidance of the prompt?", "answer": " A large language model generates output Y of the test sample X by maximizing the conditional probability p(P \u2295 T (X , Y)).", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " How is prediction handled for label prediction tasks in language models?", "answer": " For label prediction tasks, the prediction can be obtained in one-step generation.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " For sequence generation tasks like machine translation, how can predictions be obtained in language models?", "answer": " For sequence generation tasks, predictions can be obtained through sampling strategies like greedy search and beam search.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " What is the role of exemplars and templates in in-context learning?", "answer": " Exemplars, which are supervised data pairs, and a human-written template are used to construct prompts for in-context learning.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " What does the symbol \u2295 denote in the context of prompt construction?", "answer": " The symbol \u2295 denotes the concatenation symbol, such as whitespace or line-break.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " What is the purpose of the language family direction table mentioned in the text?", "answer": " The language family direction table compares translation performance metrics across different language pairs.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}, {"question": " How are the performance metrics like BLEU and COMET used to evaluate translation performance?", "answer": " Performance metrics like BLEU and COMET are used to quantify the quality of translations for different language pairs.", "ref_chunk": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}], "doc_text": "put into scaling-up language models (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Among them, GPT-4 (OpenAI, 2023) and ChatGPT (Ope- nAI, 2022) are the most representative systems, which shows impressive results in various NLP tasks. 2.2 Emergent Ability: In-context Learning In-context learning is one of the well-known emer- gent abilities (Brown et al., 2020; Dong et al., 2022), which enables LLM to learn target tasks according to the prompt without updating any pa- rameters. Specifically, the prompt is made up of in-context exemplars {(Xi, Yi)}k i=1 and in-context template T . Exemplars are often picked from supervised data, where Yi is the ground truth corresponding to the input sentence Xi. Template T is usually a human-written instruction related to the target task. Wrapping exemplars with the template and concate- nating them together produce the final prompt: P = T (X1, Y1) \u2295 T (X2, Y2) \u2295 \u00b7 \u00b7 \u00b7 \u2295 T (Xk, Yk) where \u2295 denotes the concatenation symbol, e.g., whitespace, line-break. During inference, LLM is able to generate the corresponding output Y of the test sample X under the guidance of the prompt: arg max Y p(P \u2295 T (X , Y)) For label prediction tasks, the prediction Y can be obtained in one-step generation. For sequence generation tasks, e.g., machine translation, the pre- diction Y can be obtained through sampling strate- gies like greedy search and beam search. (1) Language Family Direction XGLM-7.5B OPT-175B Falcon-7B Translation Performance (BLEU / COMET) LLaMA2-7B LLaMA2-7B-Chat ChatGPT GPT-4 M2M-12B NLLB-1.3B Google Indo-Euro-Germanic (8) X\u21d2Eng Eng\u21d2X 18.54 / 70.09 9.16 / 50.21 34.65 / 83.71 18.89 / 71.97 27.37 / 67.40 13.19 / 52.93 37.28 / 84.73 22.78 / 76.05 34.82 / 84.25 19.44 / 73.63 45.83 / 89.05 36.34 / 87.83 48.51 / 89.48 40.64 / 88.50 42.72 / 87.74 37.30 / 86.47 46.54 / 88.18 38.47 / 87.31 51.16 / 89.36 45.27 / 89.05 Indo-Euro-Romance (8) X\u21d2Eng Eng\u21d2X 31.11 / 79.67 21.95 / 69.08 38.93 / 87.75 24.30 / 79.07 34.06 / 84.40 20.02 / 70.36 41.10 / 88.10 27.81 / 82.05 37.84 / 87.80 25.50 / 79.67 45.68 / 89.61 41.35 / 89.00 47.29 / 89.74 44.47 / 88.94 42.33 / 88.31 42.98 / 87.56 46.33 / 88.99 43.48 / 88.12 35.69 / 89.66 37.10 / 88.77 Indo-Euro-Slavic (12) X\u21d2Eng Eng\u21d2X 13.20 / 64.24 6.40 / 43.28 20.83 / 74.80 8.18 / 54.45 13.15 / 57.34 4.34 / 35.73 34.00 / 84.90 20.24 / 76.30 30.94 / 83.90 16.14 / 69.75 39.27 / 87.74 32.61 / 87.90 41.19 / 88.15 36.06 / 89.15 35.87 / 85.97 35.01 / 86.43 39.23 / 87.08 36.56 / 88.74 43.61 / 88.18 42.75 / 90.05 Indo-Euro-Indo-Aryan (10) X\u21d2Eng Eng\u21d2X 8.68 / 63.93 4.76 / 40.99 1.20 / 49.37 0.14 / 31.85 1.40 / 45.22 0.13 / 25.84 6.68 / 62.63 1.61 / 35.92 4.29 / 60.29 1.24 / 34.74 25.32 / 84.14 16.50 / 68.43 37.30 / 87.79 21.35 / 73.75 17.53 / 69.66 14.44 / 65.32 40.75 / 88.80 34.04 / 82.55 45.66 / 89.43 39.04 / 82.78 Indo-Euro-Other (11) X\u21d2Eng Eng\u21d2X 7.32 / 55.29 4.51 / 40.60 7.80 / 59.60 3.10 / 40.04 7.04 / 51.59 3.38 / 34.64 14.27 / 69.87 5.00 / 44.09 11.46 / 67.64 4.83 / 43.73 29.54 / 84.52 22.81 / 77.33 37.29 / 86.76 28.45 / 80.94 22.38 / 77.47 19.71 / 74.90 36.16 / 86.81 31.65 / 85.82 41.68 / 88.29 38.54 / 87.44 Austronesian (6) X\u21d2Eng Eng\u21d2X 16.19 / 78.80 10.01 / 73.14 25.60 / 78.03 10.68 / 64.97 18.62 / 75.36 8.56 / 60.89 26.70 / 80.21 14.59 / 74.80 24.39 / 80.39 13.29 / 74.88 39.95 / 87.29 30.17 / 86.36 46.81 / 88.65 34.66 / 87.68 31.84 / 84.76 27.03 / 86.83 45.41 / 87.85 37.17 / 88.82 50.68 / 88.89 40.74 / 89.34 Atlantic-Congo (14) X\u21d2Eng Eng\u21d2X 6.67 / 62.00 2.52 / 54.93 9.17 / 57.59 1.60 / 34.15 6.98 / 0.56 1.89 / 0.34 8.76 / 57.72 2.45 / 34.17 9.01 / 57.86 3.09 / 38.13 19.86 / 79.63 8.91 / 75.26 28.27 / 83.42 13.70 / 77.79 10.55 / 76.43 6.53 / 75.79 32.20 / 84.00 21.99 / 79.95 23.55 / 85.44 16.77 / 80.89 Afro-Asiatic (6) X\u21d2Eng Eng\u21d2X 6.70 / 54.51 2.07 / 41.48 5.93 / 52.90 1.40 / 41.86 4.87 / 38.62 1.40 / 27.64 10.41 / 57.72 3.22 / 43.04 8.65 / 58.27 3.07 / 43.39 20.84 / 70.39 13.57 / 67.60 30.48 / 78.76 19.36 / 75.56 10.00 / 66.98 7.83 / 68.86 32.69 / 82.99 26.08 / 82.84 36.14 / 84.47 31.00 / 83.78 Turkic (5) X\u21d2Eng Eng\u21d2X 7.43 / 61.69 3.48 / 40.32 7.89 / 62.47 2.58 / 44.80 4.15 / 33.11 1.75 / 20.00 9.51 / 65.95 3.28 / 39.65 8.88 / 66.15 3.09 / 41.97 24.64 / 84.04 17.13 / 74.77 31.73 / 86.90 20.96 / 78.50 10.25 / 58.52 10.87 / 68.21 32.92 / 87.51 30.17 / 88.47 37.78 / 88.53 36.54 / 89.38 Dravidian (4) X\u21d2Eng Eng\u21d2X 8.04 / 61.95 5.30 / 48.15 0.89 / 44.01 0.02 / 32.51 1.18 / 24.29 0.03 / 15.31 2.65 / 53.17 0.56 / 34.03 1.52 / 52.95 0.58 / 35.65 20.26 / 82.00 12.34 / 64.74 33.10 / 86.91 18.60 / 75.15 10.26 / 63.77 6.85 / 62.25 39.07 / 88.42 37.33 / 86.32 43.17 / 89.10 44.16 / 87.75 Sino-Tibetan (3) X\u21d2Eng Eng\u21d2X 9.35 / 58.60 10.14 / 74.16 9.32 / 65.32 2.57 / 54.73 16.59 / 72.34 10.74 / 66.74 18.35 / 74.45 12.24 / 65.99 16.88 / 74.20 9.06 / 65.07 21.36 / 78.52 19.92 / 76.04 27.74 / 84.48 22.81 / 81.11 11.09 / 71.35 10.42 / 73.82 30.88 / 86.50 16.85 / 80.74 35.68 / 87.66 32.40 / 88.52 Other (14) X\u21d2Eng Eng\u21d2X 9.71 / 60.43 8.42 / 51.57 10.10 / 60.78 3.82 / 46.85 5.37 / 47.38 1.73 / 29.73 16.00 / 71.15 8.19 / 53.20 14.25 / 70.35 7.14 / 52.12"}