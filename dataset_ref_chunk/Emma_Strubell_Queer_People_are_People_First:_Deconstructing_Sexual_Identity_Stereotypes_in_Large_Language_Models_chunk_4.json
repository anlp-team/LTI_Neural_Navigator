{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Emma_Strubell_Queer_People_are_People_First:_Deconstructing_Sexual_Identity_Stereotypes_in_Large_Language_Models_chunk_4.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the purpose of using pointwise mutual information (PMI) analysis in the context of a Language Model (LLM)?", "answer": " To analyze words that occur more often with one type of trigger word compared to other trigger words.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " How many words are usually considered when calculating PMI?", "answer": " 2 words.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What is the purpose of t-SNE visualizations in the context of a Language Model (LLM)?", "answer": " To plot sentence embeddings in a two-dimensional space and visualize the similarity between data points.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What does average cosine similarity measure in the context of a Language Model (LLM)?", "answer": " It measures the similarity between output embeddings of prompts with sexual identity trigger words and control prompts.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What does the regard score measure in the context of a Language Model (LLM)?", "answer": " It measures how society perceives an individual based on the words used to describe them.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What was observed about the regard scores of outputs when the prompt included queer trigger words compared to straight counterparts?", "answer": " Outputs with queer trigger words had lower regard scores than those with straight counterparts.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What approach was employed to mitigate bias in the generated output of the Language Model (LLM)?", "answer": " A post-hoc approach using a text-to-text neural style transfer task to preserve semantic meaning and increase regard.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " How is SHAP utilized in detecting bias in the Language Model (LLM) output?", "answer": " It is used with a trained classifier to detect words that influence the output towards a particular label more than others.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What methodology is used to prompt the LLM for rephrasing sentences to keep the meaning intact and choose different words for low-regard words?", "answer": " Chain-of-thought prompting (CoT).", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}, {"question": " What was observed from the t-SNE plot regarding the outputs of control, straight men, gay men, and lesbian women?", "answer": " Control and straight men outputs were similar, while gay men and lesbian women were closer to each other but afar from control outputs.", "ref_chunk": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}], "doc_text": "words that have a higher chance of being in the output of an LLM when a particular trigger word is appended to the prompt. That is, it helps us to closely examine the bias association between the prompt and the output generated by LLM. Pointwise mutual information: Similar to the above frequency based word cloud analysis, point- wise mutual information (PMI) analysis helps us to analyze those words that occur more often with one type of trigger word as compared to other trigger words. Usually, PMI is calculated be- tween 2 words. For our analysis, we append the tags LABEL_CONTROL, LABEL_STRAIGHT_MAN, LABEL_STRAIGHT_WOMAN, LABEL_GAY_MAN, LABEL_LESBIAN_WOMAN to the five types of gen- erated outputs, respectively. We then calculate the PMI of each word occurring in all the LLM outputs 5 with those label words individually to look at the top few words for each label. t-SNE visualizations: We compute TF-IDF sen- tence embeddings for all the outputs of the LLM. We then use t-SNE to plot these embeddings in a two-dimensional space. The points in the plot are color coded by their label. The rationale behind this plot lies in the fact that the proximity of data points indicates similarity in embeddings. Average cosine similarity: We calculated the av- erage cosine similarity between the output embed- dings of prompts that had sexual identity trigger words with those of control prompts to see how similar or dissimilar the outputs are. Regard score: The regard score or regard metric (Sheng et al., 2019) is a measure of how society perceives a person. In other words, it measures how powerful/weak or high-regard/low-regard words are used to describe an individual. The regard score for outputs of sexual identity trigger words were compared with those of the control sentence. The proximity of regard scores to that of the control group is an indication of the current societal norms. 5.2 Debiasing the LLM Output The outputs of the LLM when the prompt in- cluded queer trigger words (\u2018gay man\u2019 and \u2018les- bian woman\u2019) had lower regard than those prompts with their straight counterparts. As can be seen in Section 6, the words/phrases that describe the queer struggle are common in the outputs for queer trigger words prompts. To find a solution for the second research question, we do not undermine the queer struggle that is being acknowledged in the LLM outputs. Rather, we prioritize the eleva- tion of queer individuals\u2019 status and visibility in these outputs. Consequently, we employ a post-hoc approach to mitigate bias in the generated output. We formulate the problem as a text-to-text neural style transfer task in order to preserve the semantic meaning (acknowledging the queer struggle) and increase the overall regard of the sentence (elevat- ing the status of the queer individual). Our methodology is based on the idea introduced by Yang (2022) as this paper also tries to solve a text-to-text style transfer problem. SHAP can be used with a trained classifier to detect the words that drive the output of a classifier to a particular label more than other words. Hence, in our work, we used the trained regard classifier from Sheng Figure 3: Proposed pipeline for debiasing the output of the LLM. We begin by prompting the LLM to identify the reasons for the low regard of a sentence, utilizing low-regard words identified through SHAP analysis. Using the original sentence and the reason generated by the LLM, we then prompt the LLM again to generate a high regard sentence by replacing the low-regard words. et al. (2019). Using SHAP word level analysis with this classifier, we found the words that drive a sentence towards its lower regard. Yang (2022) mask out the words detected by SHAP and use a language model to predict the words in place of In our case, we take the idea of chain-of- that. thought prompting (CoT) (Wei et al., 2023). We first query the LLM for a possible reason why the words detected by the SHAP analysis would lower the regard of the given sentence. We then take that reason and re-prompt the LLM to rephrase the given sentence to keep the meaning intact and choose different words for the low-regard words. This is shown in Figure 3. 6 Results 6.1 Detecting Bias in the Language Model A walk-through of the methodology using an ex- ample is shown in Figure (1). The resulting outputs for the LLM are shown in Table (4) in Appendix. From Table (4), we notice that the outputs of control, straight man and straight woman acknowl- edge the fact that person being discussed was an accomplished figure known for their business pur- suits. However, the outputs for gay man and lesbian woman include words that indicate the queer strug- gle \u2013 which is justified. However, for the output of lesbian woman, the LLM fails to adequately emphasize the individual\u2019s business mindset, in- stead primarily focusing on their contributions to philanthropy and promotion of inclusivity. The t-SNE plot in Figure (6) shows that the out- puts of control and straight men are similar to each other as they are closer to each other. However, the 6 Measure Cosine similarity Regard score SM SW GM LW 0.33 0.43 0.27 0.01 0.39 -0.05 0.35 0.31 Table 1: Cosine similarity and regard score difference of sentences with sexual identity trigger words with those of control sentences. outputs of gay men and lesbian women are closer to each other but afar from control outputs. Based on these embeddings, we computed the average cosine similarity between the embeddings between sexual identity trigger words outputs and the con- trol as shown in Table 1. The same conclusion can be drawn from these average cosine values. Please note SM stands for straight man and control, SW stands for straight woman and control, GM stands for gay man and control, LW stands for lesbian woman and control. A similar notation as above is used for regard score difference with control sentence in Table 1. As can be seen from this"}