{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Eric_P._Xing_3D_Semantic_Segmentation_in_the_Wild:_Learning_Generalized_Models_for_Adverse-Condition_Point_Clouds_chunk_7.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the name of the large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions?", "answer": " SemanticSTF", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " Which pre-trained models perform clearly better than SalsaNext and Cylinder3D according to the experimental results in the text?", "answer": " RandLA-Net, SPVCNN, and SPVNAS", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What is PointDR and what is its purpose?", "answer": " PointDR is a domain randomization technique that aims to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds.", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What types of adverse weather conditions are included in the annotations provided by SemanticSTF?", "answer": " Dense fog, light fog, snow, and rain", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What is the significance of SemanticSTF in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions?", "answer": " It demonstrates the importance of robust point cloud parsing under adverse weather conditions.", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What is the name of the domain generalization technique that aims to use meta-regularization for domain generalization?", "answer": " Metareg", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What novel designs are included in PointDR to achieve perturbation-invariant representations?", "answer": " Geometry style randomization and embedding aggregation", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What are some examples of adverse weather conditions included in the studies mentioned in the text?", "answer": " Dense fog, light fog, snow, and rain", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " Who funded the study mentioned in the text?", "answer": " Ministry of Education Singapore", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}, {"question": " What is the goal of using normal-weather point clouds in training a domain generalizable 3DSS model?", "answer": " To create a model that can work well over adverse-weather point clouds", "ref_chunk": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}], "doc_text": "evaluated over the validation set of SemanticSTF. We di- rectly use the officially released code and the pre-trained weights for evaluation. Table 6 shows experimental results. We can observe that the five pre-trained models perform very differently though they all achieve superior segmenta- tion over SemanticKITTI. Specifically, RandLA-Net [19], SPVCNN [43], and SPVNAS [43] perform clearly better than SalsaNext [9] and Cylinder3D [64]. In addition, none of the five pre-trained models perform well, verifying the clear domain discrepancy between point clouds of normal and adverse weather conditions. The experiments further indicate the great value of SemanticSTF in the future explo- ration of robust point cloud parsing under all weather con- In addition, the supervised performance of these ditions. 3DSS networks over SemanticSTF is provided in the ap- pendix. 6. Conclusion and Outlook This paper presents SemanticSTF, a large-scale dataset and benchmark suite for semantic segmentation of LiDAR point clouds under adverse weather conditions. Semantic- STF provides high-quality point-level annotations for point clouds captured under adverse weather including dense fog, light fog, snow and rain. Extensive studies have been con- ducted to examine how state-of-the-art 3DSS methods per- form over SemanticSTF, demonstrating its significance in directing future research on domain adaptive and domain generalizable 3DSS under all-weather conditions. We also design PointDR, a domain randomization tech- nique that aims to use normal-weather point clouds to train a domain generalizable 3DSS model that can work well over adverse-weather point clouds. PointDR consists of two novel designs including geometry style randomization and embedding aggregation which jointly learn perturbation- invariant representations that generalize well to various new point-cloud domains. Extensive experiments show that PointDR achieves superior point cloud segmentation per- formance as compared with the state-of-the-art. Acknowledgement This study is funded BY the Ministry of Education Singapore, under the Tier-1 scheme with project number RG18/22. It is also supported under the RIE2020 In- dustry Alignment Fund \u2013 Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from Singapore Telecommunications Limited (Singtel), through Singtel Cognitive and Artificial Intelli- gence Lab for Enterprises (SCALE@NTU). 8 References [1] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chel- lappa. Metareg: Towards domain generalization using meta- regularization. Advances in neural information processing systems, 31, 2018. 2 [2] Jens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pages 9297\u20139307, 2019. 1, 3, 4, 6, 7, 8, 16 [3] Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide. See- ing through fog without seeing fog: Deep multimodal sen- In Proceedings of sor fusion in unseen adverse weather. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11682\u201311692, 2020. 1, 2, 3, 4 [4] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Gener- alizing from several related classification tasks to a new un- labeled sample. Advances in neural information processing systems, 24, 2011. 2 [5] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi- ancarlo Baldan, and Oscar Beijbom. nuscenes: A multi- In Proceedings of modal dataset for autonomous driving. the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020. 4 [6] Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, and Bingbing Liu. 2-s3net: Attentive feature fusion with adap- tive feature selection for sparse semantic segmentation net- work. In Proceedings of the IEEE/CVF conference on com- puter vision and pattern recognition, pages 12547\u201312556, 2021. 2 [7] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neu- ral networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u2013 3084, 2019. 2, 6, 7, 12, 14, 15 [8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3213\u20133223, 2016. 4 [9] Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of In International Symposium on Visual lidar point clouds. Computing, pages 207\u2013222. Springer, 2020. 2, 8, 15 [10] A Filgueira, H Gonz\u00b4alez-Jorge, Susana Lag\u00a8uela, L D\u00b4\u0131az- Vilari\u02dcno, and Pedro Arias. Quantifying the influence of rain in lidar performance. Measurement, 95:143\u2013148, 2017. 3 [11] Whye Kit Fong, Rohit Mohan, Juana Valeria Hurtado, Lub- ing Zhou, Holger Caesar, Oscar Beijbom, and Abhinav Val- ada. Panoptic nuscenes: A large-scale benchmark for lidar panoptic segmentation and tracking. IEEE Robotics and Au- tomation Letters, 7(2):3795\u20133802, 2022. 1, 4 9 [12] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015. 2 [13] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The kitti dataset. The Inter- national Journal of Robotics Research, 32(11):1231\u20131237, 2013. 4 [14] Dayan Guan, Jiaxing Huang, Aoran Xiao, and Shijian Lu. Domain adaptive video segmentation via temporal consis- tency regularization. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 8053\u20138064, 2021. 2 [15] Martin Hahner, Christos Sakaridis, Mario Bijelic, Felix Heide, Fisher Yu, Dengxin Dai, and Luc Van Gool. Lidar snowfall simulation for robust 3d object detection. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16364\u201316374, 2022. 2 [16] Martin Hahner, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Fog simulation on real lidar point clouds for 3d object detection in adverse weather. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15283\u201315292, 2021. 2 [17] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition, pages 9729\u20139738, 2020. 5, 12 [18] Robin Heinzler, Philipp Schindler, J\u00a8urgen Seekircher, Werner Ritter, and Wilhelm Stork. Weather influence In 2019 and classification with automotive lidar sensors. IEEE intelligent vehicles symposium"}