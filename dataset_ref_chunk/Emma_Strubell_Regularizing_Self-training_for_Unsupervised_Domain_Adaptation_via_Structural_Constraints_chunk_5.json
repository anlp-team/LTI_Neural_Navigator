{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Emma_Strubell_Regularizing_Self-training_for_Unsupervised_Domain_Adaptation_via_Structural_Constraints_chunk_5.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the target domain performance using self-training?", "answer": " 31.2 28.8 50.8 46.7", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " How can the constraint in Eqn. 7 be extended to multiple images?", "answer": " By simply averaging over them", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What is the final regularised self-training objective defined as?", "answer": " Lpac = Ls obj", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What does \u03b1obj control in the overall training?", "answer": " The effect of the constraint", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " How is the spatial resolution of pixel-wise embeddings set in CAG and SAC?", "answer": " 256\u00d7470 in CAG and SAC, 300\u00d7300 in DACS", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What datasets are evaluated in the PAC-UDA framework?", "answer": " Cityscapes and SYNTHIA", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " How are the GTA UDA framework experiments conducted regarding GPUs?", "answer": " On 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What is the size of the GTA5 synthetic images?", "answer": " 24,966 images with resolution 1914 \u00d7 1052", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What is the number of real images in the Cityscapes dataset?", "answer": " 5,000", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}, {"question": " What modification was done for the SAC method in the experiments?", "answer": " Reducing GROUP SIZE from 4 to 2", "ref_chunk": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}], "doc_text": "- 31.2 28.8 50.8 46.7 target domain performance using self-training. Addition- ally, the constraint in Eqn. 7 is de\ufb01ned for a single image but can be easily extended to multiple images by simply averaging over them; the \ufb01nal regularised self-training ob- jective is then de\ufb01ned as Lpac = Ls obj, where \u03b1obj controls the effect of the constraint on overall training. uda + \u03b1obj \u2217 Lt 3.3. Learning and Optimization To train the our model, PAC-UDA with a base self- training approach, we follow the exact procedure outlined by the corresponding approach. The only difference is that we plug in our constraint as a regularise to the base ob- jective, Luda. One important consideration is that our reg- ularise depends on reasonable quality of pseudo labels to de\ufb01ne region labels that are not random. Thus the regular- isation weight, \u03b1obj is set to zero for a few initial training iterations, post which it switches to the actual value. 4. Experiments prior works [2, 61]. The performance metrics used are per class Intersection over Union (IoU) and mean IoU (mIoU) over all the classes. Implementation Details: For object region estimates, we experiment with three different numbers, ks \u2208 {25, 50, 100} of RGB-clusters, two values of prominence thresholds, \u03b4peak \u2208 {0.001, 0.0025} and three numbers of histogram bins, b \u2208 {100, 200, 400}. Depth maps obtained from stereo pairs can have missing values at pixel-level, as is the case with Cityscapes. These missing values have a value zero and are ignored while generating depth segments using depth-histogram. Finally, due to high computational cost of computing the contrastive objective from pixel-wise embedding, we set the spatial resolution of these embed- dings to 256\u00d7470 in CAG and SAC and 300\u00d7300 in DACS. We \ufb01xed the relative weighting of the regularizer, \u03b1obj to 1.0 as the target performance was found to be insensitive to the exact value. For hyperameter choices regarding ar- chitecture and optimizers, we exactly follow the respective self-training base methods [2, 47, 60]. Experiments were conducted on 4 \u00d7 11GB RTX 2080 Ti GPUs with PyTorch implementation. Further details in the supplementary. Datasets and Evaluation Metric: We evaluate the PAC- the GTA UDA framework in two common scenarios: [37]\u2192Cityscapes [12] transfer semantic segmenta- tion task and the SYNTHIA [38]\u2192Cityscapes [12] task. GTA5 is composed of 24, 966 synthetic images with resolution 1914 \u00d7 1052 and has annotations for 19 classes that are compatible with the categories in Cityscapes. Sim- ilarly, SYNTHIA consists of 9, 400 synthetic images of ur- ban scenes at resolution 1280 \u00d7 760 with annotations for only 16 common categories. Cityscapes has of 5, 000 real images and aligned depth maps of urban scenes at resolu- tion 2048 \u00d7 1024 and is split into three sets of 2, 975 train, 500 validation and 1, 525 test images. Of the 2, 975, we use 2, 475 randomly selected images for self-training and remaining 500 images for validation. We report the \ufb01nal test performance of our method on the 500 images of the of\ufb01cial validation split. The data-splits are consistent with 4.1. Generality of Objectness Constraint In Table 1, we test the generality of our proposed reg- ularizer on three base methods, namely, CAG [60], SAC [2] and DACS [47] that generate pseudo labels in differ- ent ways. We use of\ufb01cial implementations of each base method with almost same con\ufb01gurations for data prepro- cessing, model architecture, and optimizer except for a few modi\ufb01cations as follows. In the case of CAG, we replace the Euclidean metric with a Cosine metric as it was found to generate more reliable pseudo-labels. Also, we run it for a single self-training iteration instead of three [60]. For the SAC method, we reduce the GROUP SIZE from default value of 4 to 2 following GPU constraints. Finally, for the 6 mIoU 48.2 49.6 52.8 53.4 52.8 54.2 40.8 41.7 50.3 52.5 50.0 51.2 Table 2. GTA \u2192 Cityscapes results: Classwise and mean (over 16 classes) IoU comparison of our DACS+PAC with prior works. \u2020 denotes the use of PSPNet [63], * denotes our implementation of SAC with a restricted con\ufb01guration (GROUP SIZE=2) compared to original SAC method (GROUP SIZE=4). All other methods use DeepLabV2 [9] architecture. d a o r k l a w e d i s g n i d l i u b l l a w e c n e f e l o p t h g i l n g i s . e g e v n i a r r e t y k s n o s r e p r e d i r r a c k c u r t s u b n i a r t r o t o m e k i b mIoU AdvEnt [50] DISE [7] Cycada [18] BLF [25] CAG-UDA [60] PyCDA\u2020 [26] CD-AM [58] FADA [52] FDA [59] SA-I2I [34] PIT [31] IAST [32] DACS [47] RPT\u2020 [61] SAC [2] SAC* [2] 89.4 91.5 86.7 91.0 90.4 90.5 91.3 92.5 92.5 91.2 87.5 93.8 89.9 89.2 90.4 89.9 33.1 47.5 35.6 44.7 51.6 36.3 46.0 47.5 53.3 43.3 43.4 57.8 39.7 43.3 53.9 54.0 81.0 82.5 80.1 84.2 83.8 84.4 84.5 85.1 82.4 85.2 78.8 85.1 87.9 86.1 86.6 86.2 26.6 31.3 19.8 34.6 34.2 32.4 34.4 37.6 26.5 38.6 31.2 39.5 30.7 39.5 42.4 37.8 26.8 25.6 17.5 27.6 27.8 28.7 29.7 32.8 27.6 25.9 30.2 26.7 39.5 29.9 27.3 28.9 27.2 33.0 38.0 30.2 38.4 34.6 32.6 33.4 36.4 34.7 36.3 26.2 38.5 40.2 45.1 45.9 33.5 33.7 39.9 36.0 25.3 36.4 35.8 33.8 40.6 41.3 39.9 43.1 46.4 49.6 48.5 46.9 24.7 25.8 41.5 36.0 48.4 31.5 36.4 18.4 38.9 41.0 42.0 34.7 52.8 33.1 42.7 47.7 83.9 82.7 82.7 85.0 85.4 86.8 84.5 85.3 82.3 85.5 79.2 84.9 88.0 87.4 87.4 88.0 36.7 28.8 27.9 43.6 38.2 37.9 43.2 37.7 39.8 46.0 37.1 32.9 44.0 38.5 40.1 44.8 78.8 82.7 73.6 83.0 78.1 78.5 83.0 83.5 78.0 86.5 79.3 88.0 88.7 86.0"}