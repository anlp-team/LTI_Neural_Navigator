{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Shinji_Watanabe_chunk_10.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What is the goal of the survey discussed in the text?", "answer": " The goal of the survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What are the aspects of E2E ASR covered in the survey?", "answer": " All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What are the two tracks of the MISP2022 challenge mentioned in the text?", "answer": " The two tracks of the MISP2022 challenge are audio-visual speaker diarization (AVSD) and audio-visual diarization and recognition (AVDR).", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What is the focus of the MISP2022 challenge in terms of language and scenarios?", "answer": " Both tracks of the MISP2022 challenge focus on the Chinese language and use far-field audio and video in real home-TV scenarios with 2-6 people communicating with TV noise in the background.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What problem does DPHuBERT aim to solve?", "answer": " DPHuBERT aims to address the large model size and heavy computational cost hindering the deployment of self-supervised speech models.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " How does DPHuBERT differ from pure distillation methods?", "answer": " DPHuBERT is a task-agnostic compression method for speech SSL based on joint distillation and pruning, which outperforms pure distillation methods in almost all tasks.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What is the purpose of the external quality assessment feasibility study discussed in the text?", "answer": " The study aims to provide a snapshot of laboratory proficiency, identify issues, improve laboratory performance, and reduce inter-laboratory variation in seasonal influenza serology testing.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What are the methods used in the external quality assessment feasibility study?", "answer": " Participant laboratories from various sectors returned data for hemagglutination inhibition (HAI) and microneutralization (MN) assays to assess laboratory proficiency in seasonal influenza serology testing.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What is the focus of the Wavlab submission to The Clarity ICASSP 2023 Grand Challenge?", "answer": " The focus of the submission is to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}, {"question": " What model is the Wavlab submission based on?", "answer": " The Wavlab submission builds on the iNeuBe-X model, which is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement.", "ref_chunk": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}], "doc_text": "learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.', ['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'R. Schluter', 'Shinji Watanabe']] ['The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.', ['Zhe Wang', 'Shilong Wu', 'Hang Chen', 'Maokui He', 'Jun Du', 'Chin-Hui Lee', 'Jingdong Chen', 'Shinji Watanabe', 'Sabato Marco Siniscalchi', 'O. Scharenborg', 'Diyuan Liu', 'Baocai Yin', 'Jia Pan', 'Jianqing Gao', 'Cong Liu']] ['DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models', '2023', ['Interspeech', 'Conf Int Speech Commun Assoc', 'INTERSPEECH', 'Conference of the International Speech Communication Association'], 'Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.', ['Yifan Peng', 'Yui Sudo', 'Muhammad Shakeel', 'Shinji Watanabe']] ['An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study', '2023', ['Frontiers in Immunology', 'Front Immunol'], 'Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.', ['J. Waldock', 'C. Weiss', 'Wei Wang', 'M. Levine', 'Stacie N. Jefferson', 'S. Ho', 'K. Hoschler', 'B. Londt', 'E. Masat', 'Louise A. Carolan', 'Stephany S\u00e1nchez-Ovando', 'A. Fox', 'Shinji Watanabe', 'Miki Akimoto', 'Aya Sato', 'N. Kishida', 'A. Buys', 'Lorens Maake', 'Cardia Fourie', 'Catherine Caillet', 'Sandrine Raynaud', 'R. Webby', 'J. Debeauchamp', 'R. Cox', 'Sarah Lartey', 'C. Trombetta', 'S. Marchi', 'E. Montomoli', 'I. Sanz-Mu\u00f1oz', 'J. Eiros', 'Javier S\u00e1nchez-Mart\u00ednez', 'D. Duijsings', 'O. Engelhardt']] ['Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge', '2023', ['IEEE International Conference on Acoustics, Speech, and Signal Processing', 'Int Conf Acoust Speech Signal Process', 'IEEE Int Conf Acoust Speech Signal Process', 'ICASSP', 'International Conference on Acoustics, Speech, and Signal Processing'], 'In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and"}