{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Graham_Neubig_User-Centric_Evaluation_of_OCR_Systems_for_Kwak\u2019wala_chunk_1.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What type of evaluation of OCR systems is presented in the paper?", "answer": " A human-centric evaluation", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " Why has there been recent interest in improving OCR for endangered languages?", "answer": " Because a large number of documents and books in these languages are not in machine-readable formats", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " According to the text, what are some examples of documents created for endangered languages?", "answer": " Folk tales, poetry, speech transcriptions, vocabulary lists, and archival material", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " How are machine-readable transcriptions of documents typically produced?", "answer": " By a human transcriber who looks at the document and retypes the text present in it", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " What technique has been used to improve OCR in low-resourced settings?", "answer": " Automatic post-correction", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " What do CER and WER stand for in the context of evaluating OCR systems?", "answer": " Character Error Rate and Word Error Rate", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " Why is it mentioned that error rates are not enough to evaluate OCR systems?", "answer": " Because they do not measure whether the transcriptions produced are useful to downstream users", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " What language is the focus of the user study mentioned in the text?", "answer": " Kwak\u2019wala", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " What is the main finding of the user study regarding the use of OCR?", "answer": " There is a statistically significant reduction in the time needed for manual transcription when an OCR system is used", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}, {"question": " What is the potential benefit highlighted in the results of using OCR tools for endangered languages?", "answer": " Adding valuable efficiency to language preservation and revitalization efforts", "ref_chunk": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}], "doc_text": "3 2 0 2 b e F 6 2 ] L C . s c [ 1 v 0 1 4 3 1 . 2 0 3 2 : v i X r a User-Centric Evaluation of OCR Systems for Kwak\u2019wala Shruti Rijhwani,1 Daisy Rosenblum,2 Michayla King,3 Antonios Anastasopoulos,4 Graham Neubig1 1Language Technologies Institute, Carnegie Mellon University 2University of British Columbia 3K \u00af \u2019wa \u00af la Language Program 4Department of Computer Science, George Mason University srijhwan@cs.cmu.edu, daisy.rosenblum@ubc.ca, michayla.g3@gmail.com antonis@gmu.edu, gneubig@cs.cmu.edu Abstract There has been recent interest in improving op- tical character recognition (OCR) for endan- gered languages, particularly because a large number of documents and books in these lan- guages are not in machine-readable formats. The performance of OCR systems is typi- cally evaluated using automatic metrics such as character and word error rates. While er- ror rates are useful for the comparison of dif- ferent models and systems, they do not mea- sure whether and how the transcriptions pro- duced from OCR tools are useful to down- stream users. In this paper, we present a human-centric evaluation of OCR systems, fo- cusing on the Kwak\u2019wala language as a case study. With a user study, we show that utiliz- ing OCR reduces the time spent in the man- ual transcription of culturally valuable docu- ments \u2013 a task that is often undertaken by en- dangered language community members and researchers \u2013 by over 50%. Our results demon- strate the potential bene\ufb01ts that OCR tools can have on downstream language documentation and revitalization efforts.1 1 Introduction Documentation and revitalization efforts for en- dangered languages frequently lead to the creation of textual documents in these languages. These include cultural materials such as folk tales and poetry; linguistic documentation like speech tran- scriptions and vocabulary lists; and other archival material (Himmelmann, 1998; Grenoble and Wha- ley, 2005). However, even though a substantial number of such documents have been created for endangered languages around the globe, the vast majority are not widely accessible because they exist only as printed books and handwritten notes. Although some of these documents are digitally available as scanned images, the text contained in the images is not machine-readable, inhibiting sev- eral use cases that are important to communities that speak endangered languages. For example, (1) the text is not searchable for speakers and re- searchers of these languages; (2) it cannot be refor- matted, indexed, or adapted to various needs; and (3) it cannot be used to build datasets for training NLP models. Machine-readable transcriptions of documents are typically produced by a human tran- scriber, who looks at the document and retypes the text present in it. Like other manual transcription tasks (e.g., speech transcription), this process is time-consuming and requires signi\ufb01cant effort. That said, there are computational approaches to producing machine-readable text from scanned documents, speci\ufb01cally through optical character recognition (OCR). Training a high-performance OCR system is challenging given the small amount of data that is typically available in endangered languages. However, there has been recent inter- est (Rijhwani et al., 2020, 2021; Tjuatja et al., 2021; Disbray et al., 2022) in improving OCR even in very low-resourced settings using the technique of automatic post-correction. Post-correction models correct errors in existing OCR transcriptions (Ko- lak and Resnik, 2005; Dong and Smith, 2018; Kr- ishna et al., 2018). The post-correction methods presented in Rijhwani et al. (2021) demonstrated substantial performance gains for multiple low- resourced endangered languages \u2013 reducing char- acter error rates (CER) by 32\u201358% and word error rates (WER) by 29\u201359% relative to off-the-shelf OCR systems.2 1Code, models, and datasets are available at https:// shrutirij.github.io/ocr-el/. 2Character error rate (CER) and word error rate (WER) are based on edit distance and are standard metrics for evaluating OCR systems (Berg-Kirkpatrick et al., 2013; Schulz and Kuhn, 2017). CER is the edit distance between the predicted and While error rates are useful to quantify the per- formance of various OCR technologies, they do not measure whether the produced transcriptions are useful to the primary audience for these tran- scriptions: community language learners, teachers, and researchers. In this paper, we look beyond error rates and take a human-centered approach to evaluating OCR and understanding whether the automatically produced transcriptions are bene\ufb01- cial to downstream users. More speci\ufb01cally, we analyze whether OCR is effective in lowering the time and effort spent in manually creating accu- rate transcriptions of scanned documents which, as discussed above, is a task that is frequently under- taken in language documentation and preservation programs. As a case study, we focus on Kwak\u2019wala, an endangered language spoken in North America, be- cause of its long tradition of written documentation and active community engagement in accessing the knowledge contained in these texts (detailed in Section 2). We conduct a user study where we compare the time spent by human transcribers on producing an accurate transcription of typewritten Kwak\u2019wala documents with and without the use of an OCR system.3 We demonstrate that there is a statistically signi\ufb01cant reduction in the time needed for manual transcription when an OCR system is used beforehand. Our results indicate that further research and development of improved OCR tools for endangered languages can add valuable ef\ufb01- ciency to language preservation and revitalization efforts. 2 Documents in the Kwak\u2019wala Language To conduct our proposed human-centric evaluation of OCR, we focus on documents in the Kwak\u2019wala language, while noting that our user study does not involve any language-speci\ufb01c components and can be extended to other languages. Kwak\u2019wala is a member of the Wakashan lan- guage family spoken on the Northwest North Amer- the gold transcriptions of the document, divided by the total number of characters in the gold transcription. WER is similar but is calculated at the word level. 3Similar user studies have been carried out to determine the effectiveness of machine translation in reducing human post- editing effort (Specia and Farzindar, 2010; Gaspari et al., 2014; Koponen, 2016), but none for OCR or endangered languages, to the best of our knowledge. Kettunen et al. (2022) measure user-perceived"}