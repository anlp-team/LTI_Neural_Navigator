{"file_path": "/Users/sz904/Desktop/11711/LTI_Neural_Navigator/data/2024-02-26/chunk_paper_txt/Maarten_Sap_Don't_Take_This_Out_of_Context!_On_the_Need_for_Contextual_Models_and_Evaluations_for_Stylistic_Rewriting_chunk_12.txt", "num_qa_pairs": 10, "qa_list": [{"question": " What do Figures 27, 28, and 29 depict?", "answer": " The detoxification results for conversational datasets.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " How do the trends in Figures 27, 28, and 29 align with the findings from the contextual human evaluation study?", "answer": " They align with the findings from the contextual human evaluation study.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What correlations were measured in Section E.1?", "answer": " Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " Where can you refer to for the correlation scores of non-contextual evaluation metrics with human judgments for each task?", "answer": " Tables 13 \u2013 15.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What is depicted in Figure 4?", "answer": " Screenshot of the instructions for human evaluation annotation.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What task is showcased in Example (b)?", "answer": " Formality change.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " In Example (c), what transformation is applied to the text?", "answer": " Detoxification from toxic to less toxic.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What sentiment transfer is showcased in Example (e)?", "answer": " Positive to negative.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What sentiment transfer is showcased in Example (f)?", "answer": " Negative to positive.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}, {"question": " What types of results are presented in Tables 16-27?", "answer": " Non-contextual automatic evaluation results.", "ref_chunk": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}], "doc_text": "transfer results for document-level and conversation-level datasets, respectively. Figures 27, 28, and 29 depict the de-toxification results for conversational datasets. All of these figures exhibit similar trends to the aggregate results across all tasks and datasets presented in Figure 3 and they align with the findings from our contextual human evaluation study. E.1 Correlation with Human Judgments Similar to \u00a7D.1, we measure the Spearman rank \u03c1 correlation and Kendall\u2019s \u03c4 correlation for the samples used during human evaluation in \u00a75.1. Re- fer to Tables 13 \u2013 15 for the correlation scores of non-contextual evaluation metrics with human judgments for each task. Figure 4: Screenshot of the instructions for human evaluation annotation Figure 5: Screenshot of the human evaluation annotation task Task Conversion Context Original Sentence Model Contextual Rewrite Non-contextual Rewrite (a) Formality Informal -> Formal @ I am reading a book, 777 Mathematical Conversation Starters by John dePillis. Its an interesting book with lots of quotes, poems (cid:15) Herez some of them, and further I will keep updating this page with what I like. GPT-3.5 GPT-NeoX (cid:15) I plan to continue to up- date this page with further selections that I find partic- ularly intriguing from the book. (cid:15) Here are some of them, and in a later post I will keep updating this page with my favourite quotes from the book. (cid:15) Here are some of them, and I will continue to up- date this page with my preferences. (cid:15) Here is some of the one and further I will update this page with what else I find interesting. (b) Formality Semi-formal -> Informal (cid:220) I can never again take a site serious that gives the mess and ... just an awful game. (cid:215) I liked that game. It\u2019s almost as if opinions are subjective. GPT-3.5 GPT-NeoX (cid:215) I enjoyed Ni No Kuni 2, but it\u2019s clear that other people didn\u2019t - and that\u2019s okay. Everyone\u2019s got their own opinion! (cid:215) I liked that game, de- spite critical opinions to the contrary. The fact that people enjoyed it doesn\u2019t make it any worse than anything else. (cid:215) I enjoyed that game. It seems opinions may in- deed vary among individu- als. (cid:215) I liked that game. It\u2019s almost as if opinions are relative. (c) Detoxification Toxic -> Less Toxic (cid:220) Did Rolando just call me just to tell me shut up? (cid:215) @USER fuck yeah I did!! Shut up GPT-3.5 (cid:215) @USER Yes, I was ask- ing you to be quiet. GPT-NeoX (cid:215) user yes, please keep quiet (cid:215) I am very proud of my accomplishment! yeah (cid:215) yeah, I did! Shut up. (d) Detoxification Toxic -> Less Toxic (cid:220) \"i am here 2 play games i am playin 1 wit u 10:50 to 2:42 baby i\u2019m everywhare\" (cid:215) It\u2019s so amusing when the illiterate try to taunt. GPT-3.5 GPT-NeoX (cid:215) I\u2019m not sure I under- stand what you\u2019re trying to say. Could you please rephrase? (cid:215) It\u2019s amusing when someone attempts to insult or taunt me and they are clearly uneducated about language. (cid:215) It\u2019s interesting to see how someone is illiterate tries to tease. (cid:215) It\u2019s funny when the un- educated try to insult. (e) Sentiment Positive -> Negative @ I just want to echo what everyone else has already said about this mechanic... Not only did Tim fix my car quickly and inexpensively, he actually came to pick it up himself so that I wouldn\u2019t have to spend money on a tow truck! (cid:15) He\u2019s also an extremely friendly, funny guy who puts you at ease immediately. GPT-3.5 GPT-NeoX (cid:15) Despite an efficient mechanic, Tim lacked the friendly and humorous demeanor expected of a service provider. being (cid:15) However, Tim\u2019s not very friendly or humor- ous which might make you feel uneasy (cid:15) He\u2019s an unfriendly and humorless person who makes you feel uneasy right away. (cid:15) He is also a very rude, unamused guy who makes you feel anxious. (f) Sentiment Negative -> Positive (cid:220) I had to move it so that I can get my bike through. (cid:215) How dare you be so inconsiderate ? That\u2019s wrong. GPT-3.5 (cid:215) It was very consider- ate of you to move it, so that you can get your bike through. That\u2019s great. (cid:215) How kind of you to be so considerate! That\u2019s right. GPT-NeoX (cid:215) I understand you needed to move it so you could get your bike through - thank you for being thoughtful! (cid:215) How can you be so con- siderate! That\u2019s right. Table 6: Examples from our datasets and corresponding rewrites generated by GPT-3.5 and GPT-NeoX, showcasing all three tasks: formality change, de-toxification, and sentiment transfer. @ = document context, (cid:15) = sentence to rewrite, (cid:15) = contextual rewrite, (cid:15) = non-contextual rewrite; (cid:220) = previous turn in conversation, (cid:215) = response to rewrite, (cid:215) = contextual rewrite of response, (cid:215) = non-contextual rewrite of response modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.190.402.140.920.620.5138.370.59non-contextual0.280.490.910.940.730.6743.400.58random-context0.180.353.170.910.520.47GPT-NeoXcontextual0.260.421.880.910.600.4744.590.42non-contextual0.450.630.720.950.800.6744.800.35random-context0.210.361.900.910.600.41 Table 16: Non-contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.160.382.670.900.670.4533.780.68non-contextual0.220.411.230.910.720.5340.060.67random-context0.150.323.720.890.580.43GPT-NeoXcontextual0.240.411.970.900.650.4452.450.45non-contextual0.360.550.980.920.780.5457.120.37random-context0.270.402.700.900.600.44 Table 17: Non-contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.180.361.570.900.590.4042.210.74non-contextual0.400.610.640.940.800.6358.380.64random-context0.140.301.740.890.490.36GPT-NeoXcontextual0.270.431.430.910.560.4157.640.49non-contextual0.450.600.670.940.740.6273.020.49random-context0.290.441.370.910.560.42 Table 18: Non-contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticFluencyStyleROUMETWERBERT-SSBERTSmatchPPL GPT-3.5contextual0.300.541.030.910.630.5336.310.69non-contextual0.450.670.650.930.750.6842.820.64random-context0.300.521.070.910.590.53GPT-NeoXcontextual0.160.301.660.870.430.2242.390.35non-contextual0.330.480.810.900.590.5064.090.25random-context0.180.331.630.880.430.30 Table 19: Non-contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.200.360.940.900.640.4537.920.010.410.06non-contextual0.240.410.800.910.720.5140.980.010.470.07random-context0.170.320.970.890.570.43GPT-NeoXcontextual0.320.400.780.900.600.4663.040.070.610.13non-contextual0.440.520.610.920.710.5767.470.100.690.15random-context0.320.400.770.900.580.47 Table 20: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from CCC dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.110.321.180.870.510.4375.480.040.310.11non-contextual0.120.340.990.880.560.4778.230.050.340.12random-context0.080.281.240.860.420.40GPT-NeoXcontextual0.180.281.290.870.450.3980.100.390.620.35non-contextual0.320.490.910.900.670.54106.660.520.740.46random-context0.150.251.410.860.390.36 Table 21: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from MDMD dataset modelrewrite typeLexicalSemanticFluencyStyleStyleStyleROUMETWERBERT-SSBERTSmatchPPL HateRobertaHateBertPerspectiveGPT-3.5contextual0.050.211.690.880.380.2922.800.030.250.06non-contextual0.110.290.970.910.520.4133.000.140.400.09random-context0.050.191.610.880.250.29GPT-NeoXcontextual0.250.401.120.910.530.4432.860.370.630.26non-contextual0.430.590.660.940.720.6337.900.640.790.38random-context0.250.401.060.910.480.44 Table 22: Non-contextual Automatic Evaluation Results on Toxicity: Conversational context from ProsocialDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.230.890.900.610.3822.050.940.93non-contextual0.150.200.870.890.500.3332.790.870.91random-context0.100.161.060.870.380.2934.240.690.80GPT-NeoXcontextual0.250.280.830.900.620.3720.510.970.94non-contextual0.230.240.840.890.520.3332.150.940.94random-context0.160.190.920.870.420.2939.180.820.87 Table 23: Contextual Automatic Evaluation Results on Formality: Document-level context from CNN/DailyMail + Blog Authorship Corpus modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.140.270.910.890.660.3728.820.880.89non-contextual0.140.240.950.880.560.3641.020.820.87random-context0.110.201.580.870.470.3246.790.730.81GPT-NeoXcontextual0.210.290.880.890.640.3634.740.900.90non-contextual0.230.290.880.880.580.3652.450.860.89random-context0.170.221.290.870.460.3153.980.800.85 Table 24: Contextual Automatic Evaluation Results on Formality: Conversational context comprised of Reddit threads modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.110.170.920.880.530.2425.530.980.94non-contextual0.160.170.870.880.480.2441.180.930.94random-context0.070.120.930.860.380.1944.130.820.86GPT-NeoXcontextual0.130.160.900.870.470.2333.050.960.93non-contextual0.170.180.870.880.440.2248.590.930.93random-context0.120.150.910.870.410.2053.440.910.91 Table 25: Contextual Automatic Evaluation Results on Sentiment: Document-level context comprised of Yelp Reviews modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.250.360.840.890.620.4333.880.970.94non-contextual0.280.350.810.890.540.4150.600.920.93random-context0.200.300.890.880.450.3854.100.870.89GPT-NeoXcontextual0.170.260.970.860.460.3432.450.880.88non-contextual0.200.240.870.870.420.2160.310.860.88random-context0.120.211.040.850.340.2141.690.790.83 Table 26: Contextual Automatic Evaluation Results on Sentiment: Conversational context from DailyDialog dataset modelrewrite typeLexicalSemanticCoherenceCohesivenessCustomROU\u1d9c\u1d57\u02e3MET\u1d9c\u1d57\u02e3WER\u1d9c\u1d57\u02e3BERT-S\u1d9c\u1d57\u02e3SBERT\u1d9c\u1d57\u02e3Smatch\u1d9c\u1d57\u02e3PPL\u1d9c\u1d57\u02e3NSPCtxSimFitGPT-3.5contextual0.160.240.860.880.610.3628.450.950.93non-contextual0.170.250.850.880.570.3537.400.910.91random-context0.120.200.900.870.470.3138.960.890.89GPT-NeoXcontextual0.240.250.820.880.540.3437.410.960.93non-contextual0.290.290.770.890.540.3251.560.920.92random-context0.210.230.840.870.440.3252.240.890.90 Table 27: Contextual Automatic"}